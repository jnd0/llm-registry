import { Benchmark } from "@/types";

const DEFAULT_BENCHMARK_LINK = "https://artificialanalysis.ai/evaluations";

const BENCHMARK_LINK_OVERRIDES: Record<string, string> = {
  "mmlu": "https://arxiv.org/abs/2009.03300",
  "mmlu-pro": "https://arxiv.org/abs/2406.01574",
  "math": "https://arxiv.org/abs/2103.03874",
  "human-eval": "https://arxiv.org/abs/2107.03374",
  "swe-bench-verified": "https://www.swebench.com/",
  "mmmu": "https://mmmu-benchmark.github.io/",
  "mmmu-pro": "https://mmmu-benchmark.github.io/",
  "mmmu-val": "https://mmmu-benchmark.github.io/",
  "mmmu-vision": "https://mmmu-benchmark.github.io/",
  "mmmlu": "https://arxiv.org/abs/2402.03300",
  "mathvista": "https://mathvista.github.io/",
  "mathvista-mini": "https://mathvista.github.io/",
  "livebench": "https://livebench.ai/",
  "livecodebench-v6": "https://livecodebench.github.io/",
  "livecodebench-pro": "https://livecodebenchpro.com/",
  "bigcodebench": "https://github.com/bigcode-project/bigcodebench",
  "gsm8k": "https://github.com/openai/grade-school-math",
  "aime": "https://artofproblemsolving.com/wiki/index.php/AIME",
  "aime-2025": "https://artofproblemsolving.com/wiki/index.php/AIME",
  "aime-2026": "https://artofproblemsolving.com/wiki/index.php/AIME",
  "gpqa-diamond": "https://arxiv.org/abs/2311.12022",
  "arc-agi-1": "https://arcprize.org/",
  "arc-agi-2": "https://arcprize.org/",
  "arc-agi-1-image": "https://arcprize.org/",
  "arc-agi-2-image": "https://arcprize.org/",
  "hle": "https://www.humanityslastexam.com/",
  "hle-full": "https://www.humanityslastexam.com/",
  "hle-full-tools": "https://www.humanityslastexam.com/",
  "hle-text": "https://www.humanityslastexam.com/",
  "hle-verified": "https://www.humanityslastexam.com/",
  "hle-vl": "https://www.humanityslastexam.com/",
  "codeforces": "https://codeforces.com/",
  "lmarena-elo": "https://chat.lmsys.org/?leaderboard",
  "webarena": "https://webarena.dev/",
  "agentbench": "https://github.com/THUDM/AgentBench",
  "tau-bench": "https://github.com/sierra-research/tau2-bench",
  "tau-bench-retail": "https://taubench.com/",
  "tau-bench-telecom": "https://github.com/sierra-research/tau2-bench",
  "docvqa": "https://rrc.cvc.uab.es/?ch=17",
  "ocrbench": "https://ocrbench.github.io/",
  "ocrbench-v2": "https://ocrbench.github.io/",
  "videomme": "https://video-mme.github.io/",
  "terminal-bench": "https://www.tbench.ai/leaderboard/terminal-bench/2.0",
  "terminal-bench-hard": "https://www.tbench.ai/leaderboard/terminal-bench/2.0",
  "osworld-verified": "https://os-world.github.io/",
  "swe-bench-pro": "https://www.swebench.com/",
  "lcr": "https://artificialanalysis.ai/evaluations/lcr",
  "ifbench": "https://artificialanalysis.ai/evaluations/ifbench",
  "aa-omniscience": "https://artificialanalysis.ai/evaluations/omniscience",
  "critpt": "https://arxiv.org/abs/2501.00663",
  "scicode": "https://github.com/scicode-bench/scicode",
  "browsecomp": "https://github.com/google-research/browsecomp",
  "screenspot-pro": "https://github.com/octopus-tools/screenspot-pro",
  "charxiv-reasoning": "https://arxiv.org/abs/2406.18521",
  "facts-benchmark": "https://github.com/google-deepmind/facts-benchmark",
  "mcp-atlas": "https://github.com/modelcontextprotocol/mcp-atlas",
  "toolathlon": "https://github.com/toolathlon/toolathlon",
};

function getBenchmarkLink(benchmark: Benchmark): string {
  return benchmark.link ?? BENCHMARK_LINK_OVERRIDES[benchmark.id] ?? `${DEFAULT_BENCHMARK_LINK}#${benchmark.id}`;
}

const rawBenchmarks: Benchmark[] = [
  {
    id: "mmlu",
    name: "MMLU (5-shot)",
    category: "Knowledge",
    description: "Massive Multitask Language Understanding covers 57 subjects across STEM, the humanities, social sciences, and more.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://arxiv.org/abs/2009.03300"
  },
  {
    id: "math",
    name: "MATH (CoT)",
    category: "Math",
    description: "Challenging competition mathematics problems (AIME/IMO level).",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://arxiv.org/abs/2103.03874"
  },
  {
    id: "human-eval",
    name: "HumanEval",
    category: "Coding",
    description: "Functional correctness of synthesized programs from docstrings.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://arxiv.org/abs/2107.03374"
  },
  {
    id: "swe-bench-verified",
    name: "SWE-bench Verified",
    category: "Coding",
    description: "Resolving real-world GitHub issues. Verified subset ensures solvable issues.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://www.swebench.com/"
  },
  {
    id: "mmmu",
    name: "MMMU (Multimodal)",
    category: "Multimodal",
    description: "Multi-discipline Multimodal Understanding and Reasoning.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://mmmu-benchmark.github.io/"
  },
  {
    id: "livebench",
    name: "LiveBench",
    category: "Reasoning",
    description: "Contamination-free, continuously updated reasoning benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://livebench.ai/"
  },
  {
    id: "bigcodebench",
    name: "BigCodeBench",
    category: "Coding",
    description: "Next-generation HumanEval with more diverse library calls and complex tasks.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://github.com/bigcode-project/bigcodebench"
  },
  {
    id: "gsm8k",
    name: "GSM8K",
    category: "Math",
    description: "Grade school math word problems requiring multi-step reasoning.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://github.com/openai/grade-school-math"
  },
  {
    id: "aime",
    name: "AIME 2024/25",
    category: "Math",
    description: "American Invitational Mathematics Examination. Competition-level math.",
    maxScore: 100,
    higherIsBetter: true
  },
  {
    id: "lmarena-elo",
    name: "LMArena ELO",
    category: "Real-world",
    description: "Chatbot Arena ELO score. Crowd-sourced human preference ranking.",
    maxScore: 1700,
    minScore: 1000,
    higherIsBetter: true,
    normalization: "elo",
    unit: "ELO",
    link: "https://chat.lmsys.org/?leaderboard"
  },
  {
    id: "aa-intelligence-index",
    name: "AA Intelligence Index",
    category: "Real-world",
    description: "Artificial Analysis aggregate intelligence index.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "agentbench",
    name: "AgentBench",
    category: "Agent",
    description: "Comprehensive framework to evaluate LLMs as agents across diverse environments.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://github.com/THUDM/AgentBench"
  },
  // --- SCIENCE ---
  {
    id: "mmlu-pro",
    name: "MMLU-Pro",
    category: "Science",
    description: "A more robust and harder version of MMLU, focusing on complex reasoning and STEM subjects.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "hle",
    name: "HLE",
    category: "Science",
    description: "Humanity's Last Exam - Hard reasoning benchmark without tools.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "hle-full",
    name: "HLE-Full",
    category: "Science",
    description: "Humanity's Last Exam full evaluation without tools.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "hle-full-tools",
    name: "HLE-Full (w/ tools)",
    category: "Science",
    description: "Humanity's Last Exam full evaluation with tool access enabled.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "critpt",
    name: "CritPt",
    category: "Science",
    description: "Complex Research using Integrated Thinking - Physics Test. Research-level physics reasoning.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://arxiv.org/abs/2501.00663"
  },
  {
    id: "simpleqa",
    name: "SimpleQA",
    category: "Science",
    description: "Open-domain factuality benchmark focusing on short, verifiable answers.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "simpleqa-verified",
    name: "SimpleQA Verified",
    category: "Knowledge",
    description: "Verified subset of SimpleQA for parametric knowledge evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "healthbench",
    name: "HealthBench",
    category: "Science",
    description: "Medical knowledge and diagnostic reasoning evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "supergpqa",
    name: "SuperGPQA",
    category: "Science",
    description: "Extremely difficult expert-level science questions.",
    maxScore: 100,
    higherIsBetter: true,
  },
  // --- MATH ---
  {
    id: "aime-2026",
    name: "AIME 2026",
    category: "Math",
    description: "Future prediction of AIME performance levels.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "aa-math-index",
    name: "AA Math Index",
    category: "Math",
    description: "Artificial Analysis aggregate math capability index.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "hmmt-feb-2025",
    name: "HMMT Feb 2025",
    category: "Math",
    description: "Harvard-MIT Mathematics Tournament - High difficulty competition math.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "math-500",
    name: "MATH-500",
    category: "Math",
    description: "500-problem math benchmark for broad quantitative reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "imo-answerbench",
    name: "IMO-AnswerBench",
    category: "Math",
    description: "International Mathematical Olympiad style answer-only benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "matharena-apex",
    name: "MathArenaApex",
    category: "Math",
    description: "Competitive math arena for top-tier reasoning models.",
    maxScore: 100,
    higherIsBetter: true,
  },
  // --- CODE ---
  {
    id: "codeforces",
    name: "Codeforces",
    category: "Coding",
    description: "Competitive programming rating based on problem solving.",
    maxScore: 4000,
    higherIsBetter: true,
    normalization: "max",
    unit: "rating",
  },
  {
    id: "livecodebench-v6",
    name: "LiveCodeBench v6",
    category: "Coding",
    description: "Contamination-free coding benchmark using recent problems.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "livecodebench-pro",
    name: "LiveCodeBench Pro",
    category: "Coding",
    description: "Competitive programming problems from Codeforces, ICPC, and IOI with Elo rating.",
    maxScore: 4000,
    higherIsBetter: true,
    normalization: "max",
    unit: "Elo",
  },
  {
    id: "aa-coding-index",
    name: "AA Coding Index",
    category: "Coding",
    description: "Artificial Analysis aggregate coding capability index.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "paperbench-codedev",
    name: "PaperBench (CodeDev)",
    category: "Coding",
    description: "Research-grade coding and software development tasks.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "cybergym",
    name: "CyberGym",
    category: "Coding",
    description: "Cybersecurity-flavored coding benchmark in simulated environments.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "ojbench-cpp",
    name: "OJBench (cpp)",
    category: "Coding",
    description: "Online-judge competitive coding benchmark focused on C++ tasks.",
    maxScore: 100,
    higherIsBetter: true,
  },
  // --- STEM ---
  {
    id: "gpqa-diamond",
    name: "GPQA Diamond",
    category: "STEM",
    description: "Graduate-Level Google-Proof Q&A Benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "phybench",
    name: "Phybench",
    category: "STEM",
    description: "Physics reasoning and problem solving benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  // --- REASONING ---
  {
    id: "arc-agi-1",
    name: "ARC-AGI-1",
    category: "Reasoning",
    description: "Abstraction and Reasoning Corpus - Level 1.",
    maxScore: 100,
    higherIsBetter: true,
  },
  // --- LONG CONTEXT ---
  {
    id: "mrcr-v2",
    name: "MRCR v2",
    category: "Long Context",
    description: "Multi-Round Context Retrieval - 8-needle test.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "longbench-v2",
    name: "LongBench v2",
    category: "Long Context",
    description: "Comprehensive long-context understanding (128k).",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "lcr",
    name: "AA-LCR",
    category: "Long Context",
    description: "Artificial Analysis Long Context Reasoning benchmark. Evaluates reasoning over long contexts.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://artificialanalysis.ai/evaluations/lcr"
  },
  // --- MULTILINGUAL ---
  {
    id: "mmmlu",
    name: "MMMLU",
    category: "Multilingual",
    description: "Massive Multilingual Language Understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "ifeval",
    name: "IFEval",
    category: "Instruction Following",
    description: "Instruction Following Evaluation for Large Language Models. Measures ability to follow strict formatting and constraint requirements.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://arxiv.org/abs/2311.07911"
  },
  // --- INSTRUCTION FOLLOWING ---
  {
    id: "ifeval-inverse",
    name: "Inverse IFEval",
    category: "Instruction Following",
    description: "Reverse instruction following evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "ifbench",
    name: "IFBench",
    category: "Instruction Following",
    description: "Artificial Analysis IFBench. Evaluates precise instruction following with constraints.",
    maxScore: 100,
    higherIsBetter: true,
    link: "https://artificialanalysis.ai/evaluations/ifbench"
  },
  {
    id: "verified-advancedif",
    name: "Verified AdvancedIF",
    category: "Instruction Following",
    description: "Advanced instruction-following benchmark with verified grading.",
    maxScore: 100,
    higherIsBetter: true,
  },
  // --- HALLUCINATION ---
  {
    id: "longfact-concepts",
    name: "LongFact-Concepts",
    category: "Hallucination",
    description: "Factuality in long-form conceptual generations.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "aa-omniscience",
    name: "AA-Omniscience",
    category: "Hallucination",
    description: "Evaluates model omniscience and factual reliability across diverse domains.",
    maxScore: 100,
    minScore: -100,
    higherIsBetter: true,
    link: "https://artificialanalysis.ai/evaluations/omniscience"
  },
  {
    id: "aime-2025",
    name: "AIME 2025",
    category: "Math",
    description: "American Invitational Mathematics Examination 2025 problems.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "arc-agi-2",
    name: "ARC-AGI-2",
    category: "Reasoning",
    description: "Abstraction and Reasoning Corpus - Level 2 (Extreme difficulty).",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "factscore",
    name: "FactScore",
    category: "Hallucination",
    description: "Precision of fine-grained facts in long-form biographies.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "superchem",
    name: "Superchem",
    category: "STEM",
    description: "Expert-level chemistry knowledge and reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "korbench",
    name: "KORBench",
    category: "Reasoning",
    description: "Korean reasoning and language understanding benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "graphwalks-bfs",
    name: "Graphwalks Bfs",
    category: "Long Context",
    description: "Traversal-based long context reasoning using BFS (128k).",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "global-piqa",
    name: "Global PIQA",
    category: "Multilingual",
    description: "Physical Interaction QA across multiple languages and cultures.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "multichallenge",
    name: "MultiChallenge",
    category: "Instruction Following",
    description: "Complex, multi-constraint instruction following tasks.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "longfact-objects",
    name: "LongFact-Objects",
    category: "Hallucination",
    description: "Factuality in long-form generations about objects.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "putnam-200",
    name: "Putnam-200",
    category: "Math",
    description: "William Lowell Putnam Mathematical Competition problems - top 200 level difficulty.",
    maxScore: 100,
    higherIsBetter: true,
  },
  // --- VISION ---
  {
    id: "mathvista",
    name: "MathVista",
    category: "Vision",
    description: "Mathematical reasoning in visual contexts.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mathvista-mini",
    name: "MathVista (mini)",
    category: "Vision",
    description: "Compact MathVista split for faster multimodal reasoning checks.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mathvision",
    name: "MathVision",
    category: "Vision",
    description: "Comprehensive mathematical vision benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mmmu-vision",
    name: "MMMU",
    category: "Vision",
    description: "Massive Multi-discipline Multimodal Understanding and Reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "logicvista",
    name: "LogicVista",
    category: "Vision",
    description: "Logical reasoning in visual puzzles and diagrams.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "blink",
    name: "BLINK",
    category: "Vision",
    description: "Spatial and perception benchmark for multimodal models.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mmvp",
    name: "MMVP",
    category: "Vision",
    description: "Multimodal visual perception benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "chartqapro",
    name: "ChartQA Pro",
    category: "Vision",
    description: "Expert-level chart understanding and question answering.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "docvqa",
    name: "DocVQA",
    category: "Vision",
    description: "Document visual question answering on scanned and digital documents.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "ocrbench-v2",
    name: "OCRBench v2",
    category: "Vision",
    description: "Next-gen optical character recognition and document understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "ocrbench",
    name: "OCRBench",
    category: "Vision",
    description: "Optical character recognition and document understanding benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "dynamath",
    name: "DynaMath",
    category: "Vision",
    description: "Dynamic mathematical reasoning in visual contexts.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mathkangaroo",
    name: "MathKangaroo",
    category: "Vision",
    description: "Mathematical competition problems with visual elements.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mathcanvas",
    name: "MathCanvas",
    category: "Vision",
    description: "Multi-step mathematical reasoning on a canvas.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mmmu-pro",
    name: "MMMU-Pro",
    category: "Vision",
    description: "Professional level MMMU expansion.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mmmu-val",
    name: "MMMU (val)",
    category: "Vision",
    description: "Validation split of MMMU for multimodal understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "emma",
    name: "EMMA",
    category: "Vision",
    description: "Expert-level Multimodal Mathematics Analysis.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "sfe",
    name: "SFE",
    category: "Vision",
    description: "Scientific Figure Evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "hipho",
    name: "HiPhO",
    category: "Vision",
    description: "High-level Physics Olympiad (Vision).",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "xlrs-bench",
    name: "XLRS-Bench",
    category: "Vision",
    description: "Cross-domain Logical Reasoning and Spatial benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "phyx",
    name: "PhyX",
    category: "Vision",
    description: "Physics reasoning with open-ended visual questions.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "vpct",
    name: "VPCT",
    category: "Vision",
    description: "Visual Perception and Coding Tasks.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "zerobench-main",
    name: "ZeroBench (main)",
    category: "Vision",
    description: "Zero-shot visual reasoning benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "zerobench-sub",
    name: "ZeroBench (sub)",
    category: "Vision",
    description: "Zero-shot visual reasoning sub-tasks.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "zerobench",
    name: "ZeroBench",
    category: "Vision",
    description: "Aggregate ZeroBench score across the full task set.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "zerobench-tools",
    name: "ZeroBench (w/ tools)",
    category: "Vision",
    description: "ZeroBench score when tool use is allowed.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "arc-agi-1-image",
    name: "ArcAGI1-Image",
    category: "Vision",
    description: "ARC-AGI Level 1 tasks in image format.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "arc-agi-2-image",
    name: "ArcAGI2-Image",
    category: "Vision",
    description: "ARC-AGI Level 2 tasks in image format.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "visulogic",
    name: "VisuLogic",
    category: "Vision",
    description: "Visual logic and sequence reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "vlms-are-biased",
    name: "VLMsAreBiased",
    category: "Vision",
    description: "Evaluating bias in Vision-Language Models.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "vlms-are-blind",
    name: "VLMsAreBlind",
    category: "Vision",
    description: "Evaluating perception failures in VLMs.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "visfactor",
    name: "VisFactor",
    category: "Vision",
    description: "Visual factor identification and reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "realworldqa",
    name: "RealWorldQA",
    category: "Vision",
    description: "Real-world visual question answering.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "babyvision",
    name: "BabyVision",
    category: "Vision",
    description: "Early-stage visual development benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "hallusionbench",
    name: "HallusionBench",
    category: "Vision",
    description: "Visual hallucination and factuality benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mme-cc",
    name: "MME-CC",
    category: "Vision",
    description: "Multimodal Evaluation (Cognitive Capacity).",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mmstar",
    name: "MMStar",
    category: "Vision",
    description: "Elite multimodal model evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "muirbench",
    name: "MUIRBench",
    category: "Vision",
    description: "Multimodal Understanding and Interaction Benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mtvqa",
    name: "MTVQA",
    category: "Vision",
    description: "Multilingual Text-centric Visual QA.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "worldvqa",
    name: "WorldVQA",
    category: "Vision",
    description: "Global visual knowledge and reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "vibeeval",
    name: "VibeEval",
    category: "Vision",
    description: "Subjective and intuitive visual quality evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "viverbench",
    name: "ViVerBench",
    category: "Vision",
    description: "Visual Verification and reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "countbench",
    name: "CountBench",
    category: "Vision",
    description: "Visual object counting and identification.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "fsc-147",
    name: "FSC-147",
    category: "Vision",
    description: "Few-shot counting benchmark (Lower is better handled in normalization).",
    maxScore: 100,
    higherIsBetter: false,
    normalization: "inverse",
    unit: "error",
  },
  {
    id: "point-bench",
    name: "Point-Bench",
    category: "Vision",
    description: "Visual pointing and spatial grounding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mmsibench",
    name: "MMSIBench",
    category: "Vision",
    description: "Multimodal Spatial Interaction Benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "treebench",
    name: "TreeBench",
    category: "Vision",
    description: "Hierarchical visual reasoning tasks.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "refspatialbench",
    name: "RefSpatialBench",
    category: "Vision",
    description: "Referential spatial reasoning evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "da-2k",
    name: "DA-2K",
    category: "Vision",
    description: "Document Analysis and reasoning (2k).",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "all-angles",
    name: "All-Angles",
    category: "Vision",
    description: "Multi-perspective visual understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "erqa",
    name: "ERQA",
    category: "Vision",
    description: "Environment Reasoning and Question Answering.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "omnidocbench",
    name: "OmniDocBench",
    category: "Vision",
    description: "Universal document understanding benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "omnidocbench-15",
    name: "OmniDocBench 1.5",
    category: "Vision",
    description: "OCR benchmark measuring edit distance (lower is better).",
    maxScore: 1,
    minScore: 0,
    higherIsBetter: false,
    unit: "edit distance",
  },
  {
    id: "screenspot-pro",
    name: "ScreenSpot-Pro",
    category: "Vision",
    description: "Screen understanding benchmark for GUI interaction.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "infovqa-test",
    name: "InfoVQA (test)",
    category: "Vision",
    description: "Information-seeking visual question answering on the test split.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "charxiv-dq",
    name: "CharXiv-DQ",
    category: "Vision",
    description: "Chart-based reasoning from arXiv papers (Data QA).",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "charxiv-rq",
    name: "CharXiv-RQ",
    category: "Vision",
    description: "Chart-based reasoning from arXiv papers (Reasoning QA).",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "charxiv-reasoning",
    name: "CharXiv Reasoning",
    category: "Vision",
    description: "Information synthesis from complex charts.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "dude",
    name: "DUDE",
    category: "Vision",
    description: "Document Understanding and Dialogue Evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mmlongbench",
    name: "MMLongBench",
    category: "Vision",
    description: "Multimodal Long context benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "longdocurl",
    name: "LongDocURL",
    category: "Vision",
    description: "Long document understanding with URLs.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mmlongbench-doc",
    name: "MMLongBench-Doc",
    category: "Vision",
    description: "Multimodal Long context document evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  // --- VIDEO (Expansion) ---
  {
    id: "mmvu",
    name: "MMVU",
    category: "Video",
    description: "Multimodal Video Understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "videosimpleqa",
    name: "VideoSimpleQA",
    category: "Video",
    description: "Verifiable question answering for short video clips.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "videoreasonbench",
    name: "VideoReasonBench",
    category: "Video",
    description: "Complex reasoning tasks in video content.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "morse-500",
    name: "Morse-500",
    category: "Video",
    description: "Sequence reasoning and motion understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "videoholmes",
    name: "VideoHolmes",
    category: "Video",
    description: "Deep diagnostic video understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "minerva",
    name: "Minerva",
    category: "Video",
    description: "Long-form video reasoning and knowledge retrieval.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "contphy",
    name: "ContPhy",
    category: "Video",
    description: "Continuous Physics reasoning in video.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "tempcompass",
    name: "TempCompass",
    category: "Video",
    description: "Temporal orientation and perception in video.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "egotempo",
    name: "EgoTempo",
    category: "Video",
    description: "First-person perspective temporal reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "motionbench",
    name: "MotionBench",
    category: "Video",
    description: "Comprehensive motion perception evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "tomato",
    name: "TOMATO",
    category: "Video",
    description: "Temporal Object-centric Multimodal Analysis.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "cgbench",
    name: "CGBench",
    category: "Video",
    description: "Contextual Grounding in long videos.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "longvideobench",
    name: "LongVideoBench",
    category: "Video",
    description: "Understanding extremely long-form video content.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "videoeval-pro",
    name: "VideoEval-Pro",
    category: "Video",
    description: "Professional level video quality and content evaluation.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "lvbench",
    name: "LVBench",
    category: "Video",
    description: "Large-scale Video Benchmark.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "crossvid",
    name: "CrossVid",
    category: "Video",
    description: "Cross-video temporal and relational reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "livesports-3k",
    name: "LiveSports-3K",
    category: "Video",
    description: "Live sports broadcast understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "ovobench",
    name: "OVOBench",
    category: "Video",
    description: "Object-Video-Object relational reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "odvbench",
    name: "ODVBench",
    category: "Video",
    description: "Open-Domain Video understanding.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "vispeak",
    name: "ViSpeak",
    category: "Video",
    description: "Video-to-speech and dialogue reasoning.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "frontiersci-olympiad",
    name: "FrontierSci-olympiad",
    category: "STEM",
    description: "Scientific Olympiad level problems.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  // --- AGENTIC ---
  {
    id: "terminal-bench",
    name: "Terminal-Bench 2.0",
    category: "Agentic",
    description: "Agent performance in realistic terminal workflows (v2.0 leaderboard).",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "terminal-bench-hard",
    name: "Terminal-Bench Hard",
    category: "Agentic",
    description: "Hard split of Terminal-Bench focused on tougher terminal workflows.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "osworld-verified",
    name: "OSWorld-Verified",
    category: "Agentic",
    description: "Verified desktop computer-use benchmark for end-to-end task completion.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "webarena",
    name: "WebArena",
    category: "Agentic",
    description: "Browser-based autonomous task execution benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "swe-lancer",
    name: "SWE-Lancer",
    category: "Agentic",
    description: "Software engineering task completion in multi-step coding workflows.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "multi-swe-bench",
    name: "Multi-SWE-bench",
    category: "Agentic",
    description: "Multi-repository software engineering benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "swe-bench-pro",
    name: "SWE-bench Pro",
    category: "Agentic",
    description: "Higher-difficulty SWE-bench subset for frontier coding agents.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "swe-multilingual",
    name: "SWE Multilingual",
    category: "Agentic",
    description: "Software engineering performance across multilingual codebases.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "swe-evo",
    name: "SWE-Evo",
    category: "Agentic",
    description: "Evolutionary coding benchmark focused on long-horizon bug fixing.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "aider-polyglot",
    name: "Aider Polyglot",
    category: "Agentic",
    description: "Multi-language coding agent benchmark with editor-in-the-loop tasks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "artifactsbench",
    name: "ArtifactsBench",
    category: "Agentic",
    description: "Agent ability to produce complete, runnable software artifacts.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "codesimpleqa",
    name: "CodeSimpleQA",
    category: "Agentic",
    description: "Short-form coding QA with executable correctness checks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "spreadsheetbench-verified",
    name: "SpreadsheetBench Verified",
    category: "Agentic",
    description: "Verified spreadsheet manipulation and reasoning tasks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "browsecomp",
    name: "BrowseComp",
    category: "Agentic",
    description: "Web browsing + synthesis benchmark for research agents.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "browsecomp-ctx-manage",
    name: "BrowseComp (ctx manage)",
    category: "Agentic",
    description: "BrowseComp variant with explicit context-window management.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "browsecomp-agent-swarm",
    name: "BrowseComp (Agent Swarm)",
    category: "Agentic",
    description: "Multi-agent swarm variant of BrowseComp.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "browsecomp-zh",
    name: "BrowseComp-ZH",
    category: "Agentic",
    description: "Chinese-language browsing and synthesis benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "hle-text",
    name: "HLE-Text",
    category: "Agentic",
    description: "Text-only variant of Humanity's Last Exam under agentic settings.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "hle-verified",
    name: "HLE-Verified",
    category: "Agentic",
    description: "Verified subset of Humanity's Last Exam for reproducible evaluation.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "widesearch",
    name: "WideSearch",
    category: "Agentic",
    description: "Broad retrieval and synthesis benchmark across many sources.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "widesearch-agent-swarm",
    name: "WideSearch (Agent Swarm)",
    category: "Agentic",
    description: "Multi-agent swarm variant of WideSearch.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "finsearchcomp",
    name: "FinSearchComp",
    category: "Agentic",
    description: "Finance-focused search and evidence-grounded answering benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "finsearchcomp-t2-t3",
    name: "FinSearchComp T2&T3",
    category: "Agentic",
    description: "Tier 2 and Tier 3 slices of FinSearchComp.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "vending-bench-2",
    name: "Vending-Bench 2",
    category: "Agentic",
    description: "Long-horizon business simulation benchmark (final account balance).",
    maxScore: 10000,
    minScore: 0,
    higherIsBetter: true,
    normalization: "max",
    unit: "USD",
  },
  {
    id: "facts-benchmark",
    name: "FACTS Benchmark Suite",
    category: "Agentic",
    description: "Factuality benchmark across grounding, parametric, search, and multimodal.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "mcp-atlas",
    name: "MCP Atlas",
    category: "Agentic",
    description: "Multi-step workflows using Model Context Protocol.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "toolathlon",
    name: "Toolathlon",
    category: "Agentic",
    description: "Long horizon real-world software tasks.",
    maxScore: 100,
    higherIsBetter: true,
  },
  {
    id: "deepsearchqa",
    name: "DeepSearchQA",
    category: "Agentic",
    description: "Deep multi-hop search QA for long-horizon agents.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "seal-0",
    name: "SEAL-0",
    category: "Agentic",
    description: "Strategic environment-agent loop benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "gdpval-aa",
    name: "GDPVal-AA",
    category: "Agentic",
    description: "Artificial Analysis GDPVal benchmark for knowledge-work quality.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tau-bench",
    name: "TAU-Bench",
    category: "Agentic",
    description: "Tool-use and API orchestration benchmark for assistants.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tau-bench-retail",
    name: "TAU-Bench Retail",
    category: "Agentic",
    description: "Retail-domain tool-use and workflow benchmark from τ²-bench.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tau-bench-telecom",
    name: "TAU-Bench Telecom",
    category: "Agentic",
    description: "Telecom-domain tool-use and workflow benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "mcp-mark",
    name: "MCP-Mark",
    category: "Agentic",
    description: "Model Context Protocol interoperability benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "bfcl-v4",
    name: "BFCL v4",
    category: "Agentic",
    description: "Function calling reliability benchmark (v4).",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "vitabench",
    name: "VitaBench",
    category: "Agentic",
    description: "Virtual task assistant benchmark across practical workflows.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "deepconsult",
    name: "DeepConsult",
    category: "Agentic",
    description: "Consulting-style multi-step reasoning and recommendation benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "deepresearchbench",
    name: "DeepResearchBench",
    category: "Agentic",
    description: "Long-horizon research task benchmark with citation requirements.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "researchrubrics",
    name: "ResearchRubrics",
    category: "Agentic",
    description: "Rubric-based evaluation of research quality and rigor.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "minedojo-verified",
    name: "MineDojo Verified",
    category: "Agentic",
    description: "Verified embodied-agent benchmark in Minecraft-style tasks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "mm-browsecomp",
    name: "MM-BrowseComp",
    category: "Agentic",
    description: "Multimodal browse + synthesize benchmark for web agents.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "hle-vl",
    name: "HLE-VL",
    category: "Agentic",
    description: "Vision-language variant of Humanity's Last Exam under agentic settings.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  // --- ADVANCED TASKS ---
  {
    id: "scicode",
    name: "SciCode",
    category: "Advanced Tasks",
    description: "Scientific programming benchmark for code synthesis and correctness.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "frontiersci-research",
    name: "FrontierSci Research",
    category: "Advanced Tasks",
    description: "Open-ended scientific research benchmark with expert-level questions.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "biobench",
    name: "BioBench",
    category: "Advanced Tasks",
    description: "Biology and life-science benchmark requiring deep domain reasoning.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "ainstein-bench",
    name: "AInstein-Bench",
    category: "Advanced Tasks",
    description: "Hard scientific reasoning benchmark inspired by olympiad-level tasks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "vibe-coding",
    name: "Vibe Coding",
    category: "Advanced Tasks",
    description: "High-level coding outcome quality benchmark for agent-driven development.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "nl2repo-bench",
    name: "NL2Repo-Bench",
    category: "Advanced Tasks",
    description: "Natural language to repository-wide code edits benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "nl2repo-pass1",
    name: "NL2Repo Pass@1",
    category: "Advanced Tasks",
    description: "Pass@1 metric for repository-scale code modification tasks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "cl-bench",
    name: "CL-Bench",
    category: "Advanced Tasks",
    description: "Complex language benchmark covering difficult enterprise workflows.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tob-complex",
    name: "TOB Complex",
    category: "Advanced Tasks",
    description: "Task-oriented benchmark for complex instruction execution.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tob-reference",
    name: "TOB Reference",
    category: "Advanced Tasks",
    description: "Reference-heavy task-oriented benchmark requiring retrieval fidelity.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "healthbench-hard",
    name: "HealthBench Hard",
    category: "Advanced Tasks",
    description: "Hard-split medical reasoning benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "gdpval-diamond",
    name: "GDPVal Diamond",
    category: "Advanced Tasks",
    description: "Diamond subset for difficult planning and valuation tasks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "xpert-bench",
    name: "Xpert-Bench",
    category: "Advanced Tasks",
    description: "Expert-level evaluation benchmark across specialist domains.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tob-k12",
    name: "TOB K12",
    category: "Advanced Tasks",
    description: "Task-oriented benchmark for K12 educational tasks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tob-compositional",
    name: "TOB Compositional",
    category: "Advanced Tasks",
    description: "Compositional instruction-following benchmark with chained constraints.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tob-classification",
    name: "TOB Classification",
    category: "Advanced Tasks",
    description: "Classification-focused track of task-oriented benchmark suite.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tob-extraction",
    name: "TOB Extraction",
    category: "Advanced Tasks",
    description: "Extraction-focused benchmark for structured information tasks.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "world-travel-vlm",
    name: "World-Travel VLM",
    category: "Advanced Tasks",
    description: "Vision-language travel-planning and grounded reasoning benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "world-travel-text",
    name: "World-Travel Text",
    category: "Advanced Tasks",
    description: "Text-only travel-planning and itinerary reasoning benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  // --- VISION / VIDEO SUPPLEMENTS ---
  {
    id: "simplevqa",
    name: "SimpleVQA",
    category: "Vision",
    description: "Short-form visual question answering with verifiable responses.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "videommmu",
    name: "VideoMMMU",
    category: "Video",
    description: "Video variant of MMMU for multimodal understanding and reasoning.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "videomme",
    name: "VideoMME",
    category: "Video",
    description: "Video multimodal evaluation benchmark for perception and reasoning.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "tvbench",
    name: "TVBench",
    category: "Video",
    description: "Television/video narrative understanding benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  },
  {
    id: "ovbench",
    name: "OVBench",
    category: "Video",
    description: "Open-world video understanding benchmark.",
    maxScore: 100,
    higherIsBetter: true,
    normalization: "max",
    unit: "%",
  }
];

export const benchmarks: Benchmark[] = rawBenchmarks.map((benchmark) => ({
  ...benchmark,
  normalization:
    benchmark.normalization ??
    (benchmark.id === "lmarena-elo" ? "elo" : benchmark.higherIsBetter ? "max" : "inverse"),
  unit: benchmark.unit ?? (benchmark.id === "lmarena-elo" ? "ELO" : "%"),
  link: getBenchmarkLink(benchmark),
}));
