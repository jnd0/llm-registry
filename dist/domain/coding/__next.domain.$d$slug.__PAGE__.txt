1:"$Sreact.fragment"
2:I[22016,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js","/_next/static/chunks/d2af07b8dd42c1ce.js"],""]
f:I[86831,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js","/_next/static/chunks/d2af07b8dd42c1ce.js"],"BenchmarkExpandableList"]
10:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"OutletBoundary"]
11:"$Sreact.suspense"
0:{"buildId":"ndSWmh2LFKxVirkTwO1tD","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"space-y-4","children":[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Leaderboard\",\"item\":\"https://llm-registry.com/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Domains\",\"item\":\"https://llm-registry.com/benchmarks\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"Coding\",\"item\":\"https://llm-registry.com/domain/coding\"}]}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"CollectionPage\",\"name\":\"Coding benchmarks and rankings\",\"description\":\"Tests programming proficiency across multiple languages, software engineering tasks, debugging capabilities, and real-world coding scenarios. Includes HumanEval, MBPP, SWE-bench, and competitive programming benchmarks.\",\"url\":\"https://llm-registry.com/domain/coding\",\"isPartOf\":{\"@type\":\"WebSite\",\"name\":\"LLM Registry\",\"url\":\"https://llm-registry.com\"}}"}}],["$","nav",null,{"className":"hidden sm:flex items-center gap-1 text-xs text-muted-foreground","children":[["$","$L2",null,{"href":"/","className":"hover:text-foreground transition-colors","children":"Leaderboard"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-chevron-right h-3 w-3","aria-hidden":"true","children":[["$","path","mthhwq",{"d":"m9 18 6-6-6-6"}],"$undefined"]}],["$","span",null,{"className":"text-foreground font-medium","children":"Coding"}]]}],["$","div",null,{"children":[["$","h1",null,{"className":"font-display text-2xl font-bold tracking-tight text-foreground","children":"Coding"}],["$","p",null,{"className":"mt-2 text-sm text-muted-foreground max-w-2xl","children":"Tests programming proficiency across multiple languages, software engineering tasks, debugging capabilities, and real-world coding scenarios. Includes HumanEval, MBPP, SWE-bench, and competitive programming benchmarks."}]]}],["$","div",null,{"className":"grid gap-4 lg:grid-cols-3","children":[["$","div",null,{"className":"lg:col-span-2 space-y-4","children":["$","section",null,{"className":"surface-card rounded-xl border border-border/40 p-4","children":[["$","h2",null,{"className":"font-mono text-[10px] font-bold uppercase tracking-[0.2em] text-muted-foreground mb-3","children":"Top Models"}],["$","div",null,{"className":"space-y-2","children":[["$","$L2","openai-gpt-5-1",{"href":"/model/openai-gpt-5-1","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-amber-500/20 text-amber-600 dark:text-amber-400","children":1}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"GPT-5.1"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"98.2"}]]}]]}],["$","$L2","o1-mini",{"href":"/model/o1-mini","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-slate-400/20 text-slate-600 dark:text-slate-300","children":2}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"o1-mini"}]]}],"$L3"]}],"$L4","$L5","$L6","$L7","$L8","$L9","$La","$Lb"]}]]}]}],"$Lc"]}]]}],["$Ld"],"$Le"]}],"loading":null,"isPartial":false}
3:["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"92.4"}]]}]
4:["$","$L2","mistral-large-2",{"href":"/model/mistral-large-2","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-orange-700/20 text-orange-700 dark:text-orange-400","children":3}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Mistral Large 2"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"92.0"}]]}]]}]
5:["$","$L2","meta-llama-3-1-405b",{"href":"/model/meta-llama-3-1-405b","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":4}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Llama 3.1 405B"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"89.0"}]]}]]}]
6:["$","$L2","meta-llama-3-3-70b",{"href":"/model/meta-llama-3-3-70b","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":5}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Llama 3.3 70B"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"89.0"}]]}]]}]
7:["$","$L2","claude-3-5-haiku",{"href":"/model/claude-3-5-haiku","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":6}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Claude 3.5 Haiku"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"88.1"}]]}]]}]
8:["$","$L2","gpt-5-2-pro",{"href":"/model/gpt-5-2-pro","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":7}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"GPT-5.2 Pro"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",2]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"87.5"}]]}]]}]
9:["$","$L2","baichuan-m3",{"href":"/model/baichuan-m3","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":8}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Baichuan-M3"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"86.0"}]]}]]}]
a:["$","$L2","openai-gpt-5-3-codex",{"href":"/model/openai-gpt-5-3-codex","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":9}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"GPT-5.3 Codex"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",2]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"85.5"}]]}]]}]
b:["$","$L2","seed-2-0-pro",{"href":"/model/seed-2-0-pro","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":10}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Seed2.0 Pro"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",2]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"85.5"}]]}]]}]
c:["$","div",null,{"className":"space-y-4","children":[["$","section",null,{"className":"surface-card rounded-xl border border-border/40 p-4","children":[["$","h2",null,{"className":"font-mono text-[10px] font-bold uppercase tracking-[0.2em] text-muted-foreground mb-3","children":"Domain Info"}],["$","dl",null,{"className":"space-y-2.5 text-sm","children":[["$","div",null,{"className":"flex justify-between","children":[["$","dt",null,{"className":"text-muted-foreground","children":"Benchmarks"}],["$","dd",null,{"className":"font-mono text-foreground","children":10}]]}],["$","div",null,{"className":"flex justify-between","children":[["$","dt",null,{"className":"text-muted-foreground","children":"Models Evaluated"}],["$","dd",null,{"className":"font-mono text-foreground","children":67}]]}],["$","div",null,{"className":"flex justify-between","children":[["$","dt",null,{"className":"text-muted-foreground","children":"Categories"}],["$","dd",null,{"className":"text-foreground","children":"Coding"}]]}]]}]]}],["$","section",null,{"className":"surface-card rounded-xl border border-border/40 p-4","children":[["$","h2",null,{"className":"font-mono text-[10px] font-bold uppercase tracking-[0.2em] text-muted-foreground mb-3","children":"Benchmarks"}],["$","$Lf",null,{"benchmarks":[{"id":"human-eval","name":"HumanEval","category":"Coding","description":"Functional correctness of synthesized programs from docstrings.","maxScore":100,"higherIsBetter":true,"link":"https://paperswithcode.com/sota/code-generation-on-humaneval","paperUrl":"https://arxiv.org/abs/2107.03374","normalization":"max","unit":"%"},{"id":"swe-bench-verified","name":"SWE-bench Verified","category":"Coding","description":"Resolving real-world GitHub issues. Verified subset ensures solvable issues.","maxScore":100,"higherIsBetter":true,"link":"https://www.swebench.com/","paperUrl":"https://arxiv.org/abs/2310.06770","normalization":"max","unit":"%"},{"id":"bigcodebench","name":"BigCodeBench","category":"Coding","description":"Next-generation HumanEval with more diverse library calls and complex tasks.","maxScore":100,"higherIsBetter":true,"link":"https://github.com/bigcode-project/bigcodebench","paperUrl":"https://arxiv.org/abs/2406.15877","normalization":"max","unit":"%"},{"id":"codeforces","name":"Codeforces","category":"Coding","description":"Competitive programming rating based on problem solving.","maxScore":4000,"higherIsBetter":true,"normalization":"max","unit":"rating","link":"https://codeforces.com/"},{"id":"livecodebench-v6","name":"LiveCodeBench v6","category":"Coding","description":"Contamination-free coding benchmark using recent problems.","maxScore":100,"higherIsBetter":true,"link":"https://livecodebench.github.io/","paperUrl":"https://arxiv.org/abs/2403.07974","normalization":"max","unit":"%"},{"id":"livecodebench-pro","name":"LiveCodeBench Pro","category":"Coding","description":"Competitive programming problems from Codeforces, ICPC, and IOI with Elo rating.","maxScore":4000,"higherIsBetter":true,"normalization":"max","unit":"Elo","link":"https://livecodebenchpro.com/"},{"id":"aa-coding-index","name":"AA Coding Index","category":"Coding","description":"Artificial Analysis aggregate coding capability index.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aa-coding-index"},{"id":"paperbench-codedev","name":"PaperBench (CodeDev)","category":"Coding","description":"Research-grade coding and software development tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#paperbench-codedev"},{"id":"cybergym","name":"CyberGym","category":"Coding","description":"Cybersecurity-flavored coding benchmark in simulated environments.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#cybergym"},{"id":"ojbench-cpp","name":"OJBench (cpp)","category":"Coding","description":"Online-judge competitive coding benchmark focused on C++ tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ojbench-cpp"}]}]]}]]}]
d:["$","script","script-0",{"src":"/_next/static/chunks/d2af07b8dd42c1ce.js","async":true}]
e:["$","$L10",null,{"children":["$","$11",null,{"name":"Next.MetadataOutlet","children":"$@12"}]}]
12:null
