1:"$Sreact.fragment"
2:I[22016,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js","/_next/static/chunks/d2af07b8dd42c1ce.js"],""]
10:I[86831,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js","/_next/static/chunks/d2af07b8dd42c1ce.js"],"BenchmarkExpandableList"]
11:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"OutletBoundary"]
12:"$Sreact.suspense"
0:{"buildId":"ndSWmh2LFKxVirkTwO1tD","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"space-y-4","children":[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Leaderboard\",\"item\":\"https://llm-registry.com/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Domains\",\"item\":\"https://llm-registry.com/benchmarks\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"Intelligence\",\"item\":\"https://llm-registry.com/domain/intelligence\"}]}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"CollectionPage\",\"name\":\"Intelligence benchmarks and rankings\",\"description\":\"Measures advanced cognitive capabilities including logical reasoning, scientific knowledge, multi-step problem solving, and the ability to tackle novel challenges. Includes benchmarks for GPQA, ARC-AGI, and other frontier reasoning tasks.\",\"url\":\"https://llm-registry.com/domain/intelligence\",\"isPartOf\":{\"@type\":\"WebSite\",\"name\":\"LLM Registry\",\"url\":\"https://llm-registry.com\"}}"}}],["$","nav",null,{"className":"hidden sm:flex items-center gap-1 text-xs text-muted-foreground","children":[["$","$L2",null,{"href":"/","className":"hover:text-foreground transition-colors","children":"Leaderboard"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-chevron-right h-3 w-3","aria-hidden":"true","children":[["$","path","mthhwq",{"d":"m9 18 6-6-6-6"}],"$undefined"]}],["$","span",null,{"className":"text-foreground font-medium","children":"Intelligence"}]]}],["$","div",null,{"children":[["$","h1",null,{"className":"font-display text-2xl font-bold tracking-tight text-foreground","children":"Intelligence"}],["$","p",null,{"className":"mt-2 text-sm text-muted-foreground max-w-2xl","children":"Measures advanced cognitive capabilities including logical reasoning, scientific knowledge, multi-step problem solving, and the ability to tackle novel challenges. Includes benchmarks for GPQA, ARC-AGI, and other frontier reasoning tasks."}]]}],["$","div",null,{"className":"grid gap-4 lg:grid-cols-3","children":[["$","div",null,{"className":"lg:col-span-2 space-y-4","children":["$","section",null,{"className":"surface-card rounded-xl border border-border/40 p-4","children":[["$","h2",null,{"className":"font-mono text-[10px] font-bold uppercase tracking-[0.2em] text-muted-foreground mb-3","children":"Top Models"}],["$","div",null,{"className":"space-y-2","children":[["$","$L2","o3-pro",{"href":"/model/o3-pro","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-amber-500/20 text-amber-600 dark:text-amber-400","children":1}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"o3-pro"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"84.5"}]]}]]}],["$","$L2","gpt-5-mini",{"href":"/model/gpt-5-mini","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-slate-400/20 text-slate-600 dark:text-slate-300","children":2}],"$L3"]}],"$L4"]}],"$L5","$L6","$L7","$L8","$L9","$La","$Lb","$Lc"]}]]}]}],"$Ld"]}]]}],["$Le"],"$Lf"]}],"loading":null,"isPartial":false}
3:["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"GPT-5-mini"}]
4:["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",2]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"79.9"}]]}]
5:["$","$L2","qwen-3-5-397b-a17b",{"href":"/model/qwen-3-5-397b-a17b","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-orange-700/20 text-orange-700 dark:text-orange-400","children":3}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Qwen 3.5 397B-A17B"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",2]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"79.1"}]]}]]}]
6:["$","$L2","openai-gpt-5-1",{"href":"/model/openai-gpt-5-1","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":4}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"GPT-5.1"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",2]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"78.9"}]]}]]}]
7:["$","$L2","o1-preview",{"href":"/model/o1-preview","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":5}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"o1-preview"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"78.3"}]]}]]}]
8:["$","$L2","o1",{"href":"/model/o1","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":6}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"o1"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"78.0"}]]}]]}]
9:["$","$L2","seed-2-0-pro",{"href":"/model/seed-2-0-pro","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":7}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Seed2.0 Pro"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",5]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"76.2"}]]}]]}]
a:["$","$L2","meta-llama-4-behemoth",{"href":"/model/meta-llama-4-behemoth","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":8}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"Llama 4 Behemoth"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",2]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"76.0"}]]}]]}]
b:["$","$L2","openai-gpt-5-3-codex",{"href":"/model/openai-gpt-5-3-codex","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":9}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"GPT-5.3 Codex"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",1]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"74.3"}]]}]]}]
c:["$","$L2","gpt-5-2-pro",{"href":"/model/gpt-5-2-pro","className":"flex items-center justify-between gap-4 p-2 rounded-lg hover:bg-muted/30 transition-colors group","children":[["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"flex h-5 w-5 items-center justify-center rounded text-[10px] font-bold bg-muted text-muted-foreground","children":10}],["$","span",null,{"className":"font-medium text-foreground group-hover:text-primary transition-colors","children":"GPT-5.2 Pro"}]]}],["$","div",null,{"className":"flex items-center gap-3","children":[["$","span",null,{"className":"text-xs text-muted-foreground font-mono","children":["n=",5]}],["$","span",null,{"className":"font-mono text-sm font-bold text-foreground","children":"74.2"}]]}]]}]
d:["$","div",null,{"className":"space-y-4","children":[["$","section",null,{"className":"surface-card rounded-xl border border-border/40 p-4","children":[["$","h2",null,{"className":"font-mono text-[10px] font-bold uppercase tracking-[0.2em] text-muted-foreground mb-3","children":"Domain Info"}],["$","dl",null,{"className":"space-y-2.5 text-sm","children":[["$","div",null,{"className":"flex justify-between","children":[["$","dt",null,{"className":"text-muted-foreground","children":"Benchmarks"}],["$","dd",null,{"className":"font-mono text-foreground","children":35}]]}],["$","div",null,{"className":"flex justify-between","children":[["$","dt",null,{"className":"text-muted-foreground","children":"Models Evaluated"}],["$","dd",null,{"className":"font-mono text-foreground","children":69}]]}],["$","div",null,{"className":"flex justify-between","children":[["$","dt",null,{"className":"text-muted-foreground","children":"Categories"}],["$","dd",null,{"className":"text-foreground","children":"Reasoning, Science, STEM, Advanced Tasks"}]]}]]}]]}],["$","section",null,{"className":"surface-card rounded-xl border border-border/40 p-4","children":[["$","h2",null,{"className":"font-mono text-[10px] font-bold uppercase tracking-[0.2em] text-muted-foreground mb-3","children":"Benchmarks"}],["$","$L10",null,{"benchmarks":[{"id":"livebench","name":"LiveBench","category":"Reasoning","description":"Contamination-free, continuously updated reasoning benchmark.","maxScore":100,"higherIsBetter":true,"link":"https://livebench.ai/#/","paperUrl":"https://arxiv.org/abs/2406.19314","normalization":"max","unit":"%"},{"id":"mmlu-pro","name":"MMLU-Pro","category":"Science","description":"A more robust and harder version of MMLU, focusing on complex reasoning and STEM subjects.","maxScore":100,"higherIsBetter":true,"link":"https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro","paperUrl":"https://arxiv.org/abs/2406.01574","normalization":"max","unit":"%"},{"id":"hle","name":"HLE","category":"Science","description":"Humanity's Last Exam - Hard reasoning benchmark without tools.","maxScore":100,"higherIsBetter":true,"link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249","normalization":"max","unit":"%"},{"id":"hle-full","name":"HLE-Full","category":"Science","description":"Humanity's Last Exam full evaluation without tools.","maxScore":100,"higherIsBetter":true,"link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249","normalization":"max","unit":"%"},{"id":"hle-full-tools","name":"HLE-Full (w/ tools)","category":"Science","description":"Humanity's Last Exam full evaluation with tool access enabled.","maxScore":100,"higherIsBetter":true,"link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249","normalization":"max","unit":"%"},{"id":"critpt","name":"CritPt","category":"Science","description":"Complex Research using Integrated Thinking - Physics Test. Research-level physics reasoning.","maxScore":100,"higherIsBetter":true,"link":"https://arxiv.org/abs/2501.00663","normalization":"max","unit":"%"},{"id":"simpleqa","name":"SimpleQA","category":"Science","description":"Open-domain factuality benchmark focusing on short, verifiable answers.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#simpleqa"},{"id":"healthbench","name":"HealthBench","category":"Science","description":"Medical knowledge and diagnostic reasoning evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#healthbench"},{"id":"supergpqa","name":"SuperGPQA","category":"Science","description":"Extremely difficult expert-level science questions.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#supergpqa"},{"id":"gpqa-diamond","name":"GPQA Diamond","category":"STEM","description":"Graduate-Level Google-Proof Q&A Benchmark.","maxScore":100,"higherIsBetter":true,"link":"https://gpqa-benchmark.github.io/","paperUrl":"https://arxiv.org/abs/2311.12022","normalization":"max","unit":"%"},{"id":"phybench","name":"Phybench","category":"STEM","description":"Physics reasoning and problem solving benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#phybench"},{"id":"arc-agi-1","name":"ARC-AGI-1","category":"Reasoning","description":"Abstraction and Reasoning Corpus - Level 1.","maxScore":100,"higherIsBetter":true,"link":"https://arcprize.org/","paperUrl":"https://arxiv.org/abs/1911.01547","normalization":"max","unit":"%"},{"id":"arc-agi-2","name":"ARC-AGI-2","category":"Reasoning","description":"Abstraction and Reasoning Corpus - Level 2 (Extreme difficulty).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/"},{"id":"superchem","name":"Superchem","category":"STEM","description":"Expert-level chemistry knowledge and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#superchem"},{"id":"korbench","name":"KORBench","category":"Reasoning","description":"Korean reasoning and language understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#korbench"},{"id":"frontiersci-olympiad","name":"FrontierSci-olympiad","category":"STEM","description":"Scientific Olympiad level problems.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#frontiersci-olympiad"},{"id":"scicode","name":"SciCode","category":"Advanced Tasks","description":"Scientific programming benchmark for code synthesis and correctness.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/scicode-bench/scicode"},{"id":"frontiersci-research","name":"FrontierSci Research","category":"Advanced Tasks","description":"Open-ended scientific research benchmark with expert-level questions.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#frontiersci-research"},{"id":"biobench","name":"BioBench","category":"Advanced Tasks","description":"Biology and life-science benchmark requiring deep domain reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#biobench"},{"id":"ainstein-bench","name":"AInstein-Bench","category":"Advanced Tasks","description":"Hard scientific reasoning benchmark inspired by olympiad-level tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ainstein-bench"},{"id":"vibe-coding","name":"Vibe Coding","category":"Advanced Tasks","description":"High-level coding outcome quality benchmark for agent-driven development.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vibe-coding"},{"id":"nl2repo-bench","name":"NL2Repo-Bench","category":"Advanced Tasks","description":"Natural language to repository-wide code edits benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#nl2repo-bench"},{"id":"nl2repo-pass1","name":"NL2Repo Pass@1","category":"Advanced Tasks","description":"Pass@1 metric for repository-scale code modification tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#nl2repo-pass1"},{"id":"cl-bench","name":"CL-Bench","category":"Advanced Tasks","description":"Complex language benchmark covering difficult enterprise workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#cl-bench"},{"id":"tob-complex","name":"TOB Complex","category":"Advanced Tasks","description":"Task-oriented benchmark for complex instruction execution.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-complex"},{"id":"tob-reference","name":"TOB Reference","category":"Advanced Tasks","description":"Reference-heavy task-oriented benchmark requiring retrieval fidelity.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-reference"},{"id":"healthbench-hard","name":"HealthBench Hard","category":"Advanced Tasks","description":"Hard-split medical reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#healthbench-hard"},{"id":"gdpval-diamond","name":"GDPVal Diamond","category":"Advanced Tasks","description":"Diamond subset for difficult planning and valuation tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#gdpval-diamond"},{"id":"xpert-bench","name":"Xpert-Bench","category":"Advanced Tasks","description":"Expert-level evaluation benchmark across specialist domains.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#xpert-bench"},{"id":"tob-k12","name":"TOB K12","category":"Advanced Tasks","description":"Task-oriented benchmark for K12 educational tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-k12"},{"id":"tob-compositional","name":"TOB Compositional","category":"Advanced Tasks","description":"Compositional instruction-following benchmark with chained constraints.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-compositional"},{"id":"tob-classification","name":"TOB Classification","category":"Advanced Tasks","description":"Classification-focused track of task-oriented benchmark suite.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-classification"},{"id":"tob-extraction","name":"TOB Extraction","category":"Advanced Tasks","description":"Extraction-focused benchmark for structured information tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-extraction"},{"id":"world-travel-vlm","name":"World-Travel VLM","category":"Advanced Tasks","description":"Vision-language travel-planning and grounded reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#world-travel-vlm"},{"id":"world-travel-text","name":"World-Travel Text","category":"Advanced Tasks","description":"Text-only travel-planning and itinerary reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#world-travel-text"}]}]]}]]}]
e:["$","script","script-0",{"src":"/_next/static/chunks/d2af07b8dd42c1ce.js","async":true}]
f:["$","$L11",null,{"children":["$","$12",null,{"name":"Next.MetadataOutlet","children":"$@13"}]}]
13:null
