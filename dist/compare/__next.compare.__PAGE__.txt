1:"$Sreact.fragment"
2:"$Sreact.suspense"
3:I[18761,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js","/_next/static/chunks/b721a80a7ed88b57.js"],"CompareView"]
6:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"OutletBoundary"]
0:{"buildId":"ndSWmh2LFKxVirkTwO1tD","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"animate-in fade-in duration-700 space-y-8 pb-16","children":[["$","section",null,{"className":"relative overflow-hidden rounded-2xl border border-border bg-card/50 px-6 py-6 sm:px-10 sm:py-8","children":[["$","div",null,{"className":"pointer-events-none absolute inset-0 bg-[radial-gradient(circle_at_100%_100%,color-mix(in_oklab,var(--primary)_8%,transparent),transparent_50%)]"}],["$","div",null,{"className":"relative max-w-3xl space-y-4","children":[["$","p",null,{"className":"label-eyebrow text-muted-foreground/70","children":"Registry / Benchmarks / Analysis"}],["$","h1",null,{"className":"text-balance font-display text-3xl font-bold tracking-tight text-foreground sm:text-4xl lg:text-5xl","children":"Model Comparison"}],["$","p",null,{"className":"max-w-2xl text-base text-muted-foreground sm:text-lg","children":"Compare up to three foundation models side by side across category averages and benchmark-level performance deltas."}]]}]]}],["$","div",null,{"className":"py-2 sm:py-4","children":["$","$2",null,{"fallback":["$","div",null,{"className":"surface-card rounded-xl px-6 py-10 text-sm font-mono uppercase tracking-widest text-muted-foreground","children":"Loading comparison…"}],"children":["$","$L3",null,{"benchmarks":[{"id":"mmlu","name":"MMLU (5-shot)","category":"Knowledge","description":"Massive Multitask Language Understanding covers 57 subjects across STEM, the humanities, social sciences, and more.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu","paperUrl":"https://arxiv.org/abs/2009.03300"},{"id":"math","name":"MATH (CoT)","category":"Math","description":"Challenging competition mathematics problems (AIME/IMO level).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://paperswithcode.com/sota/math-word-problem-solving-on-math","paperUrl":"https://arxiv.org/abs/2103.03874"},{"id":"human-eval","name":"HumanEval","category":"Coding","description":"Functional correctness of synthesized programs from docstrings.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://paperswithcode.com/sota/code-generation-on-humaneval","paperUrl":"https://arxiv.org/abs/2107.03374"},{"id":"swe-bench-verified","name":"SWE-bench Verified","category":"Coding","description":"Resolving real-world GitHub issues. Verified subset ensures solvable issues.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://www.swebench.com/","paperUrl":"https://arxiv.org/abs/2310.06770"},{"id":"mmmu","name":"MMMU (Multimodal)","category":"Multimodal","description":"Multi-discipline Multimodal Understanding and Reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mmmu-benchmark.github.io/","paperUrl":"https://arxiv.org/abs/2311.16502"},{"id":"livebench","name":"LiveBench","category":"Reasoning","description":"Contamination-free, continuously updated reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://livebench.ai/#/","paperUrl":"https://arxiv.org/abs/2406.19314"},{"id":"bigcodebench","name":"BigCodeBench","category":"Coding","description":"Next-generation HumanEval with more diverse library calls and complex tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/bigcode-project/bigcodebench","paperUrl":"https://arxiv.org/abs/2406.15877"},{"id":"gsm8k","name":"GSM8K","category":"Math","description":"Grade school math word problems requiring multi-step reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/openai/grade-school-math","paperUrl":"https://arxiv.org/abs/2110.14168"},{"id":"aime","name":"AIME 2024/25","category":"Math","description":"American Invitational Mathematics Examination. Competition-level math.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artofproblemsolving.com/wiki/index.php/AIME"},{"id":"lmarena-elo","name":"LMArena ELO","category":"Real-world","description":"Chatbot Arena ELO score. Crowd-sourced human preference ranking.","maxScore":1700,"minScore":1000,"higherIsBetter":true,"normalization":"elo","unit":"ELO","link":"https://chat.lmsys.org/?leaderboard"},{"id":"aa-intelligence-index","name":"AA Intelligence Index","category":"Real-world","description":"Artificial Analysis aggregate intelligence index.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aa-intelligence-index"},{"id":"agentbench","name":"AgentBench","category":"Agent","description":"Comprehensive framework to evaluate LLMs as agents across diverse environments.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/THUDM/AgentBench","paperUrl":"https://arxiv.org/abs/2308.03688"},{"id":"mmlu-pro","name":"MMLU-Pro","category":"Science","description":"A more robust and harder version of MMLU, focusing on complex reasoning and STEM subjects.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro","paperUrl":"https://arxiv.org/abs/2406.01574"},{"id":"hle","name":"HLE","category":"Science","description":"Humanity's Last Exam - Hard reasoning benchmark without tools.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249"},{"id":"hle-full","name":"HLE-Full","category":"Science","description":"Humanity's Last Exam full evaluation without tools.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249"},{"id":"hle-full-tools","name":"HLE-Full (w/ tools)","category":"Science","description":"Humanity's Last Exam full evaluation with tool access enabled.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249"},{"id":"critpt","name":"CritPt","category":"Science","description":"Complex Research using Integrated Thinking - Physics Test. Research-level physics reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arxiv.org/abs/2501.00663"},{"id":"simpleqa","name":"SimpleQA","category":"Science","description":"Open-domain factuality benchmark focusing on short, verifiable answers.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#simpleqa"},{"id":"simpleqa-verified","name":"SimpleQA Verified","category":"Knowledge","description":"Verified subset of SimpleQA for parametric knowledge evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#simpleqa-verified"},{"id":"healthbench","name":"HealthBench","category":"Science","description":"Medical knowledge and diagnostic reasoning evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#healthbench"},{"id":"supergpqa","name":"SuperGPQA","category":"Science","description":"Extremely difficult expert-level science questions.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#supergpqa"},{"id":"aime-2026","name":"AIME 2026","category":"Math","description":"Future prediction of AIME performance levels.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artofproblemsolving.com/wiki/index.php/AIME"},{"id":"aa-math-index","name":"AA Math Index","category":"Math","description":"Artificial Analysis aggregate math capability index.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aa-math-index"},{"id":"hmmt-feb-2025","name":"HMMT Feb 2025","category":"Math","description":"Harvard-MIT Mathematics Tournament - High difficulty competition math.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#hmmt-feb-2025"},{"id":"math-500","name":"MATH-500","category":"Math","description":"500-problem math benchmark for broad quantitative reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#math-500"},{"id":"imo-answerbench","name":"IMO-AnswerBench","category":"Math","description":"International Mathematical Olympiad style answer-only benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#imo-answerbench"},{"id":"matharena-apex","name":"MathArenaApex","category":"Math","description":"Competitive math arena for top-tier reasoning models.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#matharena-apex"},{"id":"codeforces","name":"Codeforces","category":"Coding","description":"Competitive programming rating based on problem solving.","maxScore":4000,"higherIsBetter":true,"normalization":"max","unit":"rating","link":"https://codeforces.com/"},{"id":"livecodebench-v6","name":"LiveCodeBench v6","category":"Coding","description":"Contamination-free coding benchmark using recent problems.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://livecodebench.github.io/","paperUrl":"https://arxiv.org/abs/2403.07974"},{"id":"livecodebench-pro","name":"LiveCodeBench Pro","category":"Coding","description":"Competitive programming problems from Codeforces, ICPC, and IOI with Elo rating.","maxScore":4000,"higherIsBetter":true,"normalization":"max","unit":"Elo","link":"https://livecodebenchpro.com/"},{"id":"aa-coding-index","name":"AA Coding Index","category":"Coding","description":"Artificial Analysis aggregate coding capability index.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aa-coding-index"},{"id":"paperbench-codedev","name":"PaperBench (CodeDev)","category":"Coding","description":"Research-grade coding and software development tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#paperbench-codedev"},{"id":"cybergym","name":"CyberGym","category":"Coding","description":"Cybersecurity-flavored coding benchmark in simulated environments.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#cybergym"},{"id":"ojbench-cpp","name":"OJBench (cpp)","category":"Coding","description":"Online-judge competitive coding benchmark focused on C++ tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ojbench-cpp"},{"id":"gpqa-diamond","name":"GPQA Diamond","category":"STEM","description":"Graduate-Level Google-Proof Q&A Benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://gpqa-benchmark.github.io/","paperUrl":"https://arxiv.org/abs/2311.12022"},{"id":"phybench","name":"Phybench","category":"STEM","description":"Physics reasoning and problem solving benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#phybench"},{"id":"arc-agi-1","name":"ARC-AGI-1","category":"Reasoning","description":"Abstraction and Reasoning Corpus - Level 1.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/","paperUrl":"https://arxiv.org/abs/1911.01547"},{"id":"mrcr-v2","name":"MRCR v2","category":"Long Context","description":"Multi-Round Context Retrieval - 8-needle test.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mrcr-v2"},{"id":"longbench-v2","name":"LongBench v2","category":"Long Context","description":"Comprehensive long-context understanding (128k).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longbench-v2"},{"id":"lcr","name":"AA-LCR","category":"Long Context","description":"Artificial Analysis Long Context Reasoning benchmark. Evaluates reasoning over long contexts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#lcr"},{"id":"mmmlu","name":"MMMLU","category":"Multilingual","description":"Massive Multilingual Language Understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arxiv.org/abs/2402.03300","paperUrl":"https://arxiv.org/abs/2402.03300"},{"id":"ifeval","name":"IFEval","category":"Instruction Following","description":"Instruction Following Evaluation for Large Language Models. Measures ability to follow strict formatting and constraint requirements.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://huggingface.co/spaces/yejinxie/IFEval","paperUrl":"https://arxiv.org/abs/2311.07911"},{"id":"ifeval-inverse","name":"Inverse IFEval","category":"Instruction Following","description":"Reverse instruction following evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ifeval-inverse"},{"id":"ifbench","name":"IFBench","category":"Instruction Following","description":"Artificial Analysis IFBench. Evaluates precise instruction following with constraints.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ifbench"},{"id":"verified-advancedif","name":"Verified AdvancedIF","category":"Instruction Following","description":"Advanced instruction-following benchmark with verified grading.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#verified-advancedif"},{"id":"longfact-concepts","name":"LongFact-Concepts","category":"Hallucination","description":"Factuality in long-form conceptual generations.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longfact-concepts"},{"id":"aa-omniscience","name":"AA-Omniscience","category":"Hallucination","description":"Evaluates model omniscience and factual reliability across diverse domains.","maxScore":100,"minScore":-100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#omniscience"},{"id":"aime-2025","name":"AIME 2025","category":"Math","description":"American Invitational Mathematics Examination 2025 problems.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artofproblemsolving.com/wiki/index.php/AIME"},{"id":"arc-agi-2","name":"ARC-AGI-2","category":"Reasoning","description":"Abstraction and Reasoning Corpus - Level 2 (Extreme difficulty).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/"},{"id":"factscore","name":"FactScore","category":"Hallucination","description":"Precision of fine-grained facts in long-form biographies.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#factscore"},{"id":"superchem","name":"Superchem","category":"STEM","description":"Expert-level chemistry knowledge and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#superchem"},{"id":"korbench","name":"KORBench","category":"Reasoning","description":"Korean reasoning and language understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#korbench"},{"id":"graphwalks-bfs","name":"Graphwalks Bfs","category":"Long Context","description":"Traversal-based long context reasoning using BFS (128k).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#graphwalks-bfs"},{"id":"global-piqa","name":"Global PIQA","category":"Multilingual","description":"Physical Interaction QA across multiple languages and cultures.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#global-piqa"},{"id":"multichallenge","name":"MultiChallenge","category":"Instruction Following","description":"Complex, multi-constraint instruction following tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#multichallenge"},{"id":"longfact-objects","name":"LongFact-Objects","category":"Hallucination","description":"Factuality in long-form generations about objects.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longfact-objects"},{"id":"putnam-200","name":"Putnam-200","category":"Math","description":"William Lowell Putnam Mathematical Competition problems - top 200 level difficulty.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#putnam-200"},{"id":"mathvista","name":"MathVista","category":"Vision","description":"Mathematical reasoning in visual contexts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mathvista.github.io/","paperUrl":"https://arxiv.org/abs/2310.02255"},{"id":"mathvista-mini","name":"MathVista (mini)","category":"Vision","description":"Compact MathVista split for faster multimodal reasoning checks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mathvista.github.io/"},{"id":"mathvision","name":"MathVision","category":"Vision","description":"Comprehensive mathematical vision benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mathvision"},{"id":"mmmu-vision","name":"MMMU","category":"Vision","description":"Massive Multi-discipline Multimodal Understanding and Reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mmmu-benchmark.github.io/"},{"id":"logicvista","name":"LogicVista","category":"Vision","description":"Logical reasoning in visual puzzles and diagrams.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#logicvista"},{"id":"blink","name":"BLINK","category":"Vision","description":"Spatial and perception benchmark for multimodal models.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#blink"},{"id":"mmvp","name":"MMVP","category":"Vision","description":"Multimodal visual perception benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmvp"},{"id":"chartqapro","name":"ChartQA Pro","category":"Vision","description":"Expert-level chart understanding and question answering.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#chartqapro"},{"id":"docvqa","name":"DocVQA","category":"Vision","description":"Document visual question answering on scanned and digital documents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://rrc.cvc.uab.es/?ch=17","paperUrl":"https://arxiv.org/abs/2007.00398"},{"id":"ocrbench-v2","name":"OCRBench v2","category":"Vision","description":"Next-gen optical character recognition and document understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://ocrbench.github.io/"},{"id":"ocrbench","name":"OCRBench","category":"Vision","description":"Optical character recognition and document understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://ocrbench.github.io/","paperUrl":"https://arxiv.org/abs/2312.16151"},{"id":"dynamath","name":"DynaMath","category":"Vision","description":"Dynamic mathematical reasoning in visual contexts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#dynamath"},{"id":"mathkangaroo","name":"MathKangaroo","category":"Vision","description":"Mathematical competition problems with visual elements.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mathkangaroo"},{"id":"mathcanvas","name":"MathCanvas","category":"Vision","description":"Multi-step mathematical reasoning on a canvas.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mathcanvas"},{"id":"mmmu-pro","name":"MMMU-Pro","category":"Vision","description":"Professional level MMMU expansion.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mmmu-benchmark.github.io/"},{"id":"mmmu-val","name":"MMMU (val)","category":"Vision","description":"Validation split of MMMU for multimodal understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mmmu-benchmark.github.io/"},{"id":"emma","name":"EMMA","category":"Vision","description":"Expert-level Multimodal Mathematics Analysis.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#emma"},{"id":"sfe","name":"SFE","category":"Vision","description":"Scientific Figure Evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#sfe"},{"id":"hipho","name":"HiPhO","category":"Vision","description":"High-level Physics Olympiad (Vision).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#hipho"},{"id":"xlrs-bench","name":"XLRS-Bench","category":"Vision","description":"Cross-domain Logical Reasoning and Spatial benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#xlrs-bench"},{"id":"phyx","name":"PhyX","category":"Vision","description":"Physics reasoning with open-ended visual questions.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#phyx"},{"id":"vpct","name":"VPCT","category":"Vision","description":"Visual Perception and Coding Tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vpct"},{"id":"zerobench-main","name":"ZeroBench (main)","category":"Vision","description":"Zero-shot visual reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#zerobench-main"},{"id":"zerobench-sub","name":"ZeroBench (sub)","category":"Vision","description":"Zero-shot visual reasoning sub-tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#zerobench-sub"},{"id":"zerobench","name":"ZeroBench","category":"Vision","description":"Aggregate ZeroBench score across the full task set.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#zerobench"},{"id":"zerobench-tools","name":"ZeroBench (w/ tools)","category":"Vision","description":"ZeroBench score when tool use is allowed.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#zerobench-tools"},{"id":"arc-agi-1-image","name":"ArcAGI1-Image","category":"Vision","description":"ARC-AGI Level 1 tasks in image format.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/"},{"id":"arc-agi-2-image","name":"ArcAGI2-Image","category":"Vision","description":"ARC-AGI Level 2 tasks in image format.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/"},{"id":"visulogic","name":"VisuLogic","category":"Vision","description":"Visual logic and sequence reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#visulogic"},{"id":"vlms-are-biased","name":"VLMsAreBiased","category":"Vision","description":"Evaluating bias in Vision-Language Models.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vlms-are-biased"},{"id":"vlms-are-blind","name":"VLMsAreBlind","category":"Vision","description":"Evaluating perception failures in VLMs.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vlms-are-blind"},{"id":"visfactor","name":"VisFactor","category":"Vision","description":"Visual factor identification and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#visfactor"},{"id":"realworldqa","name":"RealWorldQA","category":"Vision","description":"Real-world visual question answering.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#realworldqa"},{"id":"babyvision","name":"BabyVision","category":"Vision","description":"Early-stage visual development benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#babyvision"},{"id":"hallusionbench","name":"HallusionBench","category":"Vision","description":"Visual hallucination and factuality benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#hallusionbench"},{"id":"mme-cc","name":"MME-CC","category":"Vision","description":"Multimodal Evaluation (Cognitive Capacity).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mme-cc"},{"id":"mmstar","name":"MMStar","category":"Vision","description":"Elite multimodal model evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmstar"},{"id":"muirbench","name":"MUIRBench","category":"Vision","description":"Multimodal Understanding and Interaction Benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#muirbench"},{"id":"mtvqa","name":"MTVQA","category":"Vision","description":"Multilingual Text-centric Visual QA.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mtvqa"},{"id":"worldvqa","name":"WorldVQA","category":"Vision","description":"Global visual knowledge and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#worldvqa"},{"id":"vibeeval","name":"VibeEval","category":"Vision","description":"Subjective and intuitive visual quality evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vibeeval"},{"id":"viverbench","name":"ViVerBench","category":"Vision","description":"Visual Verification and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#viverbench"},{"id":"countbench","name":"CountBench","category":"Vision","description":"Visual object counting and identification.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#countbench"},{"id":"fsc-147","name":"FSC-147","category":"Vision","description":"Few-shot counting benchmark (Lower is better handled in normalization).","maxScore":100,"higherIsBetter":false,"normalization":"inverse","unit":"error","link":"https://artificialanalysis.ai/evaluations#fsc-147"},{"id":"point-bench","name":"Point-Bench","category":"Vision","description":"Visual pointing and spatial grounding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#point-bench"},{"id":"mmsibench","name":"MMSIBench","category":"Vision","description":"Multimodal Spatial Interaction Benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmsibench"},{"id":"treebench","name":"TreeBench","category":"Vision","description":"Hierarchical visual reasoning tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#treebench"},{"id":"refspatialbench","name":"RefSpatialBench","category":"Vision","description":"Referential spatial reasoning evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#refspatialbench"},{"id":"da-2k","name":"DA-2K","category":"Vision","description":"Document Analysis and reasoning (2k).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#da-2k"},{"id":"all-angles","name":"All-Angles","category":"Vision","description":"Multi-perspective visual understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#all-angles"},{"id":"erqa","name":"ERQA","category":"Vision","description":"Environment Reasoning and Question Answering.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#erqa"},{"id":"omnidocbench","name":"OmniDocBench","category":"Vision","description":"Universal document understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#omnidocbench"},{"id":"omnidocbench-15","name":"OmniDocBench 1.5","category":"Vision","description":"OCR benchmark measuring edit distance (lower is better).","maxScore":1,"minScore":0,"higherIsBetter":false,"normalization":"inverse","unit":"edit distance","link":"https://artificialanalysis.ai/evaluations#omnidocbench-15"},{"id":"screenspot-pro","name":"ScreenSpot-Pro","category":"Vision","description":"Screen understanding benchmark for GUI interaction.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/octopus-tools/screenspot-pro"},{"id":"infovqa-test","name":"InfoVQA (test)","category":"Vision","description":"Information-seeking visual question answering on the test split.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#infovqa-test"},{"id":"charxiv-dq","name":"CharXiv-DQ","category":"Vision","description":"Chart-based reasoning from arXiv papers (Data QA).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#charxiv-dq"},{"id":"charxiv-rq","name":"CharXiv-RQ","category":"Vision","description":"Chart-based reasoning from arXiv papers (Reasoning QA).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#charxiv-rq"},{"id":"charxiv-reasoning","name":"CharXiv Reasoning","category":"Vision","description":"Information synthesis from complex charts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arxiv.org/abs/2406.18521"},{"id":"dude","name":"DUDE","category":"Vision","description":"Document Understanding and Dialogue Evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#dude"},{"id":"mmlongbench","name":"MMLongBench","category":"Vision","description":"Multimodal Long context benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmlongbench"},{"id":"longdocurl","name":"LongDocURL","category":"Vision","description":"Long document understanding with URLs.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longdocurl"},{"id":"mmlongbench-doc","name":"MMLongBench-Doc","category":"Vision","description":"Multimodal Long context document evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmlongbench-doc"},{"id":"mmvu","name":"MMVU","category":"Video","description":"Multimodal Video Understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmvu"},{"id":"videosimpleqa","name":"VideoSimpleQA","category":"Video","description":"Verifiable question answering for short video clips.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videosimpleqa"},{"id":"videoreasonbench","name":"VideoReasonBench","category":"Video","description":"Complex reasoning tasks in video content.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videoreasonbench"},{"id":"morse-500","name":"Morse-500","category":"Video","description":"Sequence reasoning and motion understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#morse-500"},{"id":"videoholmes","name":"VideoHolmes","category":"Video","description":"Deep diagnostic video understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videoholmes"},{"id":"minerva","name":"Minerva","category":"Video","description":"Long-form video reasoning and knowledge retrieval.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#minerva"},{"id":"contphy","name":"ContPhy","category":"Video","description":"Continuous Physics reasoning in video.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#contphy"},{"id":"tempcompass","name":"TempCompass","category":"Video","description":"Temporal orientation and perception in video.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tempcompass"},{"id":"egotempo","name":"EgoTempo","category":"Video","description":"First-person perspective temporal reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#egotempo"},{"id":"motionbench","name":"MotionBench","category":"Video","description":"Comprehensive motion perception evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#motionbench"},{"id":"tomato","name":"TOMATO","category":"Video","description":"Temporal Object-centric Multimodal Analysis.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tomato"},{"id":"cgbench","name":"CGBench","category":"Video","description":"Contextual Grounding in long videos.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#cgbench"},{"id":"longvideobench","name":"LongVideoBench","category":"Video","description":"Understanding extremely long-form video content.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longvideobench"},{"id":"videoeval-pro","name":"VideoEval-Pro","category":"Video","description":"Professional level video quality and content evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videoeval-pro"},{"id":"lvbench","name":"LVBench","category":"Video","description":"Large-scale Video Benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#lvbench"},{"id":"crossvid","name":"CrossVid","category":"Video","description":"Cross-video temporal and relational reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#crossvid"},{"id":"livesports-3k","name":"LiveSports-3K","category":"Video","description":"Live sports broadcast understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#livesports-3k"},{"id":"ovobench","name":"OVOBench","category":"Video","description":"Object-Video-Object relational reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ovobench"},{"id":"odvbench","name":"ODVBench","category":"Video","description":"Open-Domain Video understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#odvbench"},{"id":"vispeak","name":"ViSpeak","category":"Video","description":"Video-to-speech and dialogue reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vispeak"},{"id":"frontiersci-olympiad","name":"FrontierSci-olympiad","category":"STEM","description":"Scientific Olympiad level problems.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#frontiersci-olympiad"},{"id":"terminal-bench","name":"Terminal-Bench 2.0","category":"Agentic","description":"Agent performance in realistic terminal workflows (v2.0 leaderboard).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://www.tbench.ai/leaderboard/terminal-bench/2.0"},{"id":"terminal-bench-hard","name":"Terminal-Bench Hard","category":"Agentic","description":"Hard split of Terminal-Bench focused on tougher terminal workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://www.tbench.ai/leaderboard/terminal-bench/2.0"},{"id":"osworld-verified","name":"OSWorld-Verified","category":"Agentic","description":"Verified desktop computer-use benchmark for end-to-end task completion.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://os-world.github.io/"},{"id":"webarena","name":"WebArena","category":"Agentic","description":"Browser-based autonomous task execution benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://webarena.dev/","paperUrl":"https://arxiv.org/abs/2307.13854"},{"id":"swe-lancer","name":"SWE-Lancer","category":"Agentic","description":"Software engineering task completion in multi-step coding workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#swe-lancer"},{"id":"multi-swe-bench","name":"Multi-SWE-bench","category":"Agentic","description":"Multi-repository software engineering benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#multi-swe-bench"},{"id":"swe-bench-pro","name":"SWE-bench Pro","category":"Agentic","description":"Higher-difficulty SWE-bench subset for frontier coding agents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://www.swebench.com/"},{"id":"swe-multilingual","name":"SWE Multilingual","category":"Agentic","description":"Software engineering performance across multilingual codebases.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#swe-multilingual"},{"id":"swe-evo","name":"SWE-Evo","category":"Agentic","description":"Evolutionary coding benchmark focused on long-horizon bug fixing.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#swe-evo"},{"id":"aider-polyglot","name":"Aider Polyglot","category":"Agentic","description":"Multi-language coding agent benchmark with editor-in-the-loop tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aider-polyglot"},{"id":"artifactsbench","name":"ArtifactsBench","category":"Agentic","description":"Agent ability to produce complete, runnable software artifacts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#artifactsbench"},{"id":"codesimpleqa","name":"CodeSimpleQA","category":"Agentic","description":"Short-form coding QA with executable correctness checks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#codesimpleqa"},{"id":"spreadsheetbench-verified","name":"SpreadsheetBench Verified","category":"Agentic","description":"Verified spreadsheet manipulation and reasoning tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#spreadsheetbench-verified"},{"id":"browsecomp","name":"BrowseComp","category":"Agentic","description":"Web browsing + synthesis benchmark for research agents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/google-research/browsecomp"},{"id":"browsecomp-ctx-manage","name":"BrowseComp (ctx manage)","category":"Agentic","description":"BrowseComp variant with explicit context-window management.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#browsecomp-ctx-manage"},{"id":"browsecomp-agent-swarm","name":"BrowseComp (Agent Swarm)","category":"Agentic","description":"Multi-agent swarm variant of BrowseComp.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#browsecomp-agent-swarm"},{"id":"browsecomp-zh","name":"BrowseComp-ZH","category":"Agentic","description":"Chinese-language browsing and synthesis benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#browsecomp-zh"},{"id":"hle-text","name":"HLE-Text","category":"Agentic","description":"Text-only variant of Humanity's Last Exam under agentic settings.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/"},{"id":"hle-verified","name":"HLE-Verified","category":"Agentic","description":"Verified subset of Humanity's Last Exam for reproducible evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/"},{"id":"widesearch","name":"WideSearch","category":"Agentic","description":"Broad retrieval and synthesis benchmark across many sources.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#widesearch"},{"id":"widesearch-agent-swarm","name":"WideSearch (Agent Swarm)","category":"Agentic","description":"Multi-agent swarm variant of WideSearch.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#widesearch-agent-swarm"},{"id":"finsearchcomp","name":"FinSearchComp","category":"Agentic","description":"Finance-focused search and evidence-grounded answering benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#finsearchcomp"},{"id":"finsearchcomp-t2-t3","name":"FinSearchComp T2&T3","category":"Agentic","description":"Tier 2 and Tier 3 slices of FinSearchComp.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#finsearchcomp-t2-t3"},{"id":"vending-bench-2","name":"Vending-Bench 2","category":"Agentic","description":"Long-horizon business simulation benchmark (final account balance).","maxScore":10000,"minScore":0,"higherIsBetter":true,"normalization":"max","unit":"USD","link":"https://artificialanalysis.ai/evaluations#vending-bench-2"},{"id":"facts-benchmark","name":"FACTS Benchmark Suite","category":"Agentic","description":"Factuality benchmark across grounding, parametric, search, and multimodal.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/google-deepmind/facts-benchmark"},{"id":"mcp-atlas","name":"MCP Atlas","category":"Agentic","description":"Multi-step workflows using Model Context Protocol.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/modelcontextprotocol/mcp-atlas"},{"id":"toolathlon","name":"Toolathlon","category":"Agentic","description":"Long horizon real-world software tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/toolathlon/toolathlon"},{"id":"deepsearchqa","name":"DeepSearchQA","category":"Agentic","description":"Deep multi-hop search QA for long-horizon agents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#deepsearchqa"},{"id":"seal-0","name":"SEAL-0","category":"Agentic","description":"Strategic environment-agent loop benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#seal-0"},{"id":"gdpval-aa","name":"GDPVal-AA","category":"Agentic","description":"Artificial Analysis GDPVal benchmark for knowledge-work quality.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#gdpval-aa"},{"id":"tau-bench","name":"TAU-Bench","category":"Agentic","description":"Tool-use and API orchestration benchmark for assistants.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/sierra-research/tau2-bench"},{"id":"tau-bench-retail","name":"TAU-Bench Retail","category":"Agentic","description":"Retail-domain tool-use and workflow benchmark from τ²-bench.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://taubench.com/"},{"id":"tau-bench-telecom","name":"TAU-Bench Telecom","category":"Agentic","description":"Telecom-domain tool-use and workflow benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/sierra-research/tau2-bench"},{"id":"mcp-mark","name":"MCP-Mark","category":"Agentic","description":"Model Context Protocol interoperability benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mcp-mark"},{"id":"bfcl-v4","name":"BFCL v4","category":"Agentic","description":"Function calling reliability benchmark (v4).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#bfcl-v4"},{"id":"vitabench","name":"VitaBench","category":"Agentic","description":"Virtual task assistant benchmark across practical workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vitabench"},{"id":"deepconsult","name":"DeepConsult","category":"Agentic","description":"Consulting-style multi-step reasoning and recommendation benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#deepconsult"},{"id":"deepresearchbench","name":"DeepResearchBench","category":"Agentic","description":"Long-horizon research task benchmark with citation requirements.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#deepresearchbench"},{"id":"researchrubrics","name":"ResearchRubrics","category":"Agentic","description":"Rubric-based evaluation of research quality and rigor.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#researchrubrics"},{"id":"minedojo-verified","name":"MineDojo Verified","category":"Agentic","description":"Verified embodied-agent benchmark in Minecraft-style tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#minedojo-verified"},{"id":"mm-browsecomp","name":"MM-BrowseComp","category":"Agentic","description":"Multimodal browse + synthesize benchmark for web agents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mm-browsecomp"},{"id":"hle-vl","name":"HLE-VL","category":"Agentic","description":"Vision-language variant of Humanity's Last Exam under agentic settings.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/"},{"id":"scicode","name":"SciCode","category":"Advanced Tasks","description":"Scientific programming benchmark for code synthesis and correctness.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/scicode-bench/scicode"},{"id":"frontiersci-research","name":"FrontierSci Research","category":"Advanced Tasks","description":"Open-ended scientific research benchmark with expert-level questions.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#frontiersci-research"},{"id":"biobench","name":"BioBench","category":"Advanced Tasks","description":"Biology and life-science benchmark requiring deep domain reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#biobench"},{"id":"ainstein-bench","name":"AInstein-Bench","category":"Advanced Tasks","description":"Hard scientific reasoning benchmark inspired by olympiad-level tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ainstein-bench"},{"id":"vibe-coding","name":"Vibe Coding","category":"Advanced Tasks","description":"High-level coding outcome quality benchmark for agent-driven development.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vibe-coding"},{"id":"nl2repo-bench","name":"NL2Repo-Bench","category":"Advanced Tasks","description":"Natural language to repository-wide code edits benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#nl2repo-bench"},{"id":"nl2repo-pass1","name":"NL2Repo Pass@1","category":"Advanced Tasks","description":"Pass@1 metric for repository-scale code modification tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#nl2repo-pass1"},{"id":"cl-bench","name":"CL-Bench","category":"Advanced Tasks","description":"Complex language benchmark covering difficult enterprise workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#cl-bench"},{"id":"tob-complex","name":"TOB Complex","category":"Advanced Tasks","description":"Task-oriented benchmark for complex instruction execution.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-complex"},{"id":"tob-reference","name":"TOB Reference","category":"Advanced Tasks","description":"Reference-heavy task-oriented benchmark requiring retrieval fidelity.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-reference"},{"id":"healthbench-hard","name":"HealthBench Hard","category":"Advanced Tasks","description":"Hard-split medical reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#healthbench-hard"},{"id":"gdpval-diamond","name":"GDPVal Diamond","category":"Advanced Tasks","description":"Diamond subset for difficult planning and valuation tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#gdpval-diamond"},{"id":"xpert-bench","name":"Xpert-Bench","category":"Advanced Tasks","description":"Expert-level evaluation benchmark across specialist domains.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#xpert-bench"},{"id":"tob-k12","name":"TOB K12","category":"Advanced Tasks","description":"Task-oriented benchmark for K12 educational tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-k12"},{"id":"tob-compositional","name":"TOB Compositional","category":"Advanced Tasks","description":"Compositional instruction-following benchmark with chained constraints.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-compositional"},{"id":"tob-classification","name":"TOB Classification","category":"Advanced Tasks","description":"Classification-focused track of task-oriented benchmark suite.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-classification"},{"id":"tob-extraction","name":"TOB Extraction","category":"Advanced Tasks","description":"Extraction-focused benchmark for structured information tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-extraction"},{"id":"world-travel-vlm","name":"World-Travel VLM","category":"Advanced Tasks","description":"Vision-language travel-planning and grounded reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#world-travel-vlm"},{"id":"world-travel-text","name":"World-Travel Text","category":"Advanced Tasks","description":"Text-only travel-planning and itinerary reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#world-travel-text"},{"id":"simplevqa","name":"SimpleVQA","category":"Vision","description":"Short-form visual question answering with verifiable responses.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#simplevqa"},{"id":"videommmu","name":"VideoMMMU","category":"Video","description":"Video variant of MMMU for multimodal understanding and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videommmu"},{"id":"videomme","name":"VideoMME","category":"Video","description":"Video multimodal evaluation benchmark for perception and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://video-mme.github.io/"},{"id":"tvbench","name":"TVBench","category":"Video","description":"Television/video narrative understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tvbench"},{"id":"ovbench","name":"OVBench","category":"Video","description":"Open-world video understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ovbench"}],"modelOptions":[{"id":"o1","name":"o1","provider":"OpenAI","releaseDate":"2024-12-05"},{"id":"o1-preview","name":"o1-preview","provider":"OpenAI","releaseDate":"2024-09-12"},{"id":"o1-mini","name":"o1-mini","provider":"OpenAI","releaseDate":"2024-09-12"},{"id":"openai-gpt-4o","name":"GPT-4o","provider":"OpenAI","releaseDate":"2024-05-13"},{"id":"openai-gpt-4-5","name":"GPT-4.5 (Orion)","provider":"OpenAI","releaseDate":"2025-02-14"},{"id":"openai-gpt-5-1","name":"GPT-5.1","provider":"OpenAI","releaseDate":"2025-08-15"},{"id":"gpt-5-2-pro","name":"GPT-5.2 Pro","provider":"OpenAI","releaseDate":"2025-12-11"},{"id":"gpt-5-2","name":"GPT-5.2","provider":"OpenAI","releaseDate":"2025-12-11"},{"id":"gpt-5-2-high","name":"GPT-5.2 High","provider":"OpenAI","releaseDate":"2025-12-11"},{"id":"gpt-5-2-xhigh","name":"GPT-5.2 Extra High","provider":"OpenAI","releaseDate":"2025-12-11"},{"id":"openai-gpt-5-3-codex","name":"GPT-5.3 Codex","provider":"OpenAI","releaseDate":"2026-02-05"},{"id":"gpt-5-mini","name":"GPT-5-mini","provider":"OpenAI","releaseDate":"2025-08-07"},{"id":"gpt-5-mini-high","name":"GPT-5-mini High","provider":"OpenAI","releaseDate":"2025-08-07"},{"id":"o3-pro","name":"o3-pro","provider":"OpenAI","releaseDate":"2025-06-10"},{"id":"o3","name":"o3","provider":"OpenAI","releaseDate":"2025-04-12"},{"id":"o4-mini","name":"o4-mini","provider":"OpenAI","releaseDate":"2026-02-01"},{"id":"openai-gpt-oss-120b","name":"GPT-oss-120b","provider":"OpenAI","releaseDate":"2025-10-20"},{"id":"claude-3-5-sonnet","name":"Claude 3.5 Sonnet","provider":"Anthropic","releaseDate":"2024-06-20"},{"id":"claude-3-5-haiku","name":"Claude 3.5 Haiku","provider":"Anthropic","releaseDate":"2024-10-22"},{"id":"claude-3-7-sonnet","name":"Claude 3.7 Sonnet","provider":"Anthropic","releaseDate":"2025-03-25"},{"id":"claude-opus-4-6","name":"Claude Opus 4.6","provider":"Anthropic","releaseDate":"2026-02-05"},{"id":"claude-opus-4-5","name":"Claude Opus 4.5","provider":"Anthropic","releaseDate":"2025-11-24"},{"id":"claude-opus-4-5-high","name":"Claude Opus 4.5 High","provider":"Anthropic","releaseDate":"2025-11-24"},{"id":"claude-sonnet-4-5","name":"Claude Sonnet 4.5","provider":"Anthropic","releaseDate":"2025-11-24"},{"id":"claude-sonnet-4-5-high","name":"Claude Sonnet 4.5 High","provider":"Anthropic","releaseDate":"2025-11-24"},{"id":"google-gemini-1-5-pro","name":"Gemini 1.5 Pro","provider":"Google DeepMind","releaseDate":"2024-02-15"},{"id":"google-gemini-2-5-pro","name":"Gemini 2.5 Pro","provider":"Google DeepMind","releaseDate":"2025-06-25"},{"id":"gemini-2.5-flash","name":"Gemini 2.5 Flash","provider":"Google DeepMind","releaseDate":"2025-06-25"},{"id":"google-gemini-2-0-flash","name":"Gemini 2.0 Flash","provider":"Google DeepMind","releaseDate":"2024-12-11"},{"id":"gemini-3-pro","name":"Gemini 3 Pro","provider":"Google DeepMind","releaseDate":"2025-11-18"},{"id":"gemini-3-pro-high","name":"Gemini 3 Pro High","provider":"Google DeepMind","releaseDate":"2025-11-18"},{"id":"gemini-3.1-pro","name":"Gemini 3.1 Pro","provider":"Google DeepMind","releaseDate":"2026-02-19"},{"id":"gemini-3-flash","name":"Gemini 3 Flash","provider":"Google DeepMind","releaseDate":"2025-12-17"},{"id":"gemini-3-flash-high","name":"Gemini 3 Flash High","provider":"Google DeepMind","releaseDate":"2025-12-17"},{"id":"google-gemini-3-deep-think","name":"Gemini 3 Deep Think","provider":"Google DeepMind","releaseDate":"2026-02-12"},{"id":"nano-banana-pro","name":"Nano Banana Pro","provider":"Google DeepMind","releaseDate":"2025-12-01"},{"id":"meta-llama-3-1-405b","name":"Llama 3.1 405B","provider":"Meta","releaseDate":"2024-07-23"},{"id":"meta-llama-3-3-70b","name":"Llama 3.3 70B","provider":"Meta","releaseDate":"2024-12-06"},{"id":"meta-llama-4-behemoth","name":"Llama 4 Behemoth","provider":"Meta","releaseDate":"2026-01-14"},{"id":"meta-llama-4-maverick","name":"Llama 4 Maverick","provider":"Meta","releaseDate":"2025-09-30"},{"id":"meta-llama-4-scout","name":"Llama 4 Scout","provider":"Meta","releaseDate":"2026-01-14"},{"id":"deepseek-v3","name":"DeepSeek V3","provider":"DeepSeek","releaseDate":"2024-12-26"},{"id":"deepseek-v3-1-terminus","name":"DeepSeek-V3.1-Terminus","provider":"DeepSeek","releaseDate":"2025-09-22"},{"id":"deepseek-v3-2-speciale","name":"DeepSeek-V3.2-Speciale","provider":"DeepSeek","releaseDate":"2025-12-01"},{"id":"deepseek-r1","name":"DeepSeek R1","provider":"DeepSeek","releaseDate":"2025-01-20"},{"id":"deepseek-r1-zero","name":"DeepSeek-R1-Zero","provider":"DeepSeek","releaseDate":"2025-01-20"},{"id":"deepseek-r1-distill-llama-70b","name":"DeepSeek-R1-Distill-Llama-70B","provider":"DeepSeek","releaseDate":"2025-01-20"},{"id":"deepseek-r1-distill-qwen-32b","name":"DeepSeek-R1-Distill-Qwen-32B","provider":"DeepSeek","releaseDate":"2025-01-20"},{"id":"command-r-plus-08-2024","name":"Command R+ (08-2024)","provider":"Cohere","releaseDate":"2024-08-01"},{"id":"command-a","name":"Command A","provider":"Cohere","releaseDate":"2025-05-01"},{"id":"jamba-2-large","name":"Jamba 2 Large","provider":"AI21","releaseDate":"2025-03-01"},{"id":"minimax-2-1","name":"MiniMax 2.1","provider":"Minimax","releaseDate":"2024-10-15"},{"id":"minimax-m2","name":"MiniMax M2","provider":"Minimax","releaseDate":"2025-04-10"},{"id":"minimax-m2-5","name":"MiniMax 2.5","provider":"Minimax","releaseDate":"2026-02-12"},{"id":"kimi-k2","name":"Kimi K2","provider":"Moonshot AI","releaseDate":"2025-09-05"},{"id":"kimi-k2-thinking","name":"Kimi K2 Thinking","provider":"Moonshot AI","releaseDate":"2025-11-10"},{"id":"kimi-k2-5","name":"Kimi K2.5","provider":"Moonshot AI","releaseDate":"2026-01-20"},{"id":"glm-4-6","name":"GLM-4.6","provider":"Zhipu AI","releaseDate":"2025-09-30"},{"id":"glm-4-7","name":"GLM-4.7","provider":"Zhipu AI","releaseDate":"2025-12-22"},{"id":"glm-5","name":"GLM-5","provider":"Zhipu AI","releaseDate":"2026-02-11"},{"id":"qwen-2-5-max","name":"Qwen 2.5 Max","provider":"Alibaba","releaseDate":"2025-01-29"},{"id":"qwen3-vl-235b-a22b","name":"Qwen3-VL-235B-A22B","provider":"Alibaba","releaseDate":"2025-09-21"},{"id":"qwen3-vl-235b-a22b-thinking","name":"Qwen3-VL-235B-A22B Thinking","provider":"Alibaba","releaseDate":"2025-09-21"},{"id":"qwen-3-5-397b-a17b","name":"Qwen 3.5 397B-A17B","provider":"Alibaba","releaseDate":"2026-02-16"},{"id":"phi-4","name":"Phi-4","provider":"Microsoft","releaseDate":"2025-02-01"},{"id":"starcoder2-15b","name":"StarCoder2-15B","provider":"BigCode","releaseDate":"2024-02-28"},{"id":"dbrx-instruct","name":"DBRX Instruct","provider":"Databricks","releaseDate":"2024-03-27"},{"id":"internlm3-8b","name":"InternLM3-8B","provider":"Shanghai AI Lab","releaseDate":"2025-08-01"},{"id":"yi-1-5-34b","name":"Yi-1.5-34B","provider":"01.AI","releaseDate":"2024-05-13"},{"id":"baichuan-m3","name":"Baichuan-M3","provider":"Baichuan","releaseDate":"2026-01-15"},{"id":"snowflake-arctic","name":"Snowflake Arctic","provider":"Snowflake","releaseDate":"2024-04-24"},{"id":"mistral-large-2","name":"Mistral Large 2","provider":"Mistral","releaseDate":"2024-07-24"},{"id":"ministral-3b","name":"Ministral 3B","provider":"Mistral","releaseDate":"2024-10-16"},{"id":"grok-4","name":"Grok-4","provider":"xAI","releaseDate":"2026-02-01"},{"id":"grok-4-1-fast","name":"Grok-4.1-Fast","provider":"xAI","releaseDate":"2026-01-30"},{"id":"grok-3","name":"Grok-3","provider":"xAI","releaseDate":"2025-02-15"},{"id":"amazon-nova-pro","name":"Amazon Nova Pro","provider":"Amazon","releaseDate":"2024-12-01"},{"id":"seed-2-0-pro","name":"Seed2.0 Pro","provider":"ByteDance","releaseDate":"2026-02-14"},{"id":"seed-2-0-mini","name":"Seed2.0 Mini","provider":"ByteDance","releaseDate":"2026-02-14"},{"id":"seed-2-0-lite","name":"Seed2.0 Lite","provider":"ByteDance","releaseDate":"2026-02-14"},{"id":"deepseek-prover-v2","name":"DeepSeek-Prover-V2","provider":"DeepSeek","releaseDate":"2025-04-30"},{"id":"seed-1-5-prover","name":"Seed-1.5-Prover","provider":"ByteDance","releaseDate":"2025-12-05"},{"id":"seed-1-8","name":"Seed-1.8","provider":"ByteDance","releaseDate":"2025-11-20"}],"initialSelectedModels":[]}]}]}]]}],["$L4"],"$L5"]}],"loading":null,"isPartial":false}
4:["$","script","script-0",{"src":"/_next/static/chunks/b721a80a7ed88b57.js","async":true}]
5:["$","$L6",null,{"children":["$","$2",null,{"name":"Next.MetadataOutlet","children":"$@7"}]}]
7:null
