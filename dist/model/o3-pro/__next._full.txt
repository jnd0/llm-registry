1:"$Sreact.fragment"
2:I[46798,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js"],"TooltipProvider"]
3:I[12985,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js"],"NuqsAdapter"]
4:I[11619,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js"],"NavbarClient"]
c:I[68027,[],"default"]
:HL["/_next/static/chunks/8e1669da23dc4a96.css","style"]
:HL["/_next/static/chunks/9c1c6921831deb29.css","style"]
:HL["/_next/static/media/0c89a48fa5027cee-s.p.4564287c.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
0:{"P":null,"b":"ndSWmh2LFKxVirkTwO1tD","c":["","model","o3-pro"],"q":"","i":false,"f":[[["",{"children":["model",{"children":[["id","o3-pro","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/8e1669da23dc4a96.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/chunks/9c1c6921831deb29.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/50e362abf678ecbe.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/5a162bb283fc115e.js","async":true,"nonce":"$undefined"}],["$","script","script-2",{"src":"/_next/static/chunks/195c216f52dae3f8.js","async":true,"nonce":"$undefined"}],["$","script","script-3",{"src":"/_next/static/chunks/f1aa34f1a3c869ef.js","async":true,"nonce":"$undefined"}],["$","script","script-4",{"src":"/_next/static/chunks/6b5063fbd0ddba71.js","async":true,"nonce":"$undefined"}],["$","script","script-5",{"src":"/_next/static/chunks/ffbb017a68df0472.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","meta",null,{"name":"theme-color","content":"#0a0a12"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"LLM Registry\",\"url\":\"https://llm-registry.com\",\"description\":\"Source-of-truth registry for LLM benchmark performance with provenance, category rankings, and comparison workflows.\",\"potentialAction\":{\"@type\":\"SearchAction\",\"target\":\"https://llm-registry.com/?q={search_term_string}\",\"query-input\":\"required name=search_term_string\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Organization\",\"name\":\"LLM Registry\",\"url\":\"https://llm-registry.com\"}"}}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n(() => {\n  try {\n    const stored = localStorage.getItem(\"theme\") || \"system\";\n    const prefersDark = window.matchMedia(\"(prefers-color-scheme: dark)\").matches;\n    const dark = stored === \"dark\" || (stored === \"system\" && prefersDark);\n    document.documentElement.classList.toggle(\"dark\", dark);\n    document.documentElement.dataset.theme = stored;\n  } catch {\n    document.documentElement.classList.add(\"dark\");\n    document.documentElement.dataset.theme = \"system\";\n  }\n})();\n"}}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n  try {\n    const stored = localStorage.getItem(\"theme\") || \"system\";\n    const prefersDark = window.matchMedia(\"(prefers-color-scheme: dark)\").matches;\n    const dark = stored === \"dark\" || (stored === \"system\" && prefersDark);\n    const meta = document.querySelector('meta[name=\"theme-color\"]');\n    if (meta) meta.setAttribute('content', dark ? '#0a0a12' : '#fafafa');\n  } catch {}\n"}}]]}],["$","body",null,{"className":"geist_deef94d5-module__Sms4YG__variable geist_mono_1bf8cbf6-module__FlyLvG__variable space_grotesk_f96678b6-module__HU1eKa__variable min-h-screen overflow-x-hidden bg-background font-sans text-foreground antialiased selection:bg-primary/20 selection:text-primary","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","div",null,{"className":"relative flex min-h-screen flex-col","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:left-4 focus:top-4 focus:z-[70] focus:rounded-md focus:bg-primary focus:px-3 focus:py-2 focus:text-sm focus:font-medium focus:text-primary-foreground","children":"Skip to content"}],["$","div",null,{"className":"pointer-events-none absolute inset-0 -z-10 bg-grid-pattern opacity-55 dark:opacity-0"}],["$","$L4",null,{"models":[{"id":"o1","name":"o1","provider":"OpenAI","releaseDate":"2024-12-05","capabilities":["text","code","reasoning","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"Reasoning Model","pricing":{"input":15,"output":60}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":false,"maxTokens":true,"temperature":false,"topP":false},"trainingCutoff":"2023-10","metadataSourceId":"openai-docs","metadataAsOfDate":"2026-02-17","modelUrl":"https://platform.openai.com/docs/models/o1","scores":{"mmlu":{"score":91.8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":78,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"math-500":{"score":96.4,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"human-eval":{"score":88.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"bigcodebench":{"score":35.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"agentbench":{"score":87.6,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"lmarena-elo":{"score":1360,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"o1-preview","name":"o1-preview","provider":"OpenAI","releaseDate":"2024-09-12","capabilities":["text","code","reasoning","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"Reasoning Model","pricing":{"input":20,"output":80,"cacheInput":0.5}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":false,"maxTokens":true,"temperature":false,"topP":false},"trainingCutoff":"2023-10","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"o1","modelUrl":"https://platform.openai.com/docs/models/o1","scores":{"mmlu":{"score":90.8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":78.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"math":{"score":94.8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aime":{"score":83.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"lmarena-elo":{"score":1330,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aa-coding-index":{"score":34,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":23.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":92.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"o1-mini","name":"o1-mini","provider":"OpenAI","releaseDate":"2024-09-12","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Small Reasoning","pricing":{"input":1.1,"output":4.4}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":false,"maxTokens":true,"temperature":false,"topP":false},"trainingCutoff":"2023-10","metadataSourceId":"openai-docs","metadataAsOfDate":"2026-02-17","modelUrl":"https://platform.openai.com/docs/models/o1","scores":{"mmlu":{"score":85.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":60,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"math-500":{"score":90,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"human-eval":{"score":92.4,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"openai-gpt-4o","name":"GPT-4o","provider":"OpenAI","releaseDate":"2024-05-13","capabilities":["text","code","vision","audio"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"200B (Estimated)","pricing":{"input":2.5,"output":10}},"scores":{"mmlu":{"score":88.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":53.6,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"math":{"score":76.6,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"human-eval":{"score":90.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"bigcodebench":{"score":31.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"agentbench":{"score":90,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"superchem":{"score":40,"verified":false,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mmmu":{"score":69.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"lmarena-elo":{"score":1388,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"openai-gpt-4-5","name":"GPT-4.5 (Orion)","provider":"OpenAI","releaseDate":"2025-02-14","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"Orion Engine","pricing":{"input":4.5,"output":13.5}},"scores":{"mmlu":{"score":90.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":65.4,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mmmu":{"score":78.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"openai-gpt-5-1","name":"GPT-5.1","provider":"OpenAI","releaseDate":"2025-08-15","capabilities":["text","code","vision","audio","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":256000,"parameters":"Unknown","pricing":{"input":2,"output":10}},"scores":{"mmlu":{"score":91,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":87.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"math":{"score":92,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"human-eval":{"score":98.2,"verified":false,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mmmu":{"score":84.5,"verified":false,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"lmarena-elo":{"score":1450,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"},"livebench":{"score":70.48,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"},{"id":"gpt-5-2-pro","name":"GPT-5.2 Pro","provider":"OpenAI","releaseDate":"2025-12-11","capabilities":["text","code","vision","audio","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":400000,"parameters":"Unknown (MoE)","pricing":{"input":21,"output":168}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":false,"topP":false},"trainingCutoff":"2025-08","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"gpt-5.2-pro","modelUrl":"https://developers.openai.com/api/docs/models/gpt-5.2","scores":{"mmlu":{"score":93.2,"verified":true,"verificationLevel":"$undefined","sourceId":"llm-stats","asOfDate":"2026-02-18"},"mmlu-pro":{"score":88.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"gpqa-diamond":{"score":93.2,"verified":true,"verificationLevel":"$undefined","sourceId":"llm-stats","asOfDate":"2026-02-18"},"math":{"score":100,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"aime-2025":{"score":100,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"human-eval":{"score":95,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"swe-bench-verified":{"score":80,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"swe-bench-pro":{"score":55.6,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"mmmu-pro":{"score":86.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"videommmu":{"score":90.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"hle":{"score":50,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"arc-agi-1":{"score":86.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"arc-agi-2":{"score":52.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"charxiv-rq":{"score":88.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-gpt52-announce","asOfDate":"2025-12-11"},"lmarena-elo":{"score":1512,"verified":true,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"2026-02-18"}},"variants":"$undefined"},{"id":"gpt-5-2","name":"GPT-5.2","provider":"OpenAI","releaseDate":"2025-12-11","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":512000,"parameters":"Ultra-High Dense","pricing":{"input":1.75,"output":14}},"scores":{"mmlu-pro":{"score":85.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"hle":{"score":29.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"livebench":{"score":48.91,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":[{"id":"gpt-5-2-high","name":"GPT-5.2 High","provider":"OpenAI","releaseDate":"2025-12-11","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":512000,"parameters":"Ultra-High Dense","pricing":{"input":1.75,"output":14,"cacheInput":0.175}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-08","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"gpt-5.2","modelUrl":"https://developers.openai.com/api/docs/models/gpt-5.2","scores":{"mmlu-pro":{"score":85.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"hle":{"score":29.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"livebench":{"score":74.84,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"simpleqa":{"score":14.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"healthbench":{"score":33.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"supergpqa":{"score":29.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"matharena-apex":{"score":83.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"factscore":{"score":61.8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aime-2026":{"score":67.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"hmmt-feb-2025":{"score":61,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"codeforces":{"score":3148,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"livecodebench-v6":{"score":73.8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":92.4,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"arc-agi-1":{"score":89.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mrcr-v2":{"score":89.4,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"longbench-v2":{"score":63.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mmmlu":{"score":90.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"ifeval-inverse":{"score":87.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"longfact-concepts":{"score":99.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"korbench":{"score":57.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"graphwalks-bfs":{"score":99.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"global-piqa":{"score":93.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"multichallenge":{"score":59.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"longfact-objects":{"score":99.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"terminal-bench":{"score":62.4,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"swe-lancer":{"score":48.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"swe-bench-verified":{"score":80,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"multi-swe-bench":{"score":47.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"swe-bench-pro":{"score":55.6,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"swe-multilingual":{"score":68.8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"swe-evo":{"score":12.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aider-polyglot":{"score":80,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"artifactsbench":{"score":71.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"codesimpleqa":{"score":62.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"spreadsheetbench-verified":{"score":69.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"browsecomp":{"score":77.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"browsecomp-zh":{"score":76.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"hle-text":{"score":76.8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"hle-verified":{"score":73.8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"widesearch":{"score":71.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"finsearchcomp":{"score":36.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"deepsearchqa":{"score":76.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"seal-0":{"score":63.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"tau-bench":{"score":82,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"tau-bench-telecom":{"score":98.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mcp-mark":{"score":54.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"bfcl-v4":{"score":57.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"vitabench":{"score":65.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"deepconsult":{"score":54.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"deepresearchbench":{"score":53.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"researchrubrics":{"score":42.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"minedojo-verified":{"score":18.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mm-browsecomp":{"score":26.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"hle-vl":{"score":36,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"scicode":{"score":49.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"frontiersci-research":{"score":18.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"frontiersci-olympiad":{"score":75,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"biobench":{"score":58.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"ainstein-bench":{"score":41.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"vibe-coding":{"score":71.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"nl2repo-bench":{"score":49.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"nl2repo-pass1":{"score":8,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"cl-bench":{"score":45,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"tob-complex":{"score":63.6,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"tob-reference":{"score":64.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"healthbench-hard":{"score":36.6,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gdpval-diamond":{"score":26.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"xpert-bench":{"score":53.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"tob-k12":{"score":61.6,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"tob-compositional":{"score":62.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"tob-classification":{"score":44.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"tob-extraction":{"score":19.33,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"world-travel-vlm":{"score":32.67,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"world-travel-text":{"score":64.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"gpt-5-2-xhigh","name":"GPT-5.2 Extra High","provider":"OpenAI","releaseDate":"2025-12-11","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":512000,"parameters":"Ultra-High Dense","pricing":{"input":1.75,"output":14,"cacheInput":0.175}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-08","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"gpt-5.2","modelUrl":"https://developers.openai.com/api/docs/models/gpt-5.2","scores":{"hle":{"score":35.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle-full-tools":{"score":45.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"arc-agi-2":{"score":52.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"aime-2025":{"score":99,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmmu-pro":{"score":79.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"screenspot-pro":{"score":86.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"charxiv-reasoning":{"score":82.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"omnidocbench-15":{"score":0.143,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"videommmu":{"score":85.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livecodebench-pro":{"score":2393,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"toolathlon":{"score":46.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mcp-atlas":{"score":60.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"vending-bench-2":{"score":3952,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"facts-benchmark":{"score":61.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"simpleqa-verified":{"score":38,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"gpqa-diamond":{"score":90.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mrcr-v2":{"score":81.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmlu":{"score":89.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"global-piqa":{"score":91.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"swe-bench-verified":{"score":80,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"aa-coding-index":{"score":48.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":51.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":99,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":75.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":72.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":88.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":87.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":52.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":84.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":47,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"}]},"$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:7:variants:0","$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:7:variants:1",{"id":"openai-gpt-5-3-codex","name":"GPT-5.3 Codex","provider":"OpenAI","releaseDate":"2026-02-05","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":512000,"parameters":"Code Optimized","pricing":{"input":1.5,"output":8}},"scores":{"human-eval":{"score":98.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"swe-bench-verified":{"score":72.4,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"terminal-bench":{"score":77.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"osworld-verified":{"score":64.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"livebench":{"score":74.3,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"},{"id":"gpt-5-mini","name":"GPT-5-mini","provider":"OpenAI","releaseDate":"2025-08-07","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Efficient","pricing":{"input":0.25,"output":2}},"scores":{"mmlu":{"score":85.2,"verified":true,"verificationLevel":"$undefined","sourceId":"llm-stats","asOfDate":"2026-02-18"},"mmlu-pro":{"score":84.1,"verified":true,"verificationLevel":"$undefined","sourceId":"llm-stats","asOfDate":"2026-02-18"},"gpqa-diamond":{"score":75.8,"verified":true,"verificationLevel":"$undefined","sourceId":"llm-stats","asOfDate":"2026-02-18"},"math":{"score":78.5,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"human-eval":{"score":88,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"swe-bench-verified":{"score":55.2,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lmarena-elo":{"score":1358,"verified":true,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"2026-02-18"}},"variants":[{"id":"gpt-5-mini-high","name":"GPT-5-mini High","provider":"OpenAI","releaseDate":"2025-08-07","capabilities":["text","code","reasoning","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":400000,"parameters":"Efficient High-Cap","pricing":{"input":1.25,"output":2,"cacheInput":0.125}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":false,"topP":false},"trainingCutoff":"2024-05","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"gpt-5-mini","modelCardUrl":"https://openai.com/index/gpt-5-system-card/","modelUrl":"https://platform.openai.com/docs/models/gpt-5-mini","scores":{"mmlu-pro":{"score":83.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":19.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"simpleqa":{"score":26,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"math":{"score":92.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aime-2026":{"score":92.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"codeforces":{"score":1985,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":82.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"human-eval":{"score":94,"verified":false,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mmmu":{"score":78.2,"verified":false,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"arc-agi-1":{"score":54.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"mmmlu":{"score":86.3,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"putnam-200":{"score":30.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"lmarena-elo":{"score":1380,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"},"livebench":{"score":65.91,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":35.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":41,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":90.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":90.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":75.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":68,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":83.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":39.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":68.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":33.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"}]},"$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:11:variants:0",{"id":"o3-pro","name":"o3-pro","provider":"OpenAI","releaseDate":"2025-06-10","capabilities":["text","code","reasoning","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":256000,"parameters":"Reasoning Model","pricing":{"input":20,"output":80,"cacheInput":0.5}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":false,"maxTokens":true,"temperature":false,"topP":false},"trainingCutoff":"2024-10","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"o3","modelUrl":"https://platform.openai.com/docs/models/o3-pro","scores":{"gpqa-diamond":{"score":84.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math":{"score":99,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aime-2025":{"score":96,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"lmarena-elo":{"score":1360,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aa-intelligence-index":{"score":40.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"o3","name":"o3","provider":"OpenAI","releaseDate":"2025-04-12","capabilities":["text","code","reasoning","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"Reasoning Model","pricing":{"input":2,"output":8,"cacheInput":0.5}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":false,"maxTokens":true,"temperature":false,"topP":false},"trainingCutoff":"2024-10","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelUrl":"https://platform.openai.com/docs/models/o3","scores":{"math":{"score":98.2,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aime":{"score":90.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"bigcodebench":{"score":35.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"agentbench":{"score":84.7,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"livebench":{"score":84.6,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"superchem":{"score":40,"verified":false,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aa-coding-index":{"score":38.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":38.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":88.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":88.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":82.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":20,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":71.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":69.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":80.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":99.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":85.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":41,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":80.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":37.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"o4-mini","name":"o4-mini","provider":"OpenAI","releaseDate":"2026-02-01","capabilities":["text","code","reasoning","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"Small Reasoning","pricing":{"input":0.15,"output":0.6,"cacheInput":0.55}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":false,"maxTokens":true,"temperature":false,"topP":false},"trainingCutoff":"2024-10","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelUrl":"https://platform.openai.com/docs/models/o4-mini","scores":{"mmlu":{"score":84.5,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"math":{"score":88,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"aa-coding-index":{"score":25.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":33,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":90.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":94,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":90.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":78.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":17.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":68.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":55,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":85.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":98.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":83.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":46.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":55.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":15.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"openai-gpt-oss-120b","name":"GPT-oss-120b","provider":"OpenAI","releaseDate":"2025-10-20","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"120B","pricing":{"input":0,"output":0}},"scores":{"mmlu":{"score":90,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":80.1,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"ifbench":{"score":0.695,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"math":{"score":97.9,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"hle":{"score":19,"verified":true,"verificationLevel":"$undefined","sourceId":"openai-blog","asOfDate":"$undefined"},"livebench":{"score":46.09,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"},{"id":"claude-3-5-sonnet","name":"Claude 3.5 Sonnet","provider":"Anthropic","releaseDate":"2024-06-20","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"175B (Estimated)","pricing":{"input":3,"output":15}},"trainingCutoff":"2024-04","metadataSourceId":"anthropic-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://www.anthropic.com/news/claude-3-5-sonnet","modelUrl":"https://www.anthropic.com/claude/sonnet","scores":{"mmlu":{"score":88.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":59.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"human-eval":{"score":92,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"bigcodebench":{"score":30.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"agentbench":{"score":80.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"superchem":{"score":40,"verified":false,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":49,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"mmmu":{"score":67.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1271,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"claude-3-5-haiku","name":"Claude 3.5 Haiku","provider":"Anthropic","releaseDate":"2024-10-22","capabilities":["text","code"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"Unknown","pricing":{"input":1,"output":5}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":true},"trainingCutoff":"2024-07","metadataSourceId":"anthropic-docs","metadataAsOfDate":"2026-02-17","modelUrl":"https://www.anthropic.com/claude/haiku","scores":{"mmlu":{"score":81,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"mmlu-pro":{"score":65,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":41.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"math":{"score":73,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"human-eval":{"score":88.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"claude-3-7-sonnet","name":"Claude 3.7 Sonnet","provider":"Anthropic","releaseDate":"2025-03-25","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"Refined Architecture","pricing":{"input":3,"output":15,"cacheInput":0.3,"cacheOutput":3.75}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true},"trainingCutoff":"2024-02","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"claude-3-7-sonnet-20250219","modelUrl":"https://www.anthropic.com/claude/sonnet","scores":{"mmlu":{"score":89.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":65.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":85,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"human-eval":{"score":93.5,"verified":false,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"mmmu":{"score":76.4,"verified":false,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1451,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"},"swe-bench-verified":{"score":55.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"aa-coding-index":{"score":26.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":30.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":21,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":22.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":21,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":4.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":44,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":48.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":39.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":80.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":37.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":50,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":21.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"claude-opus-4-6","name":"Claude Opus 4.6","provider":"Anthropic","releaseDate":"2026-02-05","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Unknown","pricing":{"input":5,"output":25,"cacheInput":1.5,"cacheOutput":18.75}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2026-02","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelCardUrl":"https://www-cdn.anthropic.com/14e4fb01875d2a69f646fa5e574dea2b1c0ff7b5.pdf","modelUrl":"https://www.anthropic.com/claude/opus","scores":{"mmlu":{"score":91.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"mmlu-pro":{"score":82.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":84,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livebench":{"score":76.33,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"math":{"score":89.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"human-eval":{"score":94.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":80.8,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"mmmu":{"score":76.5,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"hle":{"score":18.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle-full":{"score":40,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"arc-agi-2":{"score":68.8,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"terminal-bench":{"score":65.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"terminal-bench-hard":{"score":48.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":46.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"browsecomp":{"score":84,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"osworld-verified":{"score":72.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"mrcr-v2":{"score":76,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"aa-omniscience":{"score":11,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"critpt":{"score":12.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1502,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"aa-coding-index":{"score":47.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":44.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":58.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":45.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":84.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"claude-opus-4-5","name":"Claude Opus 4.5","provider":"Anthropic","releaseDate":"2025-11-24","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"Unknown","pricing":{"input":5,"output":25,"cacheInput":0.5,"cacheOutput":6.25}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-09","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelCardUrl":"https://www.anthropic.com/news/claude-opus-4-5","modelUrl":"https://www.anthropic.com/claude/opus","scores":{"mmlu":{"score":90.5,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":81,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"factscore":{"score":51.3,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"hle":{"score":12.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":40.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":43,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-omniscience":{"score":10,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":80.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"livebench":{"score":59.1,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":42.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":62.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":62.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":43,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":65.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":73.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":88.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":47,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":86.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":[{"id":"claude-opus-4-5-high","name":"Claude Opus 4.5 High","provider":"Anthropic","releaseDate":"2025-11-24","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":400000,"parameters":"Unknown","pricing":{"input":5,"output":25,"cacheInput":0.5,"cacheOutput":6.25}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-09","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"claude-opus-4-5","modelUrl":"https://www.anthropic.com/claude/opus","scores":{"mmlu-pro":{"score":89.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":28.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2026":{"score":70.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"aime-2025":{"score":91.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"codeforces":{"score":1701,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":86.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"arc-agi-1":{"score":84,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"terminal-bench":{"score":60.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-lancer":{"score":48.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":80.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"multi-swe-bench":{"score":52.8,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-bench-pro":{"score":55.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-multilingual":{"score":74,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-evo":{"score":27.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"artifactsbench":{"score":68.5,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"codesimpleqa":{"score":63,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"spreadsheetbench-verified":{"score":78.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"browsecomp":{"score":67.8,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"browsecomp-zh":{"score":62.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"hle-text":{"score":76.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"hle-verified":{"score":66.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"widesearch":{"score":76.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"finsearchcomp":{"score":14,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"deepsearchqa":{"score":53.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"seal-0":{"score":56.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tau-bench":{"score":88.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tau-bench-telecom":{"score":89.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"bfcl-v4":{"score":42.3,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"vitabench":{"score":76.5,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"deepconsult":{"score":61,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"researchrubrics":{"score":45,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"scicode":{"score":49.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"frontiersci-research":{"score":21.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"biobench":{"score":49.3,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"ainstein-bench":{"score":44,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"vibe-coding":{"score":71.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"nl2repo-bench":{"score":43.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"nl2repo-pass1":{"score":3,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"cl-bench":{"score":64.8,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-complex":{"score":63.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-reference":{"score":67.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"healthbench-hard":{"score":11,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gdpval-diamond":{"score":20.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"xpert-bench":{"score":50.5,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-k12":{"score":56.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-compositional":{"score":63.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-classification":{"score":50.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-extraction":{"score":21.3,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"world-travel-vlm":{"score":32.67,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"world-travel-text":{"score":69,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"livebench":{"score":75.96,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":47.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":49.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":91.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":58,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":74,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":87.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":47,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"}]},"$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:21:variants:0",{"id":"claude-sonnet-4-5","name":"Claude Sonnet 4.5","provider":"Anthropic","releaseDate":"2025-11-24","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Unknown","pricing":{"input":3,"output":15,"cacheInput":0.3,"cacheOutput":3.75}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-07","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelCardUrl":"https://www.anthropic.com/news/claude-sonnet-4-5","modelUrl":"https://www.anthropic.com/claude/sonnet","scores":{"mmlu":{"score":89.8,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":72.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livebench":{"score":53.69,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"human-eval":{"score":93.5,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":77.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1451,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"aa-coding-index":{"score":33.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":37.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":37,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":37,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":7.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":42.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":51.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":59,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":86,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":42.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":70.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":28.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":[{"id":"claude-sonnet-4-5-high","name":"Claude Sonnet 4.5 High","provider":"Anthropic","releaseDate":"2025-11-24","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":300000,"parameters":"Unknown","pricing":{"input":3,"output":15,"cacheInput":0.3,"cacheOutput":3.75}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-07","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"claude-sonnet-4-5","modelUrl":"https://www.anthropic.com/claude/sonnet","scores":{"mmlu-pro":{"score":87.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livebench":{"score":75.47,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"hle":{"score":17.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2026":{"score":65.5,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"aime-2025":{"score":88,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"codeforces":{"score":1485,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":83.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"arc-agi-1":{"score":70.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"arc-agi-2":{"score":13.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"terminal-bench":{"score":42.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"swe-lancer":{"score":45.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":77.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"multi-swe-bench":{"score":47.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-bench-pro":{"score":48.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-multilingual":{"score":64.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"swe-evo":{"score":16.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"artifactsbench":{"score":59.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"codesimpleqa":{"score":59.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"spreadsheetbench-verified":{"score":75.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"browsecomp":{"score":43.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"browsecomp-zh":{"score":42.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"hle-text":{"score":65.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"hle-verified":{"score":58.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"widesearch":{"score":58.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"finsearchcomp":{"score":2.67,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"deepsearchqa":{"score":51.4,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"mmmu-pro":{"score":68,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"screenspot-pro":{"score":36.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"charxiv-reasoning":{"score":68.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"omnidocbench-15":{"score":0.145,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"videommmu":{"score":77.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livecodebench-pro":{"score":1418,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"tau-bench":{"score":87.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"toolathlon":{"score":38.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mcp-atlas":{"score":43.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"vending-bench-2":{"score":3839,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"facts-benchmark":{"score":48.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"simpleqa-verified":{"score":29.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmlu":{"score":89.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"global-piqa":{"score":90.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mrcr-v2":{"score":47.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"seal-0":{"score":37.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tau-bench-telecom":{"score":78.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"bfcl-v4":{"score":32.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"vitabench":{"score":72.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"deepconsult":{"score":55.8,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"researchrubrics":{"score":38.6,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"scicode":{"score":44.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"frontiersci-research":{"score":16.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"biobench":{"score":44.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"ainstein-bench":{"score":33.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"vibe-coding":{"score":59.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"nl2repo-bench":{"score":39.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"nl2repo-pass1":{"score":3,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"cl-bench":{"score":61,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-complex":{"score":57.3,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-reference":{"score":58.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"healthbench-hard":{"score":10.9,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"gdpval-diamond":{"score":15.2,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"xpert-bench":{"score":44.7,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-k12":{"score":50.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-compositional":{"score":64.5,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-classification":{"score":48.3,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"tob-extraction":{"score":10,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"world-travel-vlm":{"score":14,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"world-travel-text":{"score":59.1,"verified":true,"verificationLevel":"$undefined","sourceId":"anthropic-news","asOfDate":"$undefined"},"aa-coding-index":{"score":38.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":42.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":88,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":57.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":65.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":71.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":35.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"}]},"$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:23:variants:0",{"id":"google-gemini-1-5-pro","name":"Gemini 1.5 Pro","provider":"Google DeepMind","releaseDate":"2024-02-15","capabilities":["text","code","vision","audio","video"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":2000000,"parameters":"MoE","pricing":{"input":3.5,"output":10.5}},"scores":{"mmlu":{"score":85.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":46.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"math":{"score":67.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"human-eval":{"score":84.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"mmmu":{"score":62.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"lmarena-elo":{"score":1265,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"google-gemini-2-5-pro","name":"Gemini 2.5 Pro","provider":"Google DeepMind","releaseDate":"2025-06-25","capabilities":["text","code","vision","audio","video"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":2000000,"parameters":"Unknown","pricing":{"input":1.25,"output":5}},"scores":{"mmlu":{"score":89.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"hle":{"score":21.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"arc-agi-2":{"score":4.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"gpqa-diamond":{"score":86.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"aime-2025":{"score":88,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmu-pro":{"score":68,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"screenspot-pro":{"score":11.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"charxiv-reasoning":{"score":69.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"omnidocbench-15":{"score":0.145,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"videommmu":{"score":83.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livecodebench-pro":{"score":1775,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"terminal-bench":{"score":32.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"swe-bench-verified":{"score":59.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"tau-bench":{"score":77.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"toolathlon":{"score":10.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mcp-atlas":{"score":8.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"vending-bench-2":{"score":574,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"facts-benchmark":{"score":63.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"simpleqa-verified":{"score":54.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmlu":{"score":89.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"global-piqa":{"score":91.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mrcr-v2":{"score":58,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"phybench":{"score":36.87,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"livebench":{"score":58.33,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"},{"id":"gemini-2.5-flash","name":"Gemini 2.5 Flash","provider":"Google DeepMind","releaseDate":"2025-06-25","capabilities":["text","code","vision","audio"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Speed Optimized","pricing":{"input":0.3,"output":2.5}},"scores":{"hle":{"score":11,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"arc-agi-2":{"score":2.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"gpqa-diamond":{"score":82.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"aime-2025":{"score":72,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmu-pro":{"score":66.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"screenspot-pro":{"score":3.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"charxiv-reasoning":{"score":63.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"omnidocbench-15":{"score":0.154,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"videommmu":{"score":79.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livecodebench-pro":{"score":1143,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"terminal-bench":{"score":16.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"swe-bench-verified":{"score":60.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"tau-bench":{"score":79.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"toolathlon":{"score":3.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mcp-atlas":{"score":3.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"vending-bench-2":{"score":549,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"facts-benchmark":{"score":50.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"simpleqa-verified":{"score":28.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmlu":{"score":86.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"global-piqa":{"score":90.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mrcr-v2":{"score":54.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livebench":{"score":53.09,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"},{"id":"google-gemini-2-0-flash","name":"Gemini 2.0 Flash","provider":"Google DeepMind","releaseDate":"2024-12-11","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Multimodal Live","pricing":{"input":0.1,"output":0.4}},"scores":{"mmlu":{"score":84.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"agentbench":{"score":93.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"swe-bench-verified":{"score":35.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"gemini-3-pro","name":"Gemini 3 Pro","provider":"Google DeepMind","releaseDate":"2025-11-18","capabilities":["text","code","vision","audio","video","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Unknown","pricing":{"input":2,"output":12,"cacheInput":0.5,"cacheOutput":3}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-11","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelCardUrl":"https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf","modelUrl":"https://deepmind.google/models/gemini/pro/","scores":{"mmlu":{"score":91.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmlu-pro":{"score":89.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmmlu":{"score":91.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"gpqa-diamond":{"score":90.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":95.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"matharena-apex":{"score":23.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"swe-bench-verified":{"score":76.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmu-pro":{"score":81,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"videommmu":{"score":87.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"hle":{"score":37.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle-full-tools":{"score":45.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"arc-agi-2":{"score":31.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"terminal-bench":{"score":54.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livecodebench-pro":{"score":2439,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"tau-bench":{"score":90.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"vending-bench-2":{"score":5478,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"facts-benchmark":{"score":70.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"simpleqa-verified":{"score":72.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"global-piqa":{"score":93.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mrcr-v2":{"score":77,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"screenspot-pro":{"score":72.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livebench":{"score":73.39,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"charxiv-reasoning":{"score":81.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"omnidocbench-15":{"score":0.115,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mcp-atlas":{"score":54.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"toolathlon":{"score":36.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"aa-coding-index":{"score":46.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":48.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":95.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":70.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":70.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":91.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":56.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":87.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":41.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":[{"id":"gemini-3-pro-high","name":"Gemini 3 Pro High","provider":"Google DeepMind","releaseDate":"2025-11-18","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":2000000,"parameters":"Unknown","pricing":{"input":2,"output":12,"cacheInput":0.5,"cacheOutput":3}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-11","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"gemini-3-pro","modelCardUrl":"https://deepmind.google/models/model-cards/gemini-3-pro","modelUrl":"https://deepmind.google/models/gemini/pro/","scores":{"mmlu-pro":{"score":90.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"hle":{"score":33.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"aime-2026":{"score":73.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"aime-2025":{"score":64.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"codeforces":{"score":2726,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":91.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"arc-agi-1":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"putnam-200":{"score":26.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"aa-omniscience":{"score":13,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"critpt":{"score":9.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"mathvista":{"score":89.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"mmmu-vision":{"score":87,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"logicvista":{"score":80.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"blink":{"score":77.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"chartqapro":{"score":69,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"ocrbench-v2":{"score":94.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"frontiersci-olympiad":{"score":71,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"videommmu":{"score":88.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"videomme":{"score":85.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tvbench":{"score":71.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"ovbench":{"score":62.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"terminal-bench":{"score":56.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"swe-lancer":{"score":44.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"swe-bench-verified":{"score":76.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"multi-swe-bench":{"score":50.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"swe-bench-pro":{"score":49.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"swe-multilingual":{"score":72.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"swe-evo":{"score":8.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"artifactsbench":{"score":58.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"codesimpleqa":{"score":54.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"spreadsheetbench-verified":{"score":70.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"browsecomp":{"score":59.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"browsecomp-zh":{"score":66.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"hle-text":{"score":67.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"hle-verified":{"score":52.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"widesearch":{"score":63.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"finsearchcomp":{"score":8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"deepsearchqa":{"score":47.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"seal-0":{"score":67.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tau-bench":{"score":85.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tau-bench-telecom":{"score":98,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"bfcl-v4":{"score":53.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"vitabench":{"score":71,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"deepconsult":{"score":48,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"researchrubrics":{"score":37.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"minedojo-verified":{"score":23.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"hle-vl":{"score":36,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"scicode":{"score":57.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"frontiersci-research":{"score":15,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"biobench":{"score":51.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"ainstein-bench":{"score":42.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"vibe-coding":{"score":58.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"nl2repo-bench":{"score":34.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"nl2repo-pass1":{"score":4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"cl-bench":{"score":69.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tob-complex":{"score":64.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tob-reference":{"score":68.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"healthbench-hard":{"score":15,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"gdpval-diamond":{"score":19.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"xpert-bench":{"score":53.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tob-k12":{"score":59.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tob-compositional":{"score":67.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tob-classification":{"score":49,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"tob-extraction":{"score":14.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"world-travel-vlm":{"score":10,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"world-travel-text":{"score":52,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"}},"variants":"$undefined"}]},"$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:29:variants:0",{"id":"gemini-3.1-pro","name":"Gemini 3.1 Pro","provider":"Google DeepMind","releaseDate":"2026-02-19","capabilities":["text","code","vision","audio","video","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Unknown","pricing":{"input":2.5,"output":15}},"scores":{"gpqa-diamond":{"score":94.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"swe-bench-verified":{"score":80.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"swe-bench-pro":{"score":54.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"arc-agi-2":{"score":77.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"terminal-bench":{"score":68.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"mrcr-v2":{"score":84.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"mmmlu":{"score":92.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"mmmu-pro":{"score":80.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"browsecomp":{"score":85.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"tau-bench-retail":{"score":90.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"tau-bench-telecom":{"score":99.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"scicode":{"score":59,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"hle":{"score":44.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"},"livecodebench-pro":{"score":2887,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini31-announce","asOfDate":"2026-02-19"}},"variants":"$undefined"},{"id":"gemini-3-flash","name":"Gemini 3 Flash","provider":"Google DeepMind","releaseDate":"2025-12-17","capabilities":["text","code","vision","audio"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Speed Optimized","pricing":{"input":0.5,"output":3,"cacheInput":0.125,"cacheOutput":0.75}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-11","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"gemini-3-flash-preview","modelUrl":"https://deepmind.google/models/gemini/flash/","scores":{"hle":{"score":14.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle-full-tools":{"score":43.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"arc-agi-2":{"score":33.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"gpqa-diamond":{"score":81.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":55.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmmu-pro":{"score":81.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"screenspot-pro":{"score":69.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"charxiv-reasoning":{"score":80.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"omnidocbench-15":{"score":0.121,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"videommmu":{"score":86.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livecodebench-pro":{"score":2316,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"terminal-bench":{"score":47.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"swe-bench-verified":{"score":78,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"tau-bench":{"score":90.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"toolathlon":{"score":49.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mcp-atlas":{"score":57.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"vending-bench-2":{"score":3635,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"facts-benchmark":{"score":61.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"simpleqa-verified":{"score":68.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmlu":{"score":91.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"global-piqa":{"score":92.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mrcr-v2":{"score":67.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livebench":{"score":72.4,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":37.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":35.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":55.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":55.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":48,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":79.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":88.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":49.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":43.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":31.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":[{"id":"gemini-3-flash-high","name":"Gemini 3 Flash High","provider":"Google DeepMind","releaseDate":"2025-12-17","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Unknown","pricing":{"input":0.5,"output":3,"cacheInput":0.125,"cacheOutput":0.75}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-11","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"gemini-3-flash-preview","modelUrl":"https://deepmind.google/models/gemini/flash/","scores":{"mmlu-pro":{"score":89,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":34.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2026":{"score":93.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"aime-2025":{"score":97,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"codeforces":{"score":2727,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":89.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"arc-agi-1":{"score":86.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"aa-coding-index":{"score":42.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":46.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":97,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":78,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":66.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":90.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":50.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":80.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":38.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"}]},"$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:32:variants:0",{"id":"google-gemini-3-deep-think","name":"Gemini 3 Deep Think","provider":"Google DeepMind","releaseDate":"2026-02-12","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Unknown","pricing":{"input":2,"output":12}},"scores":{"mmlu":{"score":91.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"gpqa-diamond":{"score":93.8,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"math":{"score":96,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"swe-bench-verified":{"score":76.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"mmmu":{"score":81,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"hle":{"score":41,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"arc-agi-2":{"score":45.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"lmarena-elo":{"score":1506,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"nano-banana-pro","name":"Nano Banana Pro","provider":"Google DeepMind","releaseDate":"2025-12-01","capabilities":["text","code"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":32000,"parameters":"On-device reasoning","pricing":{"input":0,"output":0}},"trainingCutoff":"2024-01","metadataSourceId":"google-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://storage.googleapis.com/deepmind-media/gemini/gemini_1_5_report.pdf","modelUrl":"https://deepmind.google/technologies/gemini/","scores":{"mmlu":{"score":72,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"},"gsm8k":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"google-ai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"meta-llama-3-1-405b","name":"Llama 3.1 405B","provider":"Meta","releaseDate":"2024-07-23","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"405B","pricing":{"input":3,"output":3}},"scores":{"mmlu":{"score":88.6,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"gpqa-diamond":{"score":50.7,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"math":{"score":73,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"human-eval":{"score":89,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"mmmu":{"score":54,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"gsm8k":{"score":96.8,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"lmarena-elo":{"score":1261,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"meta-llama-3-3-70b","name":"Llama 3.3 70B","provider":"Meta","releaseDate":"2024-12-06","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"70B","pricing":{"input":0.2,"output":0.2}},"trainingCutoff":"2023-12","metadataSourceId":"meta-docs","metadataAsOfDate":"2026-02-17","modelUrl":"https://llama.meta.com/","scores":{"mmlu":{"score":88.6,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"math":{"score":73,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"human-eval":{"score":89,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"meta-llama-4-behemoth","name":"Llama 4 Behemoth","provider":"Meta","releaseDate":"2026-01-14","capabilities":["text","code","vision"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Hybrid Dense/MoE","pricing":{"input":2.5,"output":7.5}},"scores":{"mmlu":{"score":85.8,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"mmlu-pro":{"score":82.2,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"gpqa-diamond":{"score":69.8,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"math":{"score":84.5,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"human-eval":{"score":88.9,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"mmmu":{"score":76.1,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"swe-bench-verified":{"score":48.2,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"lmarena-elo":{"score":1310,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"meta-llama-4-maverick","name":"Llama 4 Maverick","provider":"Meta","releaseDate":"2025-09-30","capabilities":["text","code","vision"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":256000,"parameters":"MoE optimized","pricing":{"input":0.15,"output":0.6}},"scores":{"mmlu":{"score":87,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"mmlu-pro":{"score":80.5,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"gpqa-diamond":{"score":67.1,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"math-500":{"score":88.9,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"human-eval":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"livecodebench-v6":{"score":43.4,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"mathvista":{"score":73.7,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"docvqa":{"score":94.4,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"lmarena-elo":{"score":1401,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"meta-llama-4-scout","name":"Llama 4 Scout","provider":"Meta","releaseDate":"2026-01-14","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"High Efficiency","pricing":{"input":0.08,"output":0.3}},"scores":{"mmlu":{"score":79.4,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"gpqa-diamond":{"score":58.7,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"math":{"score":62,"verified":true,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"human-eval":{"score":81.2,"verified":false,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"mmmu":{"score":60.5,"verified":false,"verificationLevel":"$undefined","sourceId":"meta-ai","asOfDate":"$undefined"},"lmarena-elo":{"score":1285,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"deepseek-v3","name":"DeepSeek V3","provider":"DeepSeek","releaseDate":"2024-12-26","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"671B MoE","pricing":{"input":0.15,"output":0.75,"cacheInput":0.028}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-10","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"deepseek-v3.2","modelCardUrl":"https://arxiv.org/pdf/2412.19437.pdf","modelUrl":"https://api-docs.deepseek.com/","scores":{"mmlu":{"score":88.5,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"math":{"score":90.2,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"human-eval":{"score":91.6,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"bigcodebench":{"score":34.5,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"superchem":{"score":40,"verified":false,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1421,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aa-coding-index":{"score":16.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":16.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":26,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":25.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":26,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":55.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":3.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":34.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":29,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":35.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":88.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":75.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":35.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":22.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":6.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"deepseek-v3-1-terminus","name":"DeepSeek-V3.1-Terminus","provider":"DeepSeek","releaseDate":"2025-09-22","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Terminal Reasoning","pricing":{"input":0.02,"output":0.08}},"trainingCutoff":"2025-10","metadataSourceId":"deepseek-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf","modelUrl":"https://github.com/deepseek-ai/DeepSeek-V3","scores":{"math":{"score":93.4,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"human-eval":{"score":90,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aa-coding-index":{"score":31.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":28.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":53.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":53.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":75.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":8.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":41.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":43.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":52.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":83.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":32.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":37.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":31.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"deepseek-v3-2-speciale","name":"DeepSeek-V3.2-Speciale","provider":"DeepSeek","releaseDate":"2025-12-01","capabilities":["text","code","vision"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":256000,"parameters":"Dense Enhanced","pricing":{"input":0.27,"output":0.41,"cacheInput":0.028}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-10","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"deepseek-v3.2","modelCardUrl":"https://arxiv.org/pdf/2412.19437.pdf","modelUrl":"https://chat.deepseek.com","scores":{"mmlu":{"score":88.5,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":87.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"matharena-apex":{"score":76.5,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"livebench":{"score":62.2,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aime-2025":{"score":96.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"codeforces":{"score":2701,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":73.1,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"mmmu":{"score":74,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"hle":{"score":26.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench":{"score":39.3,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1423,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aa-coding-index":{"score":37.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":34.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":96.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":63.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":59.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":89.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":86.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":44,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":0,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":34.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"deepseek-r1","name":"DeepSeek R1","provider":"DeepSeek","releaseDate":"2025-01-20","capabilities":["text","code","reasoning"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Reasoning Flagship","pricing":{"input":0.14,"output":0.28,"cacheInput":0}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-12","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelCardUrl":"https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf","modelUrl":"https://github.com/deepseek-ai/DeepSeek-R1","scores":{"mmlu":{"score":88.1,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":81.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math":{"score":97.3,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":49.2,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aime":{"score":89.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"codeforces":{"score":2029,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1325,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aa-coding-index":{"score":24,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":27,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":76,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":76,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":14.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":39.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":54.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":77,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":98.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":84.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":40.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":36.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":15.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"deepseek-r1-zero","name":"DeepSeek-R1-Zero","provider":"DeepSeek","releaseDate":"2025-01-20","capabilities":["text","code","reasoning"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Reinforcement Learning Only","pricing":{"input":0.14,"output":0.28,"cacheInput":0}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-12","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"deepseek-r1","modelCardUrl":"https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf","modelUrl":"https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero","scores":{"mmlu":{"score":79.8,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"2025-01-20"},"gpqa-diamond":{"score":72,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math":{"score":88.5,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"2025-01-20"},"aime":{"score":71,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"2025-01-20"},"human-eval":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"swe-bench-verified":{"score":45.2,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lmarena-elo":{"score":1380,"verified":true,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"2026-02-18"}},"variants":"$undefined"},{"id":"deepseek-r1-distill-llama-70b","name":"DeepSeek-R1-Distill-Llama-70B","provider":"DeepSeek","releaseDate":"2025-01-20","capabilities":["text","code","reasoning"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":131072,"parameters":"70B (Distilled)","pricing":{"input":0.03,"output":0.11,"cacheInput":0}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-12","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"deepseek-r1","modelCardUrl":"https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf","modelUrl":"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B","scores":{"math":{"score":94.5,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aime":{"score":67,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"codeforces":{"score":1633,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"mmlu":{"score":82,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aa-coding-index":{"score":11.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":16,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":53.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":53.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":40.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":6.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":27.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":11,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":26.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":93.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":79.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":31.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":21.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":1.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"deepseek-r1-distill-qwen-32b","name":"DeepSeek-R1-Distill-Qwen-32B","provider":"DeepSeek","releaseDate":"2025-01-20","capabilities":["text","code","reasoning"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"32B (Distilled)","pricing":{"input":0.07,"output":0.14,"cacheInput":0}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-12","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"deepseek-r1","modelCardUrl":"https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf","modelUrl":"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","scores":{"mmlu":{"score":83,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"math":{"score":88,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aa-intelligence-index":{"score":17.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":63,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":68.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":63,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":61.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":5.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":22.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":9.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":27,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":94.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":73.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":37.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"command-r-plus-08-2024","name":"Command R+ (08-2024)","provider":"Cohere","releaseDate":"2024-08-01","capabilities":["text","code"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"128B","pricing":{"input":2.5,"output":10}},"trainingCutoff":"2024-08","metadataSourceId":"cohere-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://cohere.com/blog/command-r-plus-microsoft-azure","modelUrl":"https://docs.cohere.com/docs/command-r-plus","scores":{"mmlu":{"score":83,"verified":true,"verificationLevel":"$undefined","sourceId":"cohere-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":45,"verified":true,"verificationLevel":"$undefined","sourceId":"cohere-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1310,"verified":true,"verificationLevel":"$undefined","sourceId":"cohere-news","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"command-a","name":"Command A","provider":"Cohere","releaseDate":"2025-05-01","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":256000,"parameters":"Proprietary","pricing":{"input":1,"output":4}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-03","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelCardUrl":"https://cohere.com/research/papers/command-a-technical-report.pdf","modelUrl":"https://docs.cohere.com/docs/command-a","scores":{"mmlu":{"score":83,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"mmlu-pro":{"score":71.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":52.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":81.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"human-eval":{"score":84.5,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"mmmu":{"score":62.4,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"lmarena-elo":{"score":1310,"verified":true,"verificationLevel":"$undefined","sourceId":"cohere-news","asOfDate":"$undefined"},"aa-coding-index":{"score":9.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":13.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":13,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":9.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":13,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":4.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":36.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":18,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":28.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":28.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":15.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":0.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"jamba-2-large","name":"Jamba 2 Large","provider":"AI21","releaseDate":"2025-03-01","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":256000,"parameters":"399B (Hybrid SSM/Transformer)","pricing":{"input":2,"output":8}},"trainingCutoff":"2024-03","metadataSourceId":"ai21-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://arxiv.org/pdf/2403.19887.pdf","modelUrl":"https://www.ai21.com/blog/jamba-2-large-and-mini","scores":{"mmlu":{"score":86.5,"verified":true,"verificationLevel":"$undefined","sourceId":"ai21-news","asOfDate":"$undefined"},"gsm8k":{"score":90,"verified":true,"verificationLevel":"$undefined","sourceId":"ai21-news","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"minimax-2-1","name":"MiniMax 2.1","provider":"Minimax","releaseDate":"2024-10-15","capabilities":["text","code"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Proprietary","pricing":{"input":0.15,"output":0.6}},"scores":{"mmlu":{"score":82,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"minimax-m2","name":"MiniMax M2","provider":"Minimax","releaseDate":"2025-04-10","capabilities":["text","code"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"MoE","pricing":{"input":0.2,"output":0.8}},"scores":{"mmlu":{"score":85.4,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"minimax-m2-5","name":"MiniMax 2.5","provider":"Minimax","releaseDate":"2026-02-12","capabilities":["text","code"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":200000,"parameters":"MoE Agent-RL","pricing":{"input":0.3,"output":1.2}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-06","metadataSourceId":"minimax-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf","modelUrl":"https://minimax-ai.chat/models/minimax-m2/","scores":{"swe-bench-verified":{"score":80.2,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"mmlu":{"score":89,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"livebench":{"score":60.14,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":37.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":42,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":84.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":19.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":71.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":66,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":42.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":95.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":34.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"kimi-k2","name":"Kimi K2","provider":"Moonshot AI","releaseDate":"2025-09-05","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Proprietary","pricing":{"input":0.5,"output":1.5}},"scores":{"mmlu-pro":{"score":82,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"livebench":{"score":48.1,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":[{"id":"kimi-k2-thinking","name":"Kimi K2 Thinking","provider":"Moonshot AI","releaseDate":"2025-11-10","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":1000000,"parameters":"Proprietary","pricing":{"input":1.5,"output":4.5}},"scores":{"mmlu-pro":{"score":86.5,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"math":{"score":92,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"livebench":{"score":61.59,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"}]},"$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:54:variants:0",{"id":"kimi-k2-5","name":"Kimi K2.5","provider":"Moonshot AI","releaseDate":"2026-01-20","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":10000000,"parameters":"Proprietary","pricing":{"input":0.23,"output":3}},"trainingCutoff":"2024-10","metadataSourceId":"moonshot-docs","metadataAsOfDate":"2026-02-18","modelCardUrl":"https://arxiv.org/pdf/2602.02276","modelUrl":"https://www.moonshot.ai/","scores":{"hle-full-tools":{"score":30.1,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"aime-2025":{"score":50.2,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"hmmt-feb-2025":{"score":36.9,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"imo-answerbench":{"score":92.8,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":87.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":89.3,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"simpleqa":{"score":44.1,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"verified-advancedif":{"score":63.1,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"longbench-v2":{"score":40.8,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"swe-bench-verified":{"score":76.8,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"swe-bench-pro":{"score":50.7,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"swe-multilingual":{"score":73,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"terminal-bench":{"score":50.8,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"paperbench-codedev":{"score":63.5,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"cybergym":{"score":41.3,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"scicode":{"score":49,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ojbench-cpp":{"score":57.4,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"livecodebench-v6":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"browsecomp":{"score":60.6,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"browsecomp-ctx-manage":{"score":74.9,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"browsecomp-agent-swarm":{"score":72.7,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"widesearch":{"score":77.1,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"widesearch-agent-swarm":{"score":67.8,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"deepsearchqa":{"score":57.4,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"finsearchcomp-t2-t3":{"score":41,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"seal-0":{"score":37,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"gdpval-aa":{"score":65.8,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"mmmu-pro":{"score":78.5,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"mmmu-val":{"score":84.3,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"charxiv-rq":{"score":77.5,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"mathvision":{"score":84.2,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"mathvista-mini":{"score":90.1,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"simplevqa":{"score":71.2,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"worldvqa":{"score":46.3,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"zerobench":{"score":11,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"zerobench-tools":{"score":36.5,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"babyvision":{"score":78.9,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"blink":{"score":87,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"mmvp":{"score":88.8,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"omnidocbench":{"score":92.3,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"ocrbench":{"score":92.6,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"infovqa-test":{"score":74,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"videommmu":{"score":86.6,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"mmvu":{"score":80.4,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"motionbench":{"score":70.4,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"videomme":{"score":87.4,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"longvideobench":{"score":79.8,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"lvbench":{"score":75.9,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"osworld-verified":{"score":63.3,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"webarena":{"score":58.9,"verified":true,"verificationLevel":"$undefined","sourceId":"moonshot-news","asOfDate":"$undefined"},"livebench":{"score":69.07,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":39.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":46.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":29.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":70.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":65.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":95.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":34.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"glm-4-6","name":"GLM-4.6","provider":"Zhipu AI","releaseDate":"2025-09-30","capabilities":["text","code","vision"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":200000,"parameters":"355B MoE","pricing":{"input":0.1,"output":0.3}},"scores":{"mmlu":{"score":86.5,"verified":true,"verificationLevel":"$undefined","sourceId":"z-ai-blog","asOfDate":"2025-09-30"},"gpqa-diamond":{"score":78.2,"verified":true,"verificationLevel":"$undefined","sourceId":"llm-stats","asOfDate":"2026-02-18"},"human-eval":{"score":82,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math":{"score":71.5,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"swe-bench-verified":{"score":65.3,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lmarena-elo":{"score":1385,"verified":true,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"2026-02-18"},"livebench":{"score":55.19,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"},{"id":"glm-4-7","name":"GLM-4.7","provider":"Zhipu AI","releaseDate":"2025-12-22","capabilities":["text","code","vision"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":200000,"parameters":"400B MoE","pricing":{"input":0.15,"output":0.45}},"scores":{"mmlu":{"score":88.2,"verified":true,"verificationLevel":"$undefined","sourceId":"z-ai-blog","asOfDate":"2025-12-22"},"gpqa-diamond":{"score":85.7,"verified":true,"verificationLevel":"$undefined","sourceId":"llm-stats","asOfDate":"2026-02-18"},"math":{"score":75,"verified":true,"verificationLevel":"$undefined","sourceId":"z-ai-blog","asOfDate":"2025-12-22"},"human-eval":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"swe-bench-verified":{"score":70.2,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lmarena-elo":{"score":1410,"verified":true,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"2026-02-18"},"livebench":{"score":58.09,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"},{"id":"glm-5","name":"GLM-5","provider":"Zhipu AI","releaseDate":"2026-02-11","capabilities":["text","code","vision"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":200000,"parameters":"744B total, 40B active","pricing":{"input":1,"output":3.2,"cacheInput":0.2}},"trainingCutoff":"2024-06","metadataSourceId":"z-ai-blog","metadataAsOfDate":"2026-02-18","modelCardUrl":"https://arxiv.org/pdf/2602.15763","modelUrl":"https://z.ai/blog/glm-5","scores":{"mmlu":{"score":90.1,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"gpqa-diamond":{"score":82,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"human-eval":{"score":88,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"math":{"score":92.7,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"aime-2025":{"score":92.7,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"hle":{"score":27.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"swe-bench-verified":{"score":77.8,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"swe-bench-pro":{"score":52.3,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"terminal-bench":{"score":56.2,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"terminal-bench-hard":{"score":43.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"browsecomp":{"score":60.6,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"widesearch":{"score":77.1,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"vending-bench-2":{"score":4432,"verified":true,"verificationLevel":"$undefined","sourceId":"glm5-paper","asOfDate":"2026-02-17"},"tau-bench":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":98.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livebench":{"score":68.85,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-intelligence-index":{"score":49.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lmarena-elo":{"score":1452,"verified":true,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"2026-02-18"},"aa-coding-index":{"score":44.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":72.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":63.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":46.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"qwen-2-5-max","name":"Qwen 2.5 Max","provider":"Alibaba","releaseDate":"2025-01-29","capabilities":["text","code"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":131072,"parameters":"Unknown","pricing":{"input":1.6,"output":6.4}},"trainingCutoff":"2024-09","metadataSourceId":"qwen-docs","metadataAsOfDate":"2026-02-17","modelUrl":"https://qwenlm.github.io/blog/qwen2.5-max/","scores":{"mmlu":{"score":87.9,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"mmlu-pro":{"score":69,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"math":{"score":68.5,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"human-eval":{"score":73.2,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"qwen3-vl-235b-a22b","name":"Qwen3-VL-235B-A22B","provider":"Alibaba","releaseDate":"2025-09-21","capabilities":["text","code","vision","reasoning"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":262144,"parameters":"235B (22B active)","pricing":{"input":0.2,"output":0.88}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-04","metadataSourceId":"qwen-docs","metadataAsOfDate":"2026-02-17","modelUrl":"https://qwen.readthedocs.io/en/v3.0","scores":{"mmlu-pro":{"score":83.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math":{"score":87.1,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"aime-2025":{"score":88.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hmmt-feb-2025":{"score":45.8,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"imo-answerbench":{"score":97.3,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"gpqa-diamond":{"score":77.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"human-eval":{"score":88.4,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"osworld-verified":{"score":63.4,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"webarena":{"score":26.4,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"lmarena-elo":{"score":1320,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"},"livebench":{"score":48.84,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":20.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":27.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":88.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":10.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":56.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":58.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":64.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":39.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":54.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":11.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":[{"id":"qwen3-vl-235b-a22b-thinking","name":"Qwen3-VL-235B-A22B Thinking","provider":"Alibaba","releaseDate":"2025-09-21","capabilities":["text","code","vision","reasoning"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":262144,"parameters":"235B (22B active)","pricing":{"input":0,"output":0}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-04","metadataSourceId":"qwen-docs","metadataAsOfDate":"2026-02-17","modelUrl":"https://qwen.readthedocs.io/en/v3.0","scores":{"livebench":{"score":52.97,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"}},"variants":"$undefined"}]},"$0:f:0:1:0:props:children:1:props:children:1:props:children:props:children:props:children:props:children:2:props:models:61:variants:0",{"id":"qwen-3-5-397b-a17b","name":"Qwen 3.5 397B-A17B","provider":"Alibaba","releaseDate":"2026-02-16","capabilities":["text","code","vision","reasoning"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":262144,"parameters":"397B (17B active)","pricing":{"input":0.6,"output":3.6}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2026-01","metadataSourceId":"qwen-ai-blog","metadataAsOfDate":"2026-02-17","modelCardUrl":"https://qwen.ai/blog?id=qwen3.5","modelUrl":"https://huggingface.co/Qwen/Qwen3.5-397B-A17B","scores":{"mmlu-pro":{"score":87.8,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"supergpqa":{"score":70.4,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"math":{"score":74.1,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"gsm8k":{"score":93.7,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"ifeval":{"score":92.6,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"ifbench":{"score":76.5,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"multichallenge":{"score":67.6,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"swe-bench-verified":{"score":76.4,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"swe-multilingual":{"score":69.3,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"terminal-bench":{"score":52.5,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"mmmu":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"mmmu-pro":{"score":79,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"mathvision":{"score":88.6,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"mathvista-mini":{"score":90.3,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"videomme":{"score":87.5,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"videommmu":{"score":84.7,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"lvbench":{"score":75.5,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"mmvu":{"score":75.4,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"osworld-verified":{"score":62.2,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"livecodebench-v6":{"score":83.6,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"lcr":{"score":68.7,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"vitabench":{"score":49.7,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"realworldqa":{"score":83.9,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"mmstar":{"score":83.8,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"hallusionbench":{"score":71.4,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"ocrbench":{"score":93.1,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"omnidocbench":{"score":90.8,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"charxiv-rq":{"score":80.8,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"erqa":{"score":67.5,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"},"countbench":{"score":97.2,"verified":true,"verificationLevel":"$undefined","sourceId":"qwen-ai-blog","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"phi-4","name":"Phi-4","provider":"Microsoft","releaseDate":"2025-02-01","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"14B","pricing":{"input":0,"output":0,"cacheInput":0}},"providers":["Microsoft","GitHub"],"apiSupport":{"stream":true,"tools":false,"vision":false,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-06","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelUrl":"https://huggingface.co/microsoft/phi-4","scores":{"mmlu":{"score":82.3,"verified":true,"verificationLevel":"$undefined","sourceId":"microsoft-ai","asOfDate":"$undefined"},"math":{"score":78,"verified":true,"verificationLevel":"$undefined","sourceId":"microsoft-ai","asOfDate":"$undefined"},"gpqa-diamond":{"score":57.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lmarena-elo":{"score":1350,"verified":true,"verificationLevel":"$undefined","sourceId":"microsoft-ai","asOfDate":"$undefined"},"aa-coding-index":{"score":11.2,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":10.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":18,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":14.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":18,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":4.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":23.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":0,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":23.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":81,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":71.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":26,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":0,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":3.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"starcoder2-15b","name":"StarCoder2-15B","provider":"BigCode","releaseDate":"2024-02-28","capabilities":["code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":16000,"parameters":"15B","pricing":{"input":0,"output":0}},"trainingCutoff":"2024-02","metadataSourceId":"bigcode-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://arxiv.org/pdf/2402.19173.pdf","modelUrl":"https://huggingface.co/bigcode/starcoder2-15b","scores":{"mmlu":{"score":45.2,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":28.5,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"human-eval":{"score":72.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bigcode-project","asOfDate":"2024-02-28"},"bigcodebench":{"score":28.7,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":24.5,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lmarena-elo":{"score":1105,"verified":true,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"2026-02-18"}},"variants":"$undefined"},{"id":"dbrx-instruct","name":"DBRX Instruct","provider":"Databricks","releaseDate":"2024-03-27","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":32000,"parameters":"132B (MoE)","pricing":{"input":0.6,"output":2.4}},"trainingCutoff":"2023-12","metadataSourceId":"databricks-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://github.com/databricks/dbrx","modelUrl":"https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm","scores":{"mmlu":{"score":74.5,"verified":true,"verificationLevel":"$undefined","sourceId":"databricks-ai","asOfDate":"$undefined"},"human-eval":{"score":70.1,"verified":true,"verificationLevel":"$undefined","sourceId":"databricks-ai","asOfDate":"$undefined"},"gsm8k":{"score":72.8,"verified":true,"verificationLevel":"$undefined","sourceId":"databricks-ai","asOfDate":"$undefined"},"aa-intelligence-index":{"score":8.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"gpqa-diamond":{"score":33.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":6.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":9.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":27.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":39.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":11.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"internlm3-8b","name":"InternLM3-8B","provider":"Shanghai AI Lab","releaseDate":"2025-08-01","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":200000,"parameters":"8B","pricing":{"input":0,"output":0}},"trainingCutoff":"2025-01","metadataSourceId":"internlm-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://arxiv.org/pdf/2501.09030.pdf","modelUrl":"https://github.com/InternLM/InternLM","scores":{"mmlu":{"score":84,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"gpqa-diamond":{"score":54.2,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"math":{"score":20,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"aime":{"score":20,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"human-eval":{"score":82.3,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"mmmu":{"score":55.6,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"lmarena-elo":{"score":1210,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"yi-1-5-34b","name":"Yi-1.5-34B","provider":"01.AI","releaseDate":"2024-05-13","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":32000,"parameters":"34B","pricing":{"input":0,"output":0}},"trainingCutoff":"2024-03","metadataSourceId":"01ai-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://arxiv.org/pdf/2403.04652.pdf","modelUrl":"https://huggingface.co/01-ai/Yi-1.5-34B","scores":{"mmlu":{"score":81,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"gpqa-diamond":{"score":42.5,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"math":{"score":52.1,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"human-eval":{"score":76.4,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"mmmu":{"score":48.2,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"lmarena-elo":{"score":1240,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"baichuan-m3","name":"Baichuan-M3","provider":"Baichuan","releaseDate":"2026-01-15","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"235B","pricing":{"input":0.4,"output":1.2}},"trainingCutoff":"2024-03","metadataSourceId":"baichuan-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://baichuan-ai.com/Baichuan-M3-Technical-Report.pdf","modelUrl":"https://www.baichuan-ai.com/","scores":{"mmlu":{"score":88.5,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"gpqa-diamond":{"score":68.2,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"math":{"score":74.5,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"human-eval":{"score":86,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"mmmu":{"score":64.2,"verified":false,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"lmarena-elo":{"score":1290,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"snowflake-arctic","name":"Snowflake Arctic","provider":"Snowflake","releaseDate":"2024-04-24","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":4096,"parameters":"480B MoE (17B active)","pricing":{"input":0,"output":0}},"trainingCutoff":"2024-05","metadataSourceId":"snowflake-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://arxiv.org/pdf/2405.15593.pdf","modelUrl":"https://www.snowflake.com/en/data-cloud/arctic/","scores":{"mmlu":{"score":75,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"human-eval":{"score":38,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"lmarena-elo":{"score":1109,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"mistral-large-2","name":"Mistral Large 2","provider":"Mistral","releaseDate":"2024-07-24","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"123B","pricing":{"input":2,"output":6}},"trainingCutoff":"2024-07","metadataSourceId":"mistral-docs","metadataAsOfDate":"2026-02-17","modelUrl":"https://mistral.ai/news/mistral-large-2407/","scores":{"mmlu":{"score":84,"verified":true,"verificationLevel":"$undefined","sourceId":"mistral-news","asOfDate":"$undefined"},"math":{"score":76.6,"verified":true,"verificationLevel":"$undefined","sourceId":"mistral-news","asOfDate":"$undefined"},"human-eval":{"score":92,"verified":true,"verificationLevel":"$undefined","sourceId":"mistral-news","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"ministral-3b","name":"Ministral 3B","provider":"Mistral","releaseDate":"2024-10-16","capabilities":["text","code"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"3B","pricing":{"input":0.04,"output":0.04}},"apiSupport":{"stream":true,"tools":true,"vision":false,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-10","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"ministral-3b-latest","modelCardUrl":"https://docs.mistral.ai/models/ministral-3b-24-1","modelUrl":"https://mistral.ai/news/ministral-8b-ministral-3b/","scores":{"mmlu":{"score":68.8,"verified":true,"verificationLevel":"$undefined","sourceId":"mistral-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":29.7,"verified":false,"verificationLevel":"$undefined","sourceId":"mistral-news","asOfDate":"$undefined"},"math":{"score":33.3,"verified":true,"verificationLevel":"$undefined","sourceId":"mistral-news","asOfDate":"$undefined"},"human-eval":{"score":63.4,"verified":true,"verificationLevel":"$undefined","sourceId":"mistral-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1164,"verified":true,"verificationLevel":"$undefined","sourceId":"mistral-news","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"grok-4","name":"Grok-4","provider":"xAI","releaseDate":"2026-02-01","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":2000000,"parameters":"Ultra-Dense","pricing":{"input":3,"output":15}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-11","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelCardUrl":"https://data.x.ai/2025-08-20-grok-4-model-card.pdf","modelUrl":"https://docs.x.ai/developers/models/grok-4-0709","scores":{"mmlu":{"score":92,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":87.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"factscore":{"score":53.6,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"math":{"score":95,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"phybench":{"score":42.33,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"aime-2025":{"score":92.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":23.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle-full":{"score":26.9,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"arc-agi-2":{"score":15.9,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1410,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"livebench":{"score":62.02,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":40.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":41.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":92.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":94.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":53.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":68,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":81.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":99,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":86.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":45.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":74.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":37.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"grok-4-1-fast","name":"Grok-4.1-Fast","provider":"xAI","releaseDate":"2026-01-30","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":2000000,"parameters":"Efficiency Optimized","pricing":{"input":0.2,"output":0.5}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-09","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"grok-4-1-fast-non-reasoning","modelCardUrl":"https://data.x.ai/2025-08-20-grok-4-model-card.pdf","modelUrl":"https://docs.x.ai/developers/models/","scores":{"mmlu":{"score":85.4,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"hle":{"score":5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"arc-agi-2":{"score":17.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"gpqa-diamond":{"score":63.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":34.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmmu-pro":{"score":63,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"screenspot-pro":{"score":3.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"charxiv-reasoning":{"score":63.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"omnidocbench-15":{"score":0.154,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"videommmu":{"score":79.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"livecodebench-pro":{"score":1143,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"terminal-bench":{"score":16.9,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"swe-bench-verified":{"score":60.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"tau-bench":{"score":79.5,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"toolathlon":{"score":3.7,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mcp-atlas":{"score":3.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"vending-bench-2":{"score":549,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"facts-benchmark":{"score":50.4,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"simpleqa-verified":{"score":28.1,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mmmlu":{"score":86.6,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"global-piqa":{"score":90.2,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"mrcr-v2":{"score":54.3,"verified":true,"verificationLevel":"$undefined","sourceId":"google-gemini3-announce","asOfDate":"2025-11-18"},"factscore":{"score":97,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1280,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"livebench":{"score":59.99,"verified":true,"verificationLevel":"$undefined","sourceId":"livebench","asOfDate":"2026-02-20"},"aa-coding-index":{"score":19.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":23.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":34.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":36.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":22,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":39.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":74.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":29.6,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":63.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":14.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"grok-3","name":"Grok-3","provider":"xAI","releaseDate":"2025-02-15","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":131072,"parameters":"Proprietary","pricing":{"input":3,"output":15}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-11","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","modelUrl":"https://docs.x.ai/developers/models/","scores":{"mmlu":{"score":89.5,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"gpqa-diamond":{"score":69.3,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math":{"score":88.2,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"lmarena-elo":{"score":1380,"verified":true,"verificationLevel":"$undefined","sourceId":"xai-news","asOfDate":"$undefined"},"aa-coding-index":{"score":19.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-intelligence-index":{"score":25,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aa-math-index":{"score":58,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime":{"score":33,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"aime-2025":{"score":58,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"hle":{"score":5.1,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"ifbench":{"score":46.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"lcr":{"score":54.7,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"livecodebench-v6":{"score":42.5,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"math-500":{"score":87,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"mmlu-pro":{"score":79.9,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"scicode":{"score":36.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"tau-bench-telecom":{"score":48.8,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"},"terminal-bench-hard":{"score":11.4,"verified":true,"verificationLevel":"third_party","sourceId":"artificial-analysis","asOfDate":"2026-02-16"}},"variants":"$undefined"},{"id":"amazon-nova-pro","name":"Amazon Nova Pro","provider":"Amazon","releaseDate":"2024-12-01","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":300000,"parameters":"Proprietary","pricing":{"input":0.8,"output":3.2}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2024-10","metadataSourceId":"yamanahlawat-llm-registry","metadataSourceUrl":"https://github.com/yamanahlawat/llm-registry","metadataAsOfDate":"2026-02-07","externalModelId":"nova-pro","modelCardUrl":"https://assets.amazon.science/96/7d/0d3e59514abf8fdcfafcdc574300/nova-tech-report-20250317-0810.pdf","modelUrl":"https://docs.aws.amazon.com/nova/","scores":{"mmlu":{"score":83.4,"verified":true,"verificationLevel":"$undefined","sourceId":"amazon-nova","asOfDate":"$undefined"},"gpqa-diamond":{"score":44.2,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"math":{"score":64.7,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"human-eval":{"score":84.8,"verified":true,"verificationLevel":"$undefined","sourceId":"artificial-analysis","asOfDate":"$undefined"},"swe-bench-verified":{"score":35,"verified":true,"verificationLevel":"$undefined","sourceId":"amazon-nova","asOfDate":"$undefined"},"mmmu":{"score":64.1,"verified":true,"verificationLevel":"$undefined","sourceId":"amazon-nova","asOfDate":"$undefined"},"lmarena-elo":{"score":1268,"verified":true,"verificationLevel":"$undefined","sourceId":"amazon-nova","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"seed-2-0-pro","name":"Seed2.0 Pro","provider":"ByteDance","releaseDate":"2026-02-14","capabilities":["text","code","vision","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Unknown","pricing":{"input":0.47,"output":2.37}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-02","metadataSourceId":"seed-model-card","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/seed2/0214/Seed2.0%20Model%20Card.pdf","modelUrl":"https://seed.bytedance.com/en/seed2","scores":{"mmlu-pro":{"score":87,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"hle":{"score":36.8,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"math":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"aime-2026":{"score":54.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"aime-2025":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"codeforces":{"score":3020,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"gpqa-diamond":{"score":88.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"human-eval":{"score":95.4,"verified":false,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmmu":{"score":85.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"arc-agi-1":{"score":85.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"putnam-200":{"score":35.5,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"lmarena-elo":{"score":1415,"verified":false,"verificationLevel":"$undefined","sourceId":"lmarena","asOfDate":"$undefined"},"mathvista":{"score":89.8,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mathvision":{"score":81.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"dynamath":{"score":60.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mathkangaroo":{"score":90.5,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mathcanvas":{"score":61.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmmu-vision":{"score":85.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmmu-pro":{"score":73.2,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"emma":{"score":72,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"sfe":{"score":55.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"hipho":{"score":74.1,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"xlrs-bench":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"phyx":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"logicvista":{"score":81.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"vpct":{"score":61.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"zerobench-main":{"score":41.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"zerobench-sub":{"score":48.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"arc-agi-1-image":{"score":30.2,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"arc-agi-2-image":{"score":2.1,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"visulogic":{"score":54.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"vlms-are-biased":{"score":30.1,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"vlms-are-blind":{"score":85.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"visfactor":{"score":34.2,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"realworldqa":{"score":84.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"babyvision":{"score":51.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"simplevqa":{"score":70.8,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"hallusionbench":{"score":78.5,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mme-cc":{"score":87,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmstar":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"muirbench":{"score":48.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mtvqa":{"score":78.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"worldvqa":{"score":60.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"vibeeval":{"score":81.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"viverbench":{"score":82.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"countbench":{"score":95.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"fsc-147":{"score":30.2,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"point-bench":{"score":92.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"blink":{"score":78.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmsibench":{"score":30.1,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"treebench":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"refspatialbench":{"score":92.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"da-2k":{"score":70.8,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"all-angles":{"score":72.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"erqa":{"score":60.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"chartqapro":{"score":76.8,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"ocrbench-v2":{"score":95.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"omnidocbench":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"charxiv-dq":{"score":68.5,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"charxiv-rq":{"score":74,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"dude":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmlongbench":{"score":76.8,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"longdocurl":{"score":81.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmlongbench-doc":{"score":82.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"frontiersci-olympiad":{"score":83,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"videommmu":{"score":92.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmvu":{"score":81.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"videosimpleqa":{"score":78.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"videoreasonbench":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"morse-500":{"score":74.1,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"videoholmes":{"score":41.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"minerva":{"score":68.5,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"tvbench":{"score":81.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"contphy":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"tempcompass":{"score":92.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"egotempo":{"score":76.8,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"motionbench":{"score":85.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"tomato":{"score":76.8,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"videomme":{"score":95.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"cgbench":{"score":74,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"longvideobench":{"score":87,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"videoeval-pro":{"score":60.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"lvbench":{"score":84.3,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"crossvid":{"score":65.7,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"ovbench":{"score":74.1,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"livesports-3k":{"score":82.6,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"ovobench":{"score":72.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"odvbench":{"score":74.1,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"vispeak":{"score":87,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"seed-2-0-mini","name":"Seed2.0 Mini","provider":"ByteDance","releaseDate":"2026-02-14","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Unknown","pricing":{"input":0.1,"output":0.5}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-02","metadataSourceId":"seed-model-card","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/seed2/0214/Seed2.0%20Model%20Card.pdf","modelUrl":"https://seed.bytedance.com/en/seed2","scores":{"mmlu":{"score":84.5,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"math":{"score":60.2,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmmu":{"score":78.9,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"seed-2-0-lite","name":"Seed2.0 Lite","provider":"ByteDance","releaseDate":"2026-02-14","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Unknown","pricing":{"input":0.05,"output":0.25}},"apiSupport":{"stream":true,"tools":true,"vision":true,"jsonMode":true,"systemPrompt":true,"maxTokens":true,"temperature":true,"topP":true},"trainingCutoff":"2025-02","metadataSourceId":"seed-model-card","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/seed2/0214/Seed2.0%20Model%20Card.pdf","modelUrl":"https://seed.bytedance.com/en/seed2","scores":{"mmlu":{"score":81.2,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"math":{"score":55.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"deepseek-prover-v2","name":"DeepSeek-Prover-V2","provider":"DeepSeek","releaseDate":"2025-04-30","capabilities":["text","code","reasoning"],"isOpenSource":true,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Proof Optimized","pricing":{"input":0.1,"output":0.2}},"trainingCutoff":"2024-05","metadataSourceId":"deepseek-docs","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://arxiv.org/pdf/2405.14331.pdf","modelUrl":"https://github.com/deepseek-ai/DeepSeek-Prover-V2","scores":{"math":{"score":95.4,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"},"aime":{"score":88,"verified":true,"verificationLevel":"$undefined","sourceId":"deepseek-news","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"seed-1-5-prover","name":"Seed-1.5-Prover","provider":"ByteDance","releaseDate":"2025-12-05","capabilities":["text","code","reasoning"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Proof Optimized","pricing":{"input":0.2,"output":0.4}},"trainingCutoff":"2024-05","metadataSourceId":"seed-model-card","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/seed2/0214/Seed2.0%20Model%20Card.pdf","modelUrl":"https://seed.bytedance.com/","scores":{"math":{"score":94.2,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"aime":{"score":85,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"}},"variants":"$undefined"},{"id":"seed-1-8","name":"Seed-1.8","provider":"ByteDance","releaseDate":"2025-11-20","capabilities":["text","code","vision"],"isOpenSource":false,"modelType":"text","specs":{"contextWindow":128000,"parameters":"Unknown","pricing":{"input":0.15,"output":0.3}},"trainingCutoff":"2024-08","metadataSourceId":"seed-model-card","metadataAsOfDate":"2026-02-16","modelCardUrl":"https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/seed2/0214/Seed2.0%20Model%20Card.pdf","modelUrl":"https://seed.bytedance.com/","scores":{"mmlu":{"score":83.4,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"},"mmmu":{"score":76.5,"verified":true,"verificationLevel":"$undefined","sourceId":"bytedance-seed","asOfDate":"$undefined"}},"variants":"$undefined"}],"benchmarks":[{"id":"mmlu","name":"MMLU (5-shot)","category":"Knowledge","description":"Massive Multitask Language Understanding covers 57 subjects across STEM, the humanities, social sciences, and more.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu","paperUrl":"https://arxiv.org/abs/2009.03300"},{"id":"math","name":"MATH (CoT)","category":"Math","description":"Challenging competition mathematics problems (AIME/IMO level).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://paperswithcode.com/sota/math-word-problem-solving-on-math","paperUrl":"https://arxiv.org/abs/2103.03874"},{"id":"human-eval","name":"HumanEval","category":"Coding","description":"Functional correctness of synthesized programs from docstrings.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://paperswithcode.com/sota/code-generation-on-humaneval","paperUrl":"https://arxiv.org/abs/2107.03374"},{"id":"swe-bench-verified","name":"SWE-bench Verified","category":"Coding","description":"Resolving real-world GitHub issues. Verified subset ensures solvable issues.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://www.swebench.com/","paperUrl":"https://arxiv.org/abs/2310.06770"},{"id":"mmmu","name":"MMMU (Multimodal)","category":"Multimodal","description":"Multi-discipline Multimodal Understanding and Reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mmmu-benchmark.github.io/","paperUrl":"https://arxiv.org/abs/2311.16502"},{"id":"livebench","name":"LiveBench","category":"Reasoning","description":"Contamination-free, continuously updated reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://livebench.ai/#/","paperUrl":"https://arxiv.org/abs/2406.19314"},{"id":"bigcodebench","name":"BigCodeBench","category":"Coding","description":"Next-generation HumanEval with more diverse library calls and complex tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/bigcode-project/bigcodebench","paperUrl":"https://arxiv.org/abs/2406.15877"},{"id":"gsm8k","name":"GSM8K","category":"Math","description":"Grade school math word problems requiring multi-step reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/openai/grade-school-math","paperUrl":"https://arxiv.org/abs/2110.14168"},{"id":"aime","name":"AIME 2024/25","category":"Math","description":"American Invitational Mathematics Examination. Competition-level math.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artofproblemsolving.com/wiki/index.php/AIME"},{"id":"lmarena-elo","name":"LMArena ELO","category":"Real-world","description":"Chatbot Arena ELO score. Crowd-sourced human preference ranking.","maxScore":1700,"minScore":1000,"higherIsBetter":true,"normalization":"elo","unit":"ELO","link":"https://chat.lmsys.org/?leaderboard"},{"id":"aa-intelligence-index","name":"AA Intelligence Index","category":"Real-world","description":"Artificial Analysis aggregate intelligence index.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aa-intelligence-index"},{"id":"agentbench","name":"AgentBench","category":"Agent","description":"Comprehensive framework to evaluate LLMs as agents across diverse environments.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/THUDM/AgentBench","paperUrl":"https://arxiv.org/abs/2308.03688"},{"id":"mmlu-pro","name":"MMLU-Pro","category":"Science","description":"A more robust and harder version of MMLU, focusing on complex reasoning and STEM subjects.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro","paperUrl":"https://arxiv.org/abs/2406.01574"},{"id":"hle","name":"HLE","category":"Science","description":"Humanity's Last Exam - Hard reasoning benchmark without tools.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249"},{"id":"hle-full","name":"HLE-Full","category":"Science","description":"Humanity's Last Exam full evaluation without tools.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249"},{"id":"hle-full-tools","name":"HLE-Full (w/ tools)","category":"Science","description":"Humanity's Last Exam full evaluation with tool access enabled.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/","paperUrl":"https://arxiv.org/abs/2501.14249"},{"id":"critpt","name":"CritPt","category":"Science","description":"Complex Research using Integrated Thinking - Physics Test. Research-level physics reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arxiv.org/abs/2501.00663"},{"id":"simpleqa","name":"SimpleQA","category":"Science","description":"Open-domain factuality benchmark focusing on short, verifiable answers.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#simpleqa"},{"id":"simpleqa-verified","name":"SimpleQA Verified","category":"Knowledge","description":"Verified subset of SimpleQA for parametric knowledge evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#simpleqa-verified"},{"id":"healthbench","name":"HealthBench","category":"Science","description":"Medical knowledge and diagnostic reasoning evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#healthbench"},{"id":"supergpqa","name":"SuperGPQA","category":"Science","description":"Extremely difficult expert-level science questions.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#supergpqa"},{"id":"aime-2026","name":"AIME 2026","category":"Math","description":"Future prediction of AIME performance levels.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artofproblemsolving.com/wiki/index.php/AIME"},{"id":"aa-math-index","name":"AA Math Index","category":"Math","description":"Artificial Analysis aggregate math capability index.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aa-math-index"},{"id":"hmmt-feb-2025","name":"HMMT Feb 2025","category":"Math","description":"Harvard-MIT Mathematics Tournament - High difficulty competition math.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#hmmt-feb-2025"},{"id":"math-500","name":"MATH-500","category":"Math","description":"500-problem math benchmark for broad quantitative reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#math-500"},{"id":"imo-answerbench","name":"IMO-AnswerBench","category":"Math","description":"International Mathematical Olympiad style answer-only benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#imo-answerbench"},{"id":"matharena-apex","name":"MathArenaApex","category":"Math","description":"Competitive math arena for top-tier reasoning models.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#matharena-apex"},{"id":"codeforces","name":"Codeforces","category":"Coding","description":"Competitive programming rating based on problem solving.","maxScore":4000,"higherIsBetter":true,"normalization":"max","unit":"rating","link":"https://codeforces.com/"},{"id":"livecodebench-v6","name":"LiveCodeBench v6","category":"Coding","description":"Contamination-free coding benchmark using recent problems.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://livecodebench.github.io/","paperUrl":"https://arxiv.org/abs/2403.07974"},{"id":"livecodebench-pro","name":"LiveCodeBench Pro","category":"Coding","description":"Competitive programming problems from Codeforces, ICPC, and IOI with Elo rating.","maxScore":4000,"higherIsBetter":true,"normalization":"max","unit":"Elo","link":"https://livecodebenchpro.com/"},{"id":"aa-coding-index","name":"AA Coding Index","category":"Coding","description":"Artificial Analysis aggregate coding capability index.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aa-coding-index"},{"id":"paperbench-codedev","name":"PaperBench (CodeDev)","category":"Coding","description":"Research-grade coding and software development tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#paperbench-codedev"},{"id":"cybergym","name":"CyberGym","category":"Coding","description":"Cybersecurity-flavored coding benchmark in simulated environments.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#cybergym"},{"id":"ojbench-cpp","name":"OJBench (cpp)","category":"Coding","description":"Online-judge competitive coding benchmark focused on C++ tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ojbench-cpp"},{"id":"gpqa-diamond","name":"GPQA Diamond","category":"STEM","description":"Graduate-Level Google-Proof Q&A Benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://gpqa-benchmark.github.io/","paperUrl":"https://arxiv.org/abs/2311.12022"},{"id":"phybench","name":"Phybench","category":"STEM","description":"Physics reasoning and problem solving benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#phybench"},{"id":"arc-agi-1","name":"ARC-AGI-1","category":"Reasoning","description":"Abstraction and Reasoning Corpus - Level 1.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/","paperUrl":"https://arxiv.org/abs/1911.01547"},{"id":"mrcr-v2","name":"MRCR v2","category":"Long Context","description":"Multi-Round Context Retrieval - 8-needle test.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mrcr-v2"},{"id":"longbench-v2","name":"LongBench v2","category":"Long Context","description":"Comprehensive long-context understanding (128k).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longbench-v2"},{"id":"lcr","name":"AA-LCR","category":"Long Context","description":"Artificial Analysis Long Context Reasoning benchmark. Evaluates reasoning over long contexts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#lcr"},{"id":"mmmlu","name":"MMMLU","category":"Multilingual","description":"Massive Multilingual Language Understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arxiv.org/abs/2402.03300","paperUrl":"https://arxiv.org/abs/2402.03300"},{"id":"ifeval","name":"IFEval","category":"Instruction Following","description":"Instruction Following Evaluation for Large Language Models. Measures ability to follow strict formatting and constraint requirements.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://huggingface.co/spaces/yejinxie/IFEval","paperUrl":"https://arxiv.org/abs/2311.07911"},{"id":"ifeval-inverse","name":"Inverse IFEval","category":"Instruction Following","description":"Reverse instruction following evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ifeval-inverse"},{"id":"ifbench","name":"IFBench","category":"Instruction Following","description":"Artificial Analysis IFBench. Evaluates precise instruction following with constraints.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ifbench"},{"id":"verified-advancedif","name":"Verified AdvancedIF","category":"Instruction Following","description":"Advanced instruction-following benchmark with verified grading.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#verified-advancedif"},{"id":"longfact-concepts","name":"LongFact-Concepts","category":"Hallucination","description":"Factuality in long-form conceptual generations.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longfact-concepts"},{"id":"aa-omniscience","name":"AA-Omniscience","category":"Hallucination","description":"Evaluates model omniscience and factual reliability across diverse domains.","maxScore":100,"minScore":-100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#omniscience"},{"id":"aime-2025","name":"AIME 2025","category":"Math","description":"American Invitational Mathematics Examination 2025 problems.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artofproblemsolving.com/wiki/index.php/AIME"},{"id":"arc-agi-2","name":"ARC-AGI-2","category":"Reasoning","description":"Abstraction and Reasoning Corpus - Level 2 (Extreme difficulty).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/"},{"id":"factscore","name":"FactScore","category":"Hallucination","description":"Precision of fine-grained facts in long-form biographies.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#factscore"},{"id":"superchem","name":"Superchem","category":"STEM","description":"Expert-level chemistry knowledge and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#superchem"},{"id":"korbench","name":"KORBench","category":"Reasoning","description":"Korean reasoning and language understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#korbench"},{"id":"graphwalks-bfs","name":"Graphwalks Bfs","category":"Long Context","description":"Traversal-based long context reasoning using BFS (128k).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#graphwalks-bfs"},{"id":"global-piqa","name":"Global PIQA","category":"Multilingual","description":"Physical Interaction QA across multiple languages and cultures.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#global-piqa"},{"id":"multichallenge","name":"MultiChallenge","category":"Instruction Following","description":"Complex, multi-constraint instruction following tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#multichallenge"},{"id":"longfact-objects","name":"LongFact-Objects","category":"Hallucination","description":"Factuality in long-form generations about objects.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longfact-objects"},{"id":"putnam-200","name":"Putnam-200","category":"Math","description":"William Lowell Putnam Mathematical Competition problems - top 200 level difficulty.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#putnam-200"},{"id":"mathvista","name":"MathVista","category":"Vision","description":"Mathematical reasoning in visual contexts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mathvista.github.io/","paperUrl":"https://arxiv.org/abs/2310.02255"},{"id":"mathvista-mini","name":"MathVista (mini)","category":"Vision","description":"Compact MathVista split for faster multimodal reasoning checks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mathvista.github.io/"},{"id":"mathvision","name":"MathVision","category":"Vision","description":"Comprehensive mathematical vision benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mathvision"},{"id":"mmmu-vision","name":"MMMU","category":"Vision","description":"Massive Multi-discipline Multimodal Understanding and Reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mmmu-benchmark.github.io/"},{"id":"logicvista","name":"LogicVista","category":"Vision","description":"Logical reasoning in visual puzzles and diagrams.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#logicvista"},{"id":"blink","name":"BLINK","category":"Vision","description":"Spatial and perception benchmark for multimodal models.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#blink"},{"id":"mmvp","name":"MMVP","category":"Vision","description":"Multimodal visual perception benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmvp"},{"id":"chartqapro","name":"ChartQA Pro","category":"Vision","description":"Expert-level chart understanding and question answering.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#chartqapro"},{"id":"docvqa","name":"DocVQA","category":"Vision","description":"Document visual question answering on scanned and digital documents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://rrc.cvc.uab.es/?ch=17","paperUrl":"https://arxiv.org/abs/2007.00398"},{"id":"ocrbench-v2","name":"OCRBench v2","category":"Vision","description":"Next-gen optical character recognition and document understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://ocrbench.github.io/"},{"id":"ocrbench","name":"OCRBench","category":"Vision","description":"Optical character recognition and document understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://ocrbench.github.io/","paperUrl":"https://arxiv.org/abs/2312.16151"},{"id":"dynamath","name":"DynaMath","category":"Vision","description":"Dynamic mathematical reasoning in visual contexts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#dynamath"},{"id":"mathkangaroo","name":"MathKangaroo","category":"Vision","description":"Mathematical competition problems with visual elements.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mathkangaroo"},{"id":"mathcanvas","name":"MathCanvas","category":"Vision","description":"Multi-step mathematical reasoning on a canvas.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mathcanvas"},{"id":"mmmu-pro","name":"MMMU-Pro","category":"Vision","description":"Professional level MMMU expansion.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mmmu-benchmark.github.io/"},{"id":"mmmu-val","name":"MMMU (val)","category":"Vision","description":"Validation split of MMMU for multimodal understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://mmmu-benchmark.github.io/"},{"id":"emma","name":"EMMA","category":"Vision","description":"Expert-level Multimodal Mathematics Analysis.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#emma"},{"id":"sfe","name":"SFE","category":"Vision","description":"Scientific Figure Evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#sfe"},{"id":"hipho","name":"HiPhO","category":"Vision","description":"High-level Physics Olympiad (Vision).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#hipho"},{"id":"xlrs-bench","name":"XLRS-Bench","category":"Vision","description":"Cross-domain Logical Reasoning and Spatial benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#xlrs-bench"},{"id":"phyx","name":"PhyX","category":"Vision","description":"Physics reasoning with open-ended visual questions.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#phyx"},{"id":"vpct","name":"VPCT","category":"Vision","description":"Visual Perception and Coding Tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vpct"},{"id":"zerobench-main","name":"ZeroBench (main)","category":"Vision","description":"Zero-shot visual reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#zerobench-main"},{"id":"zerobench-sub","name":"ZeroBench (sub)","category":"Vision","description":"Zero-shot visual reasoning sub-tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#zerobench-sub"},{"id":"zerobench","name":"ZeroBench","category":"Vision","description":"Aggregate ZeroBench score across the full task set.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#zerobench"},{"id":"zerobench-tools","name":"ZeroBench (w/ tools)","category":"Vision","description":"ZeroBench score when tool use is allowed.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#zerobench-tools"},{"id":"arc-agi-1-image","name":"ArcAGI1-Image","category":"Vision","description":"ARC-AGI Level 1 tasks in image format.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/"},{"id":"arc-agi-2-image","name":"ArcAGI2-Image","category":"Vision","description":"ARC-AGI Level 2 tasks in image format.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arcprize.org/"},{"id":"visulogic","name":"VisuLogic","category":"Vision","description":"Visual logic and sequence reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#visulogic"},{"id":"vlms-are-biased","name":"VLMsAreBiased","category":"Vision","description":"Evaluating bias in Vision-Language Models.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vlms-are-biased"},{"id":"vlms-are-blind","name":"VLMsAreBlind","category":"Vision","description":"Evaluating perception failures in VLMs.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vlms-are-blind"},{"id":"visfactor","name":"VisFactor","category":"Vision","description":"Visual factor identification and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#visfactor"},{"id":"realworldqa","name":"RealWorldQA","category":"Vision","description":"Real-world visual question answering.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#realworldqa"},{"id":"babyvision","name":"BabyVision","category":"Vision","description":"Early-stage visual development benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#babyvision"},{"id":"hallusionbench","name":"HallusionBench","category":"Vision","description":"Visual hallucination and factuality benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#hallusionbench"},{"id":"mme-cc","name":"MME-CC","category":"Vision","description":"Multimodal Evaluation (Cognitive Capacity).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mme-cc"},{"id":"mmstar","name":"MMStar","category":"Vision","description":"Elite multimodal model evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmstar"},{"id":"muirbench","name":"MUIRBench","category":"Vision","description":"Multimodal Understanding and Interaction Benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#muirbench"},{"id":"mtvqa","name":"MTVQA","category":"Vision","description":"Multilingual Text-centric Visual QA.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mtvqa"},{"id":"worldvqa","name":"WorldVQA","category":"Vision","description":"Global visual knowledge and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#worldvqa"},{"id":"vibeeval","name":"VibeEval","category":"Vision","description":"Subjective and intuitive visual quality evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vibeeval"},{"id":"viverbench","name":"ViVerBench","category":"Vision","description":"Visual Verification and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#viverbench"},{"id":"countbench","name":"CountBench","category":"Vision","description":"Visual object counting and identification.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#countbench"},{"id":"fsc-147","name":"FSC-147","category":"Vision","description":"Few-shot counting benchmark (Lower is better handled in normalization).","maxScore":100,"higherIsBetter":false,"normalization":"inverse","unit":"error","link":"https://artificialanalysis.ai/evaluations#fsc-147"},{"id":"point-bench","name":"Point-Bench","category":"Vision","description":"Visual pointing and spatial grounding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#point-bench"},{"id":"mmsibench","name":"MMSIBench","category":"Vision","description":"Multimodal Spatial Interaction Benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmsibench"},{"id":"treebench","name":"TreeBench","category":"Vision","description":"Hierarchical visual reasoning tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#treebench"},{"id":"refspatialbench","name":"RefSpatialBench","category":"Vision","description":"Referential spatial reasoning evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#refspatialbench"},{"id":"da-2k","name":"DA-2K","category":"Vision","description":"Document Analysis and reasoning (2k).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#da-2k"},{"id":"all-angles","name":"All-Angles","category":"Vision","description":"Multi-perspective visual understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#all-angles"},{"id":"erqa","name":"ERQA","category":"Vision","description":"Environment Reasoning and Question Answering.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#erqa"},{"id":"omnidocbench","name":"OmniDocBench","category":"Vision","description":"Universal document understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#omnidocbench"},{"id":"omnidocbench-15","name":"OmniDocBench 1.5","category":"Vision","description":"OCR benchmark measuring edit distance (lower is better).","maxScore":1,"minScore":0,"higherIsBetter":false,"normalization":"inverse","unit":"edit distance","link":"https://artificialanalysis.ai/evaluations#omnidocbench-15"},{"id":"screenspot-pro","name":"ScreenSpot-Pro","category":"Vision","description":"Screen understanding benchmark for GUI interaction.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/octopus-tools/screenspot-pro"},{"id":"infovqa-test","name":"InfoVQA (test)","category":"Vision","description":"Information-seeking visual question answering on the test split.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#infovqa-test"},{"id":"charxiv-dq","name":"CharXiv-DQ","category":"Vision","description":"Chart-based reasoning from arXiv papers (Data QA).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#charxiv-dq"},{"id":"charxiv-rq","name":"CharXiv-RQ","category":"Vision","description":"Chart-based reasoning from arXiv papers (Reasoning QA).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#charxiv-rq"},{"id":"charxiv-reasoning","name":"CharXiv Reasoning","category":"Vision","description":"Information synthesis from complex charts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://arxiv.org/abs/2406.18521"},{"id":"dude","name":"DUDE","category":"Vision","description":"Document Understanding and Dialogue Evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#dude"},{"id":"mmlongbench","name":"MMLongBench","category":"Vision","description":"Multimodal Long context benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmlongbench"},{"id":"longdocurl","name":"LongDocURL","category":"Vision","description":"Long document understanding with URLs.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longdocurl"},{"id":"mmlongbench-doc","name":"MMLongBench-Doc","category":"Vision","description":"Multimodal Long context document evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmlongbench-doc"},{"id":"mmvu","name":"MMVU","category":"Video","description":"Multimodal Video Understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mmvu"},{"id":"videosimpleqa","name":"VideoSimpleQA","category":"Video","description":"Verifiable question answering for short video clips.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videosimpleqa"},{"id":"videoreasonbench","name":"VideoReasonBench","category":"Video","description":"Complex reasoning tasks in video content.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videoreasonbench"},{"id":"morse-500","name":"Morse-500","category":"Video","description":"Sequence reasoning and motion understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#morse-500"},{"id":"videoholmes","name":"VideoHolmes","category":"Video","description":"Deep diagnostic video understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videoholmes"},{"id":"minerva","name":"Minerva","category":"Video","description":"Long-form video reasoning and knowledge retrieval.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#minerva"},{"id":"contphy","name":"ContPhy","category":"Video","description":"Continuous Physics reasoning in video.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#contphy"},{"id":"tempcompass","name":"TempCompass","category":"Video","description":"Temporal orientation and perception in video.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tempcompass"},{"id":"egotempo","name":"EgoTempo","category":"Video","description":"First-person perspective temporal reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#egotempo"},{"id":"motionbench","name":"MotionBench","category":"Video","description":"Comprehensive motion perception evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#motionbench"},{"id":"tomato","name":"TOMATO","category":"Video","description":"Temporal Object-centric Multimodal Analysis.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tomato"},{"id":"cgbench","name":"CGBench","category":"Video","description":"Contextual Grounding in long videos.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#cgbench"},{"id":"longvideobench","name":"LongVideoBench","category":"Video","description":"Understanding extremely long-form video content.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#longvideobench"},{"id":"videoeval-pro","name":"VideoEval-Pro","category":"Video","description":"Professional level video quality and content evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videoeval-pro"},{"id":"lvbench","name":"LVBench","category":"Video","description":"Large-scale Video Benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#lvbench"},{"id":"crossvid","name":"CrossVid","category":"Video","description":"Cross-video temporal and relational reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#crossvid"},{"id":"livesports-3k","name":"LiveSports-3K","category":"Video","description":"Live sports broadcast understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#livesports-3k"},{"id":"ovobench","name":"OVOBench","category":"Video","description":"Object-Video-Object relational reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ovobench"},{"id":"odvbench","name":"ODVBench","category":"Video","description":"Open-Domain Video understanding.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#odvbench"},{"id":"vispeak","name":"ViSpeak","category":"Video","description":"Video-to-speech and dialogue reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vispeak"},{"id":"frontiersci-olympiad","name":"FrontierSci-olympiad","category":"STEM","description":"Scientific Olympiad level problems.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#frontiersci-olympiad"},{"id":"terminal-bench","name":"Terminal-Bench 2.0","category":"Agentic","description":"Agent performance in realistic terminal workflows (v2.0 leaderboard).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://www.tbench.ai/leaderboard/terminal-bench/2.0"},{"id":"terminal-bench-hard","name":"Terminal-Bench Hard","category":"Agentic","description":"Hard split of Terminal-Bench focused on tougher terminal workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://www.tbench.ai/leaderboard/terminal-bench/2.0"},{"id":"osworld-verified","name":"OSWorld-Verified","category":"Agentic","description":"Verified desktop computer-use benchmark for end-to-end task completion.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://os-world.github.io/"},{"id":"webarena","name":"WebArena","category":"Agentic","description":"Browser-based autonomous task execution benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://webarena.dev/","paperUrl":"https://arxiv.org/abs/2307.13854"},{"id":"swe-lancer","name":"SWE-Lancer","category":"Agentic","description":"Software engineering task completion in multi-step coding workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#swe-lancer"},{"id":"multi-swe-bench","name":"Multi-SWE-bench","category":"Agentic","description":"Multi-repository software engineering benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#multi-swe-bench"},{"id":"swe-bench-pro","name":"SWE-bench Pro","category":"Agentic","description":"Higher-difficulty SWE-bench subset for frontier coding agents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://www.swebench.com/"},{"id":"swe-multilingual","name":"SWE Multilingual","category":"Agentic","description":"Software engineering performance across multilingual codebases.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#swe-multilingual"},{"id":"swe-evo","name":"SWE-Evo","category":"Agentic","description":"Evolutionary coding benchmark focused on long-horizon bug fixing.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#swe-evo"},{"id":"aider-polyglot","name":"Aider Polyglot","category":"Agentic","description":"Multi-language coding agent benchmark with editor-in-the-loop tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#aider-polyglot"},{"id":"artifactsbench","name":"ArtifactsBench","category":"Agentic","description":"Agent ability to produce complete, runnable software artifacts.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#artifactsbench"},{"id":"codesimpleqa","name":"CodeSimpleQA","category":"Agentic","description":"Short-form coding QA with executable correctness checks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#codesimpleqa"},{"id":"spreadsheetbench-verified","name":"SpreadsheetBench Verified","category":"Agentic","description":"Verified spreadsheet manipulation and reasoning tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#spreadsheetbench-verified"},{"id":"browsecomp","name":"BrowseComp","category":"Agentic","description":"Web browsing + synthesis benchmark for research agents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/google-research/browsecomp"},{"id":"browsecomp-ctx-manage","name":"BrowseComp (ctx manage)","category":"Agentic","description":"BrowseComp variant with explicit context-window management.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#browsecomp-ctx-manage"},{"id":"browsecomp-agent-swarm","name":"BrowseComp (Agent Swarm)","category":"Agentic","description":"Multi-agent swarm variant of BrowseComp.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#browsecomp-agent-swarm"},{"id":"browsecomp-zh","name":"BrowseComp-ZH","category":"Agentic","description":"Chinese-language browsing and synthesis benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#browsecomp-zh"},{"id":"hle-text","name":"HLE-Text","category":"Agentic","description":"Text-only variant of Humanity's Last Exam under agentic settings.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/"},{"id":"hle-verified","name":"HLE-Verified","category":"Agentic","description":"Verified subset of Humanity's Last Exam for reproducible evaluation.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/"},{"id":"widesearch","name":"WideSearch","category":"Agentic","description":"Broad retrieval and synthesis benchmark across many sources.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#widesearch"},{"id":"widesearch-agent-swarm","name":"WideSearch (Agent Swarm)","category":"Agentic","description":"Multi-agent swarm variant of WideSearch.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#widesearch-agent-swarm"},{"id":"finsearchcomp","name":"FinSearchComp","category":"Agentic","description":"Finance-focused search and evidence-grounded answering benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#finsearchcomp"},{"id":"finsearchcomp-t2-t3","name":"FinSearchComp T2&T3","category":"Agentic","description":"Tier 2 and Tier 3 slices of FinSearchComp.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#finsearchcomp-t2-t3"},{"id":"vending-bench-2","name":"Vending-Bench 2","category":"Agentic","description":"Long-horizon business simulation benchmark (final account balance).","maxScore":10000,"minScore":0,"higherIsBetter":true,"normalization":"max","unit":"USD","link":"https://artificialanalysis.ai/evaluations#vending-bench-2"},{"id":"facts-benchmark","name":"FACTS Benchmark Suite","category":"Agentic","description":"Factuality benchmark across grounding, parametric, search, and multimodal.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/google-deepmind/facts-benchmark"},{"id":"mcp-atlas","name":"MCP Atlas","category":"Agentic","description":"Multi-step workflows using Model Context Protocol.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/modelcontextprotocol/mcp-atlas"},{"id":"toolathlon","name":"Toolathlon","category":"Agentic","description":"Long horizon real-world software tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/toolathlon/toolathlon"},{"id":"deepsearchqa","name":"DeepSearchQA","category":"Agentic","description":"Deep multi-hop search QA for long-horizon agents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#deepsearchqa"},{"id":"seal-0","name":"SEAL-0","category":"Agentic","description":"Strategic environment-agent loop benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#seal-0"},{"id":"gdpval-aa","name":"GDPVal-AA","category":"Agentic","description":"Artificial Analysis GDPVal benchmark for knowledge-work quality.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#gdpval-aa"},{"id":"tau-bench","name":"TAU-Bench","category":"Agentic","description":"Tool-use and API orchestration benchmark for assistants.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/sierra-research/tau2-bench"},{"id":"tau-bench-retail","name":"TAU-Bench Retail","category":"Agentic","description":"Retail-domain tool-use and workflow benchmark from -bench.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://taubench.com/"},{"id":"tau-bench-telecom","name":"TAU-Bench Telecom","category":"Agentic","description":"Telecom-domain tool-use and workflow benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/sierra-research/tau2-bench"},{"id":"mcp-mark","name":"MCP-Mark","category":"Agentic","description":"Model Context Protocol interoperability benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mcp-mark"},{"id":"bfcl-v4","name":"BFCL v4","category":"Agentic","description":"Function calling reliability benchmark (v4).","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#bfcl-v4"},{"id":"vitabench","name":"VitaBench","category":"Agentic","description":"Virtual task assistant benchmark across practical workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vitabench"},{"id":"deepconsult","name":"DeepConsult","category":"Agentic","description":"Consulting-style multi-step reasoning and recommendation benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#deepconsult"},{"id":"deepresearchbench","name":"DeepResearchBench","category":"Agentic","description":"Long-horizon research task benchmark with citation requirements.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#deepresearchbench"},{"id":"researchrubrics","name":"ResearchRubrics","category":"Agentic","description":"Rubric-based evaluation of research quality and rigor.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#researchrubrics"},{"id":"minedojo-verified","name":"MineDojo Verified","category":"Agentic","description":"Verified embodied-agent benchmark in Minecraft-style tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#minedojo-verified"},{"id":"mm-browsecomp","name":"MM-BrowseComp","category":"Agentic","description":"Multimodal browse + synthesize benchmark for web agents.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#mm-browsecomp"},{"id":"hle-vl","name":"HLE-VL","category":"Agentic","description":"Vision-language variant of Humanity's Last Exam under agentic settings.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://agi.safe.ai/"},{"id":"scicode","name":"SciCode","category":"Advanced Tasks","description":"Scientific programming benchmark for code synthesis and correctness.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://github.com/scicode-bench/scicode"},{"id":"frontiersci-research","name":"FrontierSci Research","category":"Advanced Tasks","description":"Open-ended scientific research benchmark with expert-level questions.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#frontiersci-research"},{"id":"biobench","name":"BioBench","category":"Advanced Tasks","description":"Biology and life-science benchmark requiring deep domain reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#biobench"},{"id":"ainstein-bench","name":"AInstein-Bench","category":"Advanced Tasks","description":"Hard scientific reasoning benchmark inspired by olympiad-level tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ainstein-bench"},{"id":"vibe-coding","name":"Vibe Coding","category":"Advanced Tasks","description":"High-level coding outcome quality benchmark for agent-driven development.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#vibe-coding"},{"id":"nl2repo-bench","name":"NL2Repo-Bench","category":"Advanced Tasks","description":"Natural language to repository-wide code edits benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#nl2repo-bench"},{"id":"nl2repo-pass1","name":"NL2Repo Pass@1","category":"Advanced Tasks","description":"Pass@1 metric for repository-scale code modification tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#nl2repo-pass1"},{"id":"cl-bench","name":"CL-Bench","category":"Advanced Tasks","description":"Complex language benchmark covering difficult enterprise workflows.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#cl-bench"},{"id":"tob-complex","name":"TOB Complex","category":"Advanced Tasks","description":"Task-oriented benchmark for complex instruction execution.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-complex"},{"id":"tob-reference","name":"TOB Reference","category":"Advanced Tasks","description":"Reference-heavy task-oriented benchmark requiring retrieval fidelity.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-reference"},{"id":"healthbench-hard","name":"HealthBench Hard","category":"Advanced Tasks","description":"Hard-split medical reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#healthbench-hard"},{"id":"gdpval-diamond","name":"GDPVal Diamond","category":"Advanced Tasks","description":"Diamond subset for difficult planning and valuation tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#gdpval-diamond"},{"id":"xpert-bench","name":"Xpert-Bench","category":"Advanced Tasks","description":"Expert-level evaluation benchmark across specialist domains.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#xpert-bench"},{"id":"tob-k12","name":"TOB K12","category":"Advanced Tasks","description":"Task-oriented benchmark for K12 educational tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-k12"},{"id":"tob-compositional","name":"TOB Compositional","category":"Advanced Tasks","description":"Compositional instruction-following benchmark with chained constraints.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-compositional"},{"id":"tob-classification","name":"TOB Classification","category":"Advanced Tasks","description":"Classification-focused track of task-oriented benchmark suite.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-classification"},{"id":"tob-extraction","name":"TOB Extraction","category":"Advanced Tasks","description":"Extraction-focused benchmark for structured information tasks.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tob-extraction"},{"id":"world-travel-vlm","name":"World-Travel VLM","category":"Advanced Tasks","description":"Vision-language travel-planning and grounded reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#world-travel-vlm"},{"id":"world-travel-text","name":"World-Travel Text","category":"Advanced Tasks","description":"Text-only travel-planning and itinerary reasoning benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#world-travel-text"},{"id":"simplevqa","name":"SimpleVQA","category":"Vision","description":"Short-form visual question answering with verifiable responses.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#simplevqa"},{"id":"videommmu","name":"VideoMMMU","category":"Video","description":"Video variant of MMMU for multimodal understanding and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#videommmu"},{"id":"videomme","name":"VideoMME","category":"Video","description":"Video multimodal evaluation benchmark for perception and reasoning.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://video-mme.github.io/"},{"id":"tvbench","name":"TVBench","category":"Video","description":"Television/video narrative understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#tvbench"},{"id":"ovbench","name":"OVBench","category":"Video","description":"Open-world video understanding benchmark.","maxScore":100,"higherIsBetter":true,"normalization":"max","unit":"%","link":"https://artificialanalysis.ai/evaluations#ovbench"}]}],"$L5","$L6"]}]}]}]}]]}]]}],{"children":["$L7",{"children":["$L8",{"children":["$L9",{},null,false,false]},["$La",[],[]],false,false]},null,false,false]},null,false,false],"$Lb",false]],"m":"$undefined","G":["$c",[]],"S":true}
d:I[39756,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"default"]
e:I[37457,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"default"]
f:I[22016,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js","/_next/static/chunks/86a3b9d41d9d4e2c.js"],""]
11:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"OutletBoundary"]
12:"$Sreact.suspense"
1b:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"ViewportBoundary"]
1d:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"MetadataBoundary"]
5:["$","main",null,{"id":"main-content","className":"container relative z-10 flex-1 mx-auto px-4 py-8 sm:px-8 md:py-12","children":[["$","div",null,{"className":"mb-5 flex items-center gap-3 rounded-xl border border-amber-500/40 bg-amber-500/12 px-4 py-3 text-sm text-amber-800 dark:text-amber-300","children":[["$","span",null,{"className":"flex h-2 w-2 rounded-full bg-amber-500 animate-pulse shrink-0"}],["$","p",null,{"children":[["$","strong",null,{"children":"Beta version:"}]," *Information might not be fully accurate. Please report any discrepancies."]}]]}],["$","$Ld",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Le",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]]}]
6:["$","footer",null,{"className":"mt-auto border-t border-border/40 bg-card/30","children":["$","div",null,{"className":"mx-auto max-w-7xl px-6 py-4","children":["$","div",null,{"className":"flex flex-wrap items-center justify-between gap-4 text-xs text-muted-foreground","children":[["$","p",null,{"children":[" ",2026," LLM Registry"]}],["$","div",null,{"className":"flex items-center gap-4","children":[["$","a",null,{"href":"mailto:admin@llm-registry.com","className":"transition-colors hover:text-foreground","children":"Report Inaccuracies"}],["$","$Lf",null,{"href":"/about","className":"transition-colors hover:text-foreground","children":"Methodology"}],["$","$Lf",null,{"href":"/api/v1","className":"transition-colors hover:text-foreground","children":"API"}],["$","a",null,{"href":"https://github.com/yamanahlawat/llm-registry","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-1.5 transition-colors hover:text-foreground","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-github h-3 w-3","aria-hidden":"true","children":[["$","path","tonef",{"d":"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"}],["$","path","9comsn",{"d":"M9 18c-4.51 2-5-2-7-2"}],"$undefined"]}],"GitHub"]}]]}]]}]}]}]
7:["$","$1","c",{"children":[null,["$","$Ld",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Le",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
8:["$","$1","c",{"children":[null,["$","$Ld",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Le",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
9:["$","$1","c",{"children":["$L10",[["$","script","script-0",{"src":"/_next/static/chunks/86a3b9d41d9d4e2c.js","async":true,"nonce":"$undefined"}]],["$","$L11",null,{"children":["$","$12",null,{"name":"Next.MetadataOutlet","children":"$@13"}]}]]}]
a:["$","div","l",{"className":"space-y-4 pb-12","children":[["$","nav",null,{"className":"hidden sm:flex items-center gap-1","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-16"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-3 mx-1"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-32"}]]}],["$","div",null,{"className":"flex items-center justify-between","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-6 w-16 sm:hidden"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-8 w-20"}]]}],["$","section",null,{"className":"rounded-2xl border border-border bg-card/50 px-5 py-6","children":["$","div",null,{"className":"flex flex-col gap-6 md:flex-row md:items-start md:justify-between","children":[["$","div",null,{"className":"space-y-4","children":[["$","div",null,{"className":"flex items-center gap-2","children":[["$","div",null,{"className":"animate-pulse bg-primary/10 h-5 w-20 rounded-full"}],["$","div",null,{"className":"animate-pulse bg-primary/10 h-5 w-24 rounded-full"}]]}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-10 w-64"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-48"}],["$","div",null,{"className":"flex items-center gap-2","children":[["$","div",null,{"className":"animate-pulse bg-primary/10 h-9 w-28 rounded-full"}],["$","div",null,{"className":"animate-pulse bg-primary/10 h-9 w-20 rounded-full"}],["$","div",null,{"className":"animate-pulse bg-primary/10 h-9 w-24 rounded-full"}]]}]]}],["$","div",null,{"className":"animate-pulse bg-primary/10 h-24 w-48 rounded-2xl"}]]}]}],["$","div",null,{"className":"grid gap-5 lg:grid-cols-[1fr_320px]","children":[["$","div",null,{"className":"space-y-5","children":[["$","div",null,{"className":"grid gap-5 md:grid-cols-2 xl:grid-cols-4","children":[["$","div","1",{"className":"rounded-xl p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-20 mb-3"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-12 w-16 mb-2"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-24"}]]}],["$","div","2",{"className":"rounded-xl p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-20 mb-3"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-12 w-16 mb-2"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-24"}]]}],["$","div","3",{"className":"rounded-xl p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-20 mb-3"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-12 w-16 mb-2"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-24"}]]}],["$","div","4",{"className":"rounded-xl p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-20 mb-3"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-12 w-16 mb-2"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-24"}]]}]]}],["$","div",null,{"className":"space-y-3","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-6 w-40"}],["$","div",null,{"className":"grid gap-3 sm:grid-cols-2","children":[["$","div","1",{"className":"rounded-2xl border border-border/50 p-5","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-5 w-32 mb-2"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-24"}]]}],["$","div","2",{"className":"rounded-2xl border border-border/50 p-5","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-5 w-32 mb-2"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-24"}]]}]]}]]}],["$","div",null,{"className":"space-y-3","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-6 w-48"}],["$","div",null,{"className":"grid gap-3 md:grid-cols-2 xl:grid-cols-3","children":["$L14","$L15","$L16","$L17","$L18","$L19"]}]]}]]}],"$L1a"]}]]}]
b:["$","$1","h",{"children":[null,["$","$L1b",null,{"children":"$L1c"}],["$","div",null,{"hidden":true,"children":["$","$L1d",null,{"children":["$","$12",null,{"name":"Next.Metadata","children":"$L1e"}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]
14:["$","div","1",{"className":"rounded-lg p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-10 w-12 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-2 w-full mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-20"}]]}]
15:["$","div","2",{"className":"rounded-lg p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-10 w-12 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-2 w-full mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-20"}]]}]
16:["$","div","3",{"className":"rounded-lg p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-10 w-12 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-2 w-full mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-20"}]]}]
17:["$","div","4",{"className":"rounded-lg p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-10 w-12 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-2 w-full mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-20"}]]}]
18:["$","div","5",{"className":"rounded-lg p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-10 w-12 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-2 w-full mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-20"}]]}]
19:["$","div","6",{"className":"rounded-lg p-5 border border-border/40","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-10 w-12 mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-2 w-full mb-4"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-20"}]]}]
1a:["$","aside",null,{"className":"space-y-3","children":["$","div",null,{"className":"surface-card rounded-2xl p-5","children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-8 w-24 mb-4"}],["$","div",null,{"className":"space-y-3","children":[["$","div","1",{"children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-16 mb-1"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24"}]]}],["$","div","2",{"children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-16 mb-1"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24"}]]}],["$","div","3",{"children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-16 mb-1"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24"}]]}],["$","div","4",{"children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-16 mb-1"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24"}]]}],["$","div","5",{"children":[["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-3 w-16 mb-1"}],["$","div",null,{"className":"animate-pulse rounded-md bg-primary/10 h-4 w-24"}]]}]]}]]}]}]
1f:I[4492,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js","/_next/static/chunks/86a3b9d41d9d4e2c.js"],"ShareButton"]
10:["$","div",null,{"className":"animate-in fade-in duration-700 space-y-4 pb-12","children":[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Leaderboard\",\"item\":\"https://llm-registry.com/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Models\",\"item\":\"https://llm-registry.com/\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"o3-pro\",\"item\":\"https://llm-registry.com/model/o3-pro\"}]}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"SoftwareApplication\",\"name\":\"o3-pro\",\"applicationCategory\":\"AIModel\",\"operatingSystem\":\"Cloud\",\"datePublished\":\"2025-06-10\",\"url\":\"https://llm-registry.com/model/o3-pro\",\"creator\":{\"@type\":\"Organization\",\"name\":\"OpenAI\"},\"featureList\":[\"text\",\"code\",\"reasoning\",\"vision\"],\"offers\":[{\"@type\":\"Offer\",\"name\":\"Input pricing\",\"price\":20,\"priceCurrency\":\"USD\",\"description\":\"USD per 1M input tokens\"},{\"@type\":\"Offer\",\"name\":\"Output pricing\",\"price\":80,\"priceCurrency\":\"USD\",\"description\":\"USD per 1M output tokens\"}],\"additionalProperty\":[{\"@type\":\"PropertyValue\",\"name\":\"Context window\",\"value\":\"256000\"},{\"@type\":\"PropertyValue\",\"name\":\"Parameters\",\"value\":\"Reasoning Model\"},{\"@type\":\"PropertyValue\",\"name\":\"Benchmarks with scores\",\"value\":\"5\"}]}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Dataset\",\"name\":\"o3-pro benchmark scores\",\"description\":\"Benchmark-level scores and provenance metadata for o3-pro.\",\"url\":\"https://llm-registry.com/model/o3-pro\",\"creator\":{\"@type\":\"Organization\",\"name\":\"LLM Registry\",\"url\":\"https://llm-registry.com\"},\"isAccessibleForFree\":true,\"distribution\":{\"@type\":\"DataDownload\",\"contentUrl\":\"https://llm-registry.com/api/v1/scores?modelId=o3-pro\",\"encodingFormat\":\"application/json\"}}"}}],["$","nav",null,{"className":"hidden sm:flex items-center gap-1 text-xs text-muted-foreground","children":[["$","$Lf",null,{"href":"/","className":"hover:text-foreground transition-colors","children":"Leaderboard"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-chevron-right h-3 w-3","aria-hidden":"true","children":[["$","path","mthhwq",{"d":"m9 18 6-6-6-6"}],"$undefined"]}],["$","span",null,{"className":"text-foreground font-medium","children":"o3-pro"}]]}],["$","div",null,{"className":"flex items-center justify-between gap-4","children":[["$","$Lf",null,{"href":"/","className":"group inline-flex items-center gap-2 text-sm font-mono tracking-[0.1em] text-muted-foreground transition-colors hover:text-primary sm:hidden","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left h-3 w-3 transition-transform group-hover:-translate-x-1","aria-hidden":"true","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}],"Back"]}],["$","$L1f",null,{}]]}],["$","section",null,{"className":"relative overflow-hidden rounded-2xl border border-border bg-card/50 px-5 py-6 sm:px-8 sm:py-8","children":[["$","div",null,{"className":"pointer-events-none absolute inset-0 bg-[radial-gradient(circle_at_100%_0%,color-mix(in_oklab,var(--primary)_10%,transparent),transparent_50%)]"}],["$","div",null,{"className":"flex flex-col gap-8 md:flex-row md:items-start md:justify-between","children":["$L20","$L21"]}]]}],"$L22"]}]
23:I[9081,["/_next/static/chunks/50e362abf678ecbe.js","/_next/static/chunks/5a162bb283fc115e.js","/_next/static/chunks/195c216f52dae3f8.js","/_next/static/chunks/f1aa34f1a3c869ef.js","/_next/static/chunks/6b5063fbd0ddba71.js","/_next/static/chunks/ffbb017a68df0472.js","/_next/static/chunks/86a3b9d41d9d4e2c.js"],"ModelFamilyCompare"]
20:["$","div",null,{"className":"max-w-3xl space-y-5","children":[["$","div",null,{"className":"flex flex-wrap items-center gap-2","children":[["$","span",null,{"data-slot":"badge","data-variant":"outline","className":"inline-flex items-center justify-center border w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&]:hover:bg-accent [a&]:hover:text-accent-foreground rounded-full px-3 py-0.5 font-bold text-[10px] uppercase tracking-widest border-cyan-500/35 dark:border-cyan-300/35 bg-cyan-500/12 dark:bg-cyan-300/12 text-cyan-700 dark:text-cyan-200","children":"OpenAI"}],false]}],["$","h1",null,{"className":"text-balance font-display text-4xl font-bold leading-tight tracking-tight text-foreground sm:text-5xl lg:text-6xl","children":"o3-pro"}],["$","p",null,{"className":"font-mono text-[10px] font-bold uppercase tracking-[0.2em] text-muted-foreground/60","children":["Released ","2025-06-10","  ","Reasoning Model"," Architecture"]}],["$","div",null,{"className":"flex flex-wrap items-center gap-2 pt-2","children":[["$","$L23",null,{"currentModelId":"o3-pro","family":[{"id":"o3-pro","name":"o3-pro"}]}],["$","a",null,{"href":"https://artificialanalysis.ai/","target":"_blank","rel":"noreferrer","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-shield-check mr-2 h-3.5 w-3.5","aria-hidden":"true","children":[["$","path","oel41y",{"d":"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"}],["$","path","dzmm74",{"d":"m9 12 2 2 4-4"}],"$undefined"]}],"Verified"],"data-slot":"button","data-variant":"outline","data-size":"sm","className":"inline-flex items-center justify-center whitespace-nowrap transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:ring-[3px] focus-visible:ring-primary/35 focus-visible:border-primary/40 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border shadow-xs hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 gap-1.5 has-[>svg]:px-2.5 h-9 rounded-full border-emerald-500/30 bg-emerald-500/5 px-4 text-[11px] font-bold uppercase tracking-wider text-emerald-700 hover:bg-emerald-500/10 dark:text-emerald-300","ref":null}],["$","a",null,{"href":"https://platform.openai.com/docs/models/o3-pro","target":"_blank","rel":"noreferrer","children":"Official","data-slot":"button","data-variant":"outline","data-size":"sm","className":"inline-flex items-center justify-center whitespace-nowrap transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:ring-[3px] focus-visible:ring-primary/35 focus-visible:border-primary/40 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border border-white/12 bg-background/80 shadow-xs hover:bg-accent/70 hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 gap-1.5 has-[>svg]:px-2.5 h-9 rounded-full px-4 text-[11px] font-bold uppercase tracking-wider","ref":null}],"$L24"]}]]}]
21:["$","div",null,{"className":"rounded-2xl border border-border bg-muted/30 p-5 min-w-[200px]","children":[["$","p",null,{"className":"font-mono text-[10px] font-bold uppercase tracking-[0.2em] text-muted-foreground/60","children":"Latest Data"}],["$","p",null,{"className":"mt-3 font-mono text-sm font-bold text-foreground","children":"2026-02-16"}]]}]
22:["$","div",null,{"className":"grid gap-5 lg:grid-cols-[minmax(0,1fr)_320px]","children":[["$","div",null,{"className":"space-y-7","children":[["$","div",null,{"className":"grid gap-5 md:grid-cols-2 xl:grid-cols-4","children":[["$","section","context",{"className":"data-module group relative overflow-hidden rounded-xl p-5","children":[["$","div",null,{"className":"absolute right-3 top-3 text-muted/20 transition-colors group-hover:text-muted/30 dark:text-muted/10 dark:group-hover:text-muted/20","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-layers h-10 w-10","aria-hidden":"true","children":[["$","path","zw3jo",{"d":"M12.83 2.18a2 2 0 0 0-1.66 0L2.6 6.08a1 1 0 0 0 0 1.83l8.58 3.91a2 2 0 0 0 1.66 0l8.58-3.9a1 1 0 0 0 0-1.83z"}],["$","path","1wduqc",{"d":"M2 12a1 1 0 0 0 .58.91l8.6 3.91a2 2 0 0 0 1.65 0l8.58-3.9A1 1 0 0 0 22 12"}],["$","path","kqbvx6",{"d":"M2 17a1 1 0 0 0 .58.91l8.6 3.91a2 2 0 0 0 1.65 0l8.58-3.9A1 1 0 0 0 22 17"}],"$undefined"]}]}],["$","p",null,{"className":"font-mono text-[11px] uppercase tracking-[0.12em] text-muted-foreground","children":"Context Window"}],["$","p",null,{"className":"mt-3 text-4xl font-display text-5xl font-bold tracking-[-0.03em] text-primary","children":"256k"}],["$","p",null,{"className":"mt-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground/80","children":"tokens"}]]}],["$","section","input",{"className":"data-module group relative overflow-hidden rounded-xl p-5","children":[["$","div",null,{"className":"absolute right-3 top-3 text-muted/20 transition-colors group-hover:text-muted/30 dark:text-muted/10 dark:group-hover:text-muted/20","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-zap h-10 w-10","aria-hidden":"true","children":[["$","path","1xq2db",{"d":"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z"}],"$undefined"]}]}],["$","p",null,{"className":"font-mono text-[11px] uppercase tracking-[0.12em] text-muted-foreground","children":"Input Cost"}],["$","p",null,{"className":"mt-3 text-4xl font-display text-5xl font-bold tracking-[-0.03em] text-emerald-700 dark:text-emerald-300","children":"$$20.00"}],["$","p",null,{"className":"mt-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground/80","children":"per 1M tokens"}]]}],["$","section","output",{"className":"data-module group relative overflow-hidden rounded-xl p-5","children":[["$","div",null,{"className":"absolute right-3 top-3 text-muted/20 transition-colors group-hover:text-muted/30 dark:text-muted/10 dark:group-hover:text-muted/20","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-zap h-10 w-10","aria-hidden":"true","children":[["$","path","1xq2db",{"d":"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z"}],"$undefined"]}]}],["$","p",null,{"className":"font-mono text-[11px] uppercase tracking-[0.12em] text-muted-foreground","children":"Output Cost"}],["$","p",null,{"className":"mt-3 text-4xl font-display text-5xl font-bold tracking-[-0.03em] text-emerald-700 dark:text-emerald-300","children":"$$80.00"}],["$","p",null,{"className":"mt-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground/80","children":"per 1M tokens"}]]}],["$","section","params",{"className":"data-module group relative overflow-hidden rounded-xl p-5","children":["$L25","$L26","$L27","$L28"]}]]}],"$undefined","$undefined",false,"$L29"]}],"$L2a"]}]
24:["$","$Lf",null,{"href":"/about","children":"Model Card","data-slot":"button","data-variant":"default","data-size":"sm","className":"inline-flex items-center justify-center whitespace-nowrap transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:ring-[3px] focus-visible:ring-primary/35 focus-visible:border-primary/40 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground hover:bg-primary/90 gap-1.5 has-[>svg]:px-2.5 h-9 rounded-full px-5 text-[11px] font-bold uppercase tracking-wider shadow-lg shadow-primary/20","ref":null}]
25:["$","div",null,{"className":"absolute right-3 top-3 text-muted/20 transition-colors group-hover:text-muted/30 dark:text-muted/10 dark:group-hover:text-muted/20","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-cpu h-10 w-10","aria-hidden":"true","children":[["$","path","1lh1kg",{"d":"M12 20v2"}],["$","path","tus03m",{"d":"M12 2v2"}],["$","path","1rnc9c",{"d":"M17 20v2"}],["$","path","11trls",{"d":"M17 2v2"}],["$","path","1t8f8n",{"d":"M2 12h2"}],["$","path","7oei6x",{"d":"M2 17h2"}],["$","path","asdhe0",{"d":"M2 7h2"}],["$","path","1q8mjw",{"d":"M20 12h2"}],["$","path","1fpfkl",{"d":"M20 17h2"}],["$","path","1o8tra",{"d":"M20 7h2"}],["$","path","4gnj0m",{"d":"M7 20v2"}],["$","path","1i4yhu",{"d":"M7 2v2"}],["$","rect","1vbyd7",{"x":"4","y":"4","width":"16","height":"16","rx":"2"}],["$","rect","z9xiuo",{"x":"8","y":"8","width":"8","height":"8","rx":"1"}],"$undefined"]}]}]
26:["$","p",null,{"className":"font-mono text-[11px] uppercase tracking-[0.12em] text-muted-foreground","children":"Parameters"}]
27:["$","p",null,{"className":"mt-3 text-4xl font-display text-5xl font-bold tracking-[-0.03em] text-sky-700 dark:text-sky-300","children":"Reasoning Model"}]
28:["$","p",null,{"className":"mt-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground/80","children":"model footprint"}]
29:["$","div",null,{"className":"space-y-7 pt-1.5","children":[["$","div",null,{"className":"flex items-center gap-4 border-b border-border/30 pb-4","children":[["$","div",null,{"className":"rounded-md bg-primary/10 p-2","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-zap h-5 w-5 text-primary","aria-hidden":"true","children":[["$","path","1xq2db",{"d":"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z"}],"$undefined"]}]}],["$","div",null,{"children":[["$","h2",null,{"className":"font-display text-2xl font-bold tracking-[-0.03em] text-foreground","children":"Benchmark Provenance"}],["$","p",null,{"className":"mt-1 font-mono text-sm uppercase tracking-[0.1em] text-muted-foreground","children":"Performance Analysis // Verified Benchmarks"}]]}]]}],["$","div",null,{"className":"grid gap-5 md:grid-cols-2 xl:grid-cols-3","children":[null,["$","article","math",{"className":"data-module group relative rounded-lg p-5 transition-transform duration-300 hover:-translate-y-0.5","children":[["$","div",null,{"className":"mb-5 flex items-start justify-between gap-3","children":[["$","$Lf",null,{"href":"/benchmark/math","className":"max-w-[72%] font-mono text-sm font-semibold tracking-[0.06em] text-muted-foreground transition-colors hover:text-primary group-hover:text-foreground","children":"MATH (CoT)"}],["$","span",null,{"data-slot":"badge","data-variant":"secondary","className":"inline-flex items-center justify-center border font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&]:hover:bg-secondary/90 rounded border-border bg-secondary px-1.5 py-0.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground","children":"Math"}]]}],["$","div",null,{"className":"mb-4 flex items-end gap-3","children":[["$","span",null,{"className":"origin-left font-display text-5xl font-bold tracking-[-0.03em] transition-transform group-hover:scale-105 text-foreground","children":[99,""]}],["$","span",null,{"className":"mb-1.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground/55","children":["/ ",100]}]]}],["$","div",null,{"className":"mb-5 h-2 overflow-hidden rounded-full border border-border bg-muted","children":["$","div",null,{"className":"h-full bg-foreground/85","style":{"width":"99%"}}]}],["$","div",null,{"className":"space-y-2 border-t border-border/60 pt-4","children":[["$","div",null,{"className":"flex items-center gap-1.5 font-mono text-[11px] font-bold uppercase tracking-[0.1em] text-emerald-700 dark:text-emerald-300","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-shield-check h-3 w-3","aria-hidden":"true","children":[["$","path","oel41y",{"d":"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"}],["$","path","dzmm74",{"d":"m9 12 2 2 4-4"}],"$undefined"]}],["$","span",null,{"children":"Verified"}]]}],["$","div",null,{"className":"flex items-center justify-between gap-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground","children":[["$","span",null,{"children":["Last Verified: ","Unknown Date"]}],["$","a",null,{"href":"https://openai.com/news","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-1 text-primary hover:underline","children":["OpenAI Blog"," ","$L2b"]}]]}]]}],"$L2c"]}],null,null,null,null,null,null,null,"$L2d","$L2e",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"$L2f",null,null,null,null,null,null,null,null,null,null,null,null,"$L30",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]}]]}]
2a:["$","aside",null,{"className":"space-y-3 lg:pt-1","children":[["$","section",null,{"className":"surface-card sticky top-20 rounded-2xl p-5","children":[["$","h3",null,{"className":"font-display text-3xl font-bold tracking-tight text-foreground","children":"Metadata"}],["$","div",null,{"className":"mt-4 space-y-3 border-t border-border pt-4 text-sm","children":[["$","div",null,{"children":[["$","p",null,{"className":"label-eyebrow","children":"License"}],["$","p",null,{"className":"mt-1 font-medium text-foreground","children":"Proprietary"}]]}],["$","div",null,{"children":[["$","p",null,{"className":"label-eyebrow","children":"Context Window"}],["$","p",null,{"className":"mt-1 font-medium text-foreground","children":["256,000"," tokens"]}]]}],["$","div",null,{"children":[["$","p",null,{"className":"label-eyebrow","children":"Input Pricing"}],["$","p",null,{"className":"mt-1 font-medium text-foreground","children":["$$20.00"," / 1M tokens"]}]]}],["$","div",null,{"children":[["$","p",null,{"className":"label-eyebrow","children":"Output Pricing"}],["$","p",null,{"className":"mt-1 font-medium text-foreground","children":["$$80.00"," / 1M tokens"]}]]}],["$","div",null,{"children":[["$","p",null,{"className":"label-eyebrow","children":"Modality"}],["$","div",null,{"className":"mt-2 flex flex-wrap gap-2","children":[["$","span","text",{"className":"chip-pill rounded-md px-2 py-1 text-[11px] font-mono uppercase tracking-[0.08em] text-muted-foreground","children":"text"}],["$","span","code",{"className":"chip-pill rounded-md px-2 py-1 text-[11px] font-mono uppercase tracking-[0.08em] text-muted-foreground","children":"code"}],["$","span","reasoning",{"className":"chip-pill rounded-md px-2 py-1 text-[11px] font-mono uppercase tracking-[0.08em] text-muted-foreground","children":"reasoning"}],["$","span","vision",{"className":"chip-pill rounded-md px-2 py-1 text-[11px] font-mono uppercase tracking-[0.08em] text-muted-foreground","children":"vision"}]]}]]}]]}],["$","a",null,{"href":"https://github.com/jnd0/llm-registry/issues/new?title=Data%20inaccuracy%3A%20o3-pro&body=Model%3A%20o3-pro%0AProvider%3A%20OpenAI%0APage%3A%20https%3A%2F%2Fllm-registry.com%2Fmodel%2Fo3-pro%0A%0ADescribe%20the%20inaccuracy%3A%0A","target":"_blank","rel":"noreferrer","children":"Report Inaccuracy","data-slot":"button","data-variant":"outline","data-size":"default","className":"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:ring-[3px] focus-visible:ring-primary/35 focus-visible:border-primary/40 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border border-white/12 bg-background/80 shadow-xs hover:bg-accent/70 hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 mt-5 h-10 w-full","ref":null}]]}],["$","section",null,{"className":"surface-card rounded-2xl p-5","children":[["$","h3",null,{"className":"font-display text-xl font-semibold tracking-tight text-foreground","children":"Compare With"}],["$","div",null,{"className":"mt-3 space-y-2","children":[["$","$Lf","o1",{"href":"/compare?models=o3-pro,o1","className":"flex items-center justify-between rounded-lg border border-border bg-card px-3 py-2 text-sm text-foreground transition-colors hover:border-primary/35 hover:bg-primary/5","children":[["$","span",null,{"children":"o1"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-external-link h-4 w-4 text-muted-foreground","aria-hidden":"true","children":[["$","path","1q9fwt",{"d":"M15 3h6v6"}],["$","path","gplh6r",{"d":"M10 14 21 3"}],"$L31","$undefined"]}]]}],"$L32","$L33"]}]]}]]}]
2b:["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-external-link h-3 w-3","aria-hidden":"true","children":[["$","path","1q9fwt",{"d":"M15 3h6v6"}],["$","path","gplh6r",{"d":"M10 14 21 3"}],["$","path","a6xqqp",{"d":"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"}],"$undefined"]}]
2c:["$","p",null,{"className":"mt-3 line-clamp-3 text-xs leading-relaxed text-muted-foreground","children":"Challenging competition mathematics problems (AIME/IMO level)."}]
2d:["$","article","lmarena-elo",{"className":"data-module group relative rounded-lg p-5 transition-transform duration-300 hover:-translate-y-0.5","children":[["$","div",null,{"className":"mb-5 flex items-start justify-between gap-3","children":[["$","$Lf",null,{"href":"/benchmark/lmarena-elo","className":"max-w-[72%] font-mono text-sm font-semibold tracking-[0.06em] text-muted-foreground transition-colors hover:text-primary group-hover:text-foreground","children":"LMArena ELO"}],["$","span",null,{"data-slot":"badge","data-variant":"secondary","className":"inline-flex items-center justify-center border font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&]:hover:bg-secondary/90 rounded border-border bg-secondary px-1.5 py-0.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground","children":"Real-world"}]]}],["$","div",null,{"className":"mb-4 flex items-end gap-3","children":[["$","span",null,{"className":"origin-left font-display text-5xl font-bold tracking-[-0.03em] transition-transform group-hover:scale-105 text-amber-700 dark:text-amber-400","children":[1360,""]}],["$","span",null,{"className":"mb-1.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground/55","children":["/ ",1700]}]]}],["$","div",null,{"className":"mb-5 h-2 overflow-hidden rounded-full border border-border bg-muted","children":["$","div",null,{"className":"h-full bg-foreground/45","style":{"width":"51.42857142857142%"}}]}],["$","div",null,{"className":"space-y-2 border-t border-border/60 pt-4","children":[["$","div",null,{"className":"flex items-center gap-1.5 font-mono text-[11px] font-bold uppercase tracking-[0.1em] text-emerald-700 dark:text-emerald-300","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-shield-check h-3 w-3","aria-hidden":"true","children":[["$","path","oel41y",{"d":"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"}],["$","path","dzmm74",{"d":"m9 12 2 2 4-4"}],"$undefined"]}],["$","span",null,{"children":"Verified"}]]}],["$","div",null,{"className":"flex items-center justify-between gap-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground","children":[["$","span",null,{"children":["Last Verified: ","Unknown Date"]}],["$","a",null,{"href":"https://openai.com/news","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-1 text-primary hover:underline","children":["OpenAI Blog"," ",["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-external-link h-3 w-3","aria-hidden":"true","children":[["$","path","1q9fwt",{"d":"M15 3h6v6"}],["$","path","gplh6r",{"d":"M10 14 21 3"}],["$","path","a6xqqp",{"d":"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"}],"$undefined"]}]]}]]}]]}],["$","p",null,{"className":"mt-3 line-clamp-3 text-xs leading-relaxed text-muted-foreground","children":"Chatbot Arena ELO score. Crowd-sourced human preference ranking."}]]}]
2e:["$","article","aa-intelligence-index",{"className":"data-module group relative rounded-lg p-5 transition-transform duration-300 hover:-translate-y-0.5","children":[["$","div",null,{"className":"mb-5 flex items-start justify-between gap-3","children":[["$","$Lf",null,{"href":"/benchmark/aa-intelligence-index","className":"max-w-[72%] font-mono text-sm font-semibold tracking-[0.06em] text-muted-foreground transition-colors hover:text-primary group-hover:text-foreground","children":"AA Intelligence Index"}],["$","span",null,{"data-slot":"badge","data-variant":"secondary","className":"inline-flex items-center justify-center border font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&]:hover:bg-secondary/90 rounded border-border bg-secondary px-1.5 py-0.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground","children":"Real-world"}]]}],["$","div",null,{"className":"mb-4 flex items-end gap-3","children":[["$","span",null,{"className":"origin-left font-display text-5xl font-bold tracking-[-0.03em] transition-transform group-hover:scale-105 text-amber-700 dark:text-amber-400","children":[40.7,"*"]}],["$","span",null,{"className":"mb-1.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground/55","children":["/ ",100]}]]}],["$","div",null,{"className":"mb-5 h-2 overflow-hidden rounded-full border border-border bg-muted","children":["$","div",null,{"className":"h-full bg-foreground/45","style":{"width":"40.7%"}}]}],["$","div",null,{"className":"space-y-2 border-t border-border/60 pt-4","children":[["$","div",null,{"className":"flex items-center gap-1.5 font-mono text-[11px] font-bold uppercase tracking-[0.1em] text-emerald-700 dark:text-emerald-300","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-shield-check h-3 w-3","aria-hidden":"true","children":[["$","path","oel41y",{"d":"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"}],["$","path","dzmm74",{"d":"m9 12 2 2 4-4"}],"$undefined"]}],["$","span",null,{"children":"Third-party"}]]}],["$","div",null,{"className":"flex items-center justify-between gap-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground","children":[["$","span",null,{"children":["Last Verified: ","2026-02-16"]}],["$","a",null,{"href":"https://artificialanalysis.ai/","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-1 text-primary hover:underline","children":["Artificial Analysis (Independent)"," ",["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-external-link h-3 w-3","aria-hidden":"true","children":[["$","path","1q9fwt",{"d":"M15 3h6v6"}],["$","path","gplh6r",{"d":"M10 14 21 3"}],["$","path","a6xqqp",{"d":"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"}],"$undefined"]}]]}]]}]]}],["$","p",null,{"className":"mt-3 line-clamp-3 text-xs leading-relaxed text-muted-foreground","children":"Artificial Analysis aggregate intelligence index."}]]}]
2f:["$","article","gpqa-diamond",{"className":"data-module group relative rounded-lg p-5 transition-transform duration-300 hover:-translate-y-0.5","children":[["$","div",null,{"className":"mb-5 flex items-start justify-between gap-3","children":[["$","$Lf",null,{"href":"/benchmark/gpqa-diamond","className":"max-w-[72%] font-mono text-sm font-semibold tracking-[0.06em] text-muted-foreground transition-colors hover:text-primary group-hover:text-foreground","children":"GPQA Diamond"}],["$","span",null,{"data-slot":"badge","data-variant":"secondary","className":"inline-flex items-center justify-center border font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&]:hover:bg-secondary/90 rounded border-border bg-secondary px-1.5 py-0.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground","children":"STEM"}]]}],["$","div",null,{"className":"mb-4 flex items-end gap-3","children":[["$","span",null,{"className":"origin-left font-display text-5xl font-bold tracking-[-0.03em] transition-transform group-hover:scale-105 text-emerald-700 dark:text-emerald-400","children":[84.5,"*"]}],["$","span",null,{"className":"mb-1.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground/55","children":["/ ",100]}]]}],["$","div",null,{"className":"mb-5 h-2 overflow-hidden rounded-full border border-border bg-muted","children":["$","div",null,{"className":"h-full bg-foreground/65","style":{"width":"84.5%"}}]}],["$","div",null,{"className":"space-y-2 border-t border-border/60 pt-4","children":[["$","div",null,{"className":"flex items-center gap-1.5 font-mono text-[11px] font-bold uppercase tracking-[0.1em] text-emerald-700 dark:text-emerald-300","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-shield-check h-3 w-3","aria-hidden":"true","children":[["$","path","oel41y",{"d":"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"}],["$","path","dzmm74",{"d":"m9 12 2 2 4-4"}],"$undefined"]}],["$","span",null,{"children":"Third-party"}]]}],["$","div",null,{"className":"flex items-center justify-between gap-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground","children":[["$","span",null,{"children":["Last Verified: ","2026-02-16"]}],["$","a",null,{"href":"https://artificialanalysis.ai/","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-1 text-primary hover:underline","children":["Artificial Analysis (Independent)"," ",["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-external-link h-3 w-3","aria-hidden":"true","children":[["$","path","1q9fwt",{"d":"M15 3h6v6"}],["$","path","gplh6r",{"d":"M10 14 21 3"}],["$","path","a6xqqp",{"d":"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"}],"$undefined"]}]]}]]}]]}],["$","p",null,{"className":"mt-3 line-clamp-3 text-xs leading-relaxed text-muted-foreground","children":"Graduate-Level Google-Proof Q&A Benchmark."}]]}]
30:["$","article","aime-2025",{"className":"data-module group relative rounded-lg p-5 transition-transform duration-300 hover:-translate-y-0.5","children":[["$","div",null,{"className":"mb-5 flex items-start justify-between gap-3","children":[["$","$Lf",null,{"href":"/benchmark/aime-2025","className":"max-w-[72%] font-mono text-sm font-semibold tracking-[0.06em] text-muted-foreground transition-colors hover:text-primary group-hover:text-foreground","children":"AIME 2025"}],["$","span",null,{"data-slot":"badge","data-variant":"secondary","className":"inline-flex items-center justify-center border font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&]:hover:bg-secondary/90 rounded border-border bg-secondary px-1.5 py-0.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground","children":"Math"}]]}],["$","div",null,{"className":"mb-4 flex items-end gap-3","children":[["$","span",null,{"className":"origin-left font-display text-5xl font-bold tracking-[-0.03em] transition-transform group-hover:scale-105 text-foreground","children":[96,""]}],["$","span",null,{"className":"mb-1.5 font-mono text-[11px] tracking-[0.06em] text-muted-foreground/55","children":["/ ",100]}]]}],["$","div",null,{"className":"mb-5 h-2 overflow-hidden rounded-full border border-border bg-muted","children":["$","div",null,{"className":"h-full bg-foreground/85","style":{"width":"96%"}}]}],["$","div",null,{"className":"space-y-2 border-t border-border/60 pt-4","children":[["$","div",null,{"className":"flex items-center gap-1.5 font-mono text-[11px] font-bold uppercase tracking-[0.1em] text-emerald-700 dark:text-emerald-300","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-shield-check h-3 w-3","aria-hidden":"true","children":[["$","path","oel41y",{"d":"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"}],["$","path","dzmm74",{"d":"m9 12 2 2 4-4"}],"$undefined"]}],["$","span",null,{"children":"Verified"}]]}],["$","div",null,{"className":"flex items-center justify-between gap-2 font-mono text-[11px] uppercase tracking-[0.1em] text-muted-foreground","children":[["$","span",null,{"children":["Last Verified: ","Unknown Date"]}],["$","a",null,{"href":"https://openai.com/news","target":"_blank","rel":"noreferrer","className":"inline-flex items-center gap-1 text-primary hover:underline","children":["OpenAI Blog"," ",["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-external-link h-3 w-3","aria-hidden":"true","children":[["$","path","1q9fwt",{"d":"M15 3h6v6"}],["$","path","gplh6r",{"d":"M10 14 21 3"}],["$","path","a6xqqp",{"d":"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"}],"$undefined"]}]]}]]}]]}],["$","p",null,{"className":"mt-3 line-clamp-3 text-xs leading-relaxed text-muted-foreground","children":"American Invitational Mathematics Examination 2025 problems."}]]}]
31:["$","path","a6xqqp",{"d":"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"}]
32:["$","$Lf","o1-preview",{"href":"/compare?models=o3-pro,o1-preview","className":"flex items-center justify-between rounded-lg border border-border bg-card px-3 py-2 text-sm text-foreground transition-colors hover:border-primary/35 hover:bg-primary/5","children":[["$","span",null,{"children":"o1-preview"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-external-link h-4 w-4 text-muted-foreground","aria-hidden":"true","children":[["$","path","1q9fwt",{"d":"M15 3h6v6"}],["$","path","gplh6r",{"d":"M10 14 21 3"}],["$","path","a6xqqp",{"d":"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"}],"$undefined"]}]]}]
33:["$","$Lf","o1-mini",{"href":"/compare?models=o3-pro,o1-mini","className":"flex items-center justify-between rounded-lg border border-border bg-card px-3 py-2 text-sm text-foreground transition-colors hover:border-primary/35 hover:bg-primary/5","children":[["$","span",null,{"children":"o1-mini"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-external-link h-4 w-4 text-muted-foreground","aria-hidden":"true","children":[["$","path","1q9fwt",{"d":"M15 3h6v6"}],["$","path","gplh6r",{"d":"M10 14 21 3"}],["$","path","a6xqqp",{"d":"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"}],"$undefined"]}]]}]
1c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
34:I[27201,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/a2dfb6fc5208ab9b.js"],"IconMark"]
13:null
1e:[["$","title","0",{"children":"o3-pro | LLM Registry"}],["$","meta","1",{"name":"description","content":"o3-pro by OpenAI: pricing, specs, and benchmark-level provenance in LLM Registry."}],["$","meta","2",{"name":"application-name","content":"LLM Registry"}],["$","link","3",{"rel":"manifest","href":"/manifest.webmanifest","crossOrigin":"$undefined"}],["$","meta","4",{"name":"keywords","content":"llm benchmark leaderboard,ai model comparison,llm registry,model evaluation,artificial analysis,benchmark provenance"}],["$","meta","5",{"name":"robots","content":"index, follow"}],["$","meta","6",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","meta","7",{"name":"category","content":"technology"}],["$","link","8",{"rel":"canonical","href":"https://llm-registry.com/model/o3-pro"}],["$","meta","9",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","10",{"property":"og:title","content":"o3-pro by OpenAI"}],["$","meta","11",{"property":"og:description","content":"o3-pro by OpenAI: pricing, specs, and benchmark-level provenance in LLM Registry."}],["$","meta","12",{"property":"og:url","content":"https://llm-registry.com/model/o3-pro"}],["$","meta","13",{"property":"og:image","content":"https://llm-registry.com/opengraph-image.png"}],["$","meta","14",{"property":"og:image:width","content":"1200"}],["$","meta","15",{"property":"og:image:height","content":"630"}],["$","meta","16",{"property":"og:image:alt","content":"o3-pro - LLM Registry"}],["$","meta","17",{"property":"og:type","content":"article"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"o3-pro by OpenAI"}],["$","meta","20",{"name":"twitter:description","content":"o3-pro by OpenAI: pricing, specs, and benchmark-level provenance in LLM Registry."}],["$","meta","21",{"name":"twitter:image","content":"https://llm-registry.com/opengraph-image.png"}],["$","link","22",{"rel":"icon","href":"/icon.png?icon.5b192b1b.png","sizes":"512x512","type":"image/png"}],["$","$L34","23",{}]]
