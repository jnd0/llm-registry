(globalThis.TURBOPACK||(globalThis.TURBOPACK=[])).push(["object"==typeof document?document.currentScript:void 0,33525,(e,t,i)=>{"use strict";Object.defineProperty(i,"__esModule",{value:!0}),Object.defineProperty(i,"warnOnce",{enumerable:!0,get:function(){return r}});let r=e=>{}},98183,(e,t,i)=>{"use strict";Object.defineProperty(i,"__esModule",{value:!0});var r={assign:function(){return c},searchParamsToUrlQuery:function(){return o},urlQueryToSearchParams:function(){return s}};for(var n in r)Object.defineProperty(i,n,{enumerable:!0,get:r[n]});function o(e){let t={};for(let[i,r]of e.entries()){let e=t[i];void 0===e?t[i]=r:Array.isArray(e)?e.push(r):t[i]=[e,r]}return t}function a(e){return"string"==typeof e?e:("number"!=typeof e||isNaN(e))&&"boolean"!=typeof e?"":String(e)}function s(e){let t=new URLSearchParams;for(let[i,r]of Object.entries(e))if(Array.isArray(r))for(let e of r)t.append(i,a(e));else t.set(i,a(r));return t}function c(e,...t){for(let i of t){for(let t of i.keys())e.delete(t);for(let[t,r]of i.entries())e.append(t,r)}return e}},95057,(e,t,i)=>{"use strict";Object.defineProperty(i,"__esModule",{value:!0});var r={formatUrl:function(){return s},formatWithValidation:function(){return l},urlObjectKeys:function(){return c}};for(var n in r)Object.defineProperty(i,n,{enumerable:!0,get:r[n]});let o=e.r(90809)._(e.r(98183)),a=/https?|ftp|gopher|file/;function s(e){let{auth:t,hostname:i}=e,r=e.protocol||"",n=e.pathname||"",s=e.hash||"",c=e.query||"",l=!1;t=t?encodeURIComponent(t).replace(/%3A/i,":")+"@":"",e.host?l=t+e.host:i&&(l=t+(~i.indexOf(":")?`[${i}]`:i),e.port&&(l+=":"+e.port)),c&&"object"==typeof c&&(c=String(o.urlQueryToSearchParams(c)));let d=e.search||c&&`?${c}`||"";return r&&!r.endsWith(":")&&(r+=":"),e.slashes||(!r||a.test(r))&&!1!==l?(l="//"+(l||""),n&&"/"!==n[0]&&(n="/"+n)):l||(l=""),s&&"#"!==s[0]&&(s="#"+s),d&&"?"!==d[0]&&(d="?"+d),n=n.replace(/[?#]/g,encodeURIComponent),d=d.replace("#","%23"),`${r}${l}${n}${d}${s}`}let c=["auth","hash","host","hostname","href","path","pathname","port","protocol","query","search","slashes"];function l(e){return s(e)}},18581,(e,t,i)=>{"use strict";Object.defineProperty(i,"__esModule",{value:!0}),Object.defineProperty(i,"useMergedRef",{enumerable:!0,get:function(){return n}});let r=e.r(71645);function n(e,t){let i=(0,r.useRef)(null),n=(0,r.useRef)(null);return(0,r.useCallback)(r=>{if(null===r){let e=i.current;e&&(i.current=null,e());let t=n.current;t&&(n.current=null,t())}else e&&(i.current=o(e,r)),t&&(n.current=o(t,r))},[e,t])}function o(e,t){if("function"!=typeof e)return e.current=t,()=>{e.current=null};{let i=e(t);return"function"==typeof i?i:()=>e(null)}}("function"==typeof i.default||"object"==typeof i.default&&null!==i.default)&&void 0===i.default.__esModule&&(Object.defineProperty(i.default,"__esModule",{value:!0}),Object.assign(i.default,i),t.exports=i.default)},18967,(e,t,i)=>{"use strict";Object.defineProperty(i,"__esModule",{value:!0});var r={DecodeError:function(){return b},MiddlewareNotFoundError:function(){return S},MissingStaticPage:function(){return x},NormalizeError:function(){return v},PageNotFoundError:function(){return y},SP:function(){return p},ST:function(){return f},WEB_VITALS:function(){return o},execOnce:function(){return a},getDisplayName:function(){return u},getLocationOrigin:function(){return l},getURL:function(){return d},isAbsoluteUrl:function(){return c},isResSent:function(){return h},loadGetInitialProps:function(){return g},normalizeRepeatedSlashes:function(){return m},stringifyError:function(){return w}};for(var n in r)Object.defineProperty(i,n,{enumerable:!0,get:r[n]});let o=["CLS","FCP","FID","INP","LCP","TTFB"];function a(e){let t,i=!1;return(...r)=>(i||(i=!0,t=e(...r)),t)}let s=/^[a-zA-Z][a-zA-Z\d+\-.]*?:/,c=e=>s.test(e);function l(){let{protocol:e,hostname:t,port:i}=window.location;return`${e}//${t}${i?":"+i:""}`}function d(){let{href:e}=window.location,t=l();return e.substring(t.length)}function u(e){return"string"==typeof e?e:e.displayName||e.name||"Unknown"}function h(e){return e.finished||e.headersSent}function m(e){let t=e.split("?");return t[0].replace(/\\/g,"/").replace(/\/\/+/g,"/")+(t[1]?`?${t.slice(1).join("?")}`:"")}async function g(e,t){let i=t.res||t.ctx&&t.ctx.res;if(!e.getInitialProps)return t.ctx&&t.Component?{pageProps:await g(t.Component,t.ctx)}:{};let r=await e.getInitialProps(t);if(i&&h(i))return r;if(!r)throw Object.defineProperty(Error(`"${u(e)}.getInitialProps()" should resolve to an object. But found "${r}" instead.`),"__NEXT_ERROR_CODE",{value:"E394",enumerable:!1,configurable:!0});return r}let p="u">typeof performance,f=p&&["mark","measure","getEntriesByName"].every(e=>"function"==typeof performance[e]);class b extends Error{}class v extends Error{}class y extends Error{constructor(e){super(),this.code="ENOENT",this.name="PageNotFoundError",this.message=`Cannot find module for page: ${e}`}}class x extends Error{constructor(e,t){super(),this.message=`Failed to load static file for page: ${e} ${t}`}}class S extends Error{constructor(){super(),this.code="ENOENT",this.message="Cannot find the middleware module"}}function w(e){return JSON.stringify({message:e.message,stack:e.stack})}},73668,(e,t,i)=>{"use strict";Object.defineProperty(i,"__esModule",{value:!0}),Object.defineProperty(i,"isLocalURL",{enumerable:!0,get:function(){return o}});let r=e.r(18967),n=e.r(52817);function o(e){if(!(0,r.isAbsoluteUrl)(e))return!0;try{let t=(0,r.getLocationOrigin)(),i=new URL(e,t);return i.origin===t&&(0,n.hasBasePath)(i.pathname)}catch(e){return!1}}},84508,(e,t,i)=>{"use strict";Object.defineProperty(i,"__esModule",{value:!0}),Object.defineProperty(i,"errorOnce",{enumerable:!0,get:function(){return r}});let r=e=>{}},22016,(e,t,i)=>{"use strict";Object.defineProperty(i,"__esModule",{value:!0});var r={default:function(){return b},useLinkStatus:function(){return y}};for(var n in r)Object.defineProperty(i,n,{enumerable:!0,get:r[n]});let o=e.r(90809),a=e.r(43476),s=o._(e.r(71645)),c=e.r(95057),l=e.r(8372),d=e.r(18581),u=e.r(18967),h=e.r(5550);e.r(33525);let m=e.r(91949),g=e.r(73668),p=e.r(9396);function f(e){return"string"==typeof e?e:(0,c.formatUrl)(e)}function b(t){var i;let r,n,o,[c,b]=(0,s.useOptimistic)(m.IDLE_LINK_STATUS),y=(0,s.useRef)(null),{href:x,as:S,children:w,prefetch:B=null,passHref:I,replace:k,shallow:A,scroll:M,onClick:C,onMouseEnter:V,onTouchStart:E,legacyBehavior:T=!1,onNavigate:P,ref:L,unstable_dynamicOnHover:R,...O}=t;r=w,T&&("string"==typeof r||"number"==typeof r)&&(r=(0,a.jsx)("a",{children:r}));let q=s.default.useContext(l.AppRouterContext),z=!1!==B,j=!1!==B?null===(i=B)||"auto"===i?p.FetchStrategy.PPR:p.FetchStrategy.Full:p.FetchStrategy.PPR,{href:U,as:F}=s.default.useMemo(()=>{let e=f(x);return{href:e,as:S?f(S):e}},[x,S]);if(T){if(r?.$$typeof===Symbol.for("react.lazy"))throw Object.defineProperty(Error("`<Link legacyBehavior>` received a direct child that is either a Server Component, or JSX that was loaded with React.lazy(). This is not supported. Either remove legacyBehavior, or make the direct child a Client Component that renders the Link's `<a>` tag."),"__NEXT_ERROR_CODE",{value:"E863",enumerable:!1,configurable:!0});n=s.default.Children.only(r)}let _=T?n&&"object"==typeof n&&n.ref:L,D=s.default.useCallback(e=>(null!==q&&(y.current=(0,m.mountLinkInstance)(e,U,q,j,z,b)),()=>{y.current&&((0,m.unmountLinkForCurrentNavigation)(y.current),y.current=null),(0,m.unmountPrefetchableInstance)(e)}),[z,U,q,j,b]),N={ref:(0,d.useMergedRef)(D,_),onClick(t){T||"function"!=typeof C||C(t),T&&n.props&&"function"==typeof n.props.onClick&&n.props.onClick(t),!q||t.defaultPrevented||function(t,i,r,n,o,a,c){if("u">typeof window){let l,{nodeName:d}=t.currentTarget;if("A"===d.toUpperCase()&&((l=t.currentTarget.getAttribute("target"))&&"_self"!==l||t.metaKey||t.ctrlKey||t.shiftKey||t.altKey||t.nativeEvent&&2===t.nativeEvent.which)||t.currentTarget.hasAttribute("download"))return;if(!(0,g.isLocalURL)(i)){o&&(t.preventDefault(),location.replace(i));return}if(t.preventDefault(),c){let e=!1;if(c({preventDefault:()=>{e=!0}}),e)return}let{dispatchNavigateAction:u}=e.r(99781);s.default.startTransition(()=>{u(r||i,o?"replace":"push",a??!0,n.current)})}}(t,U,F,y,k,M,P)},onMouseEnter(e){T||"function"!=typeof V||V(e),T&&n.props&&"function"==typeof n.props.onMouseEnter&&n.props.onMouseEnter(e),q&&z&&(0,m.onNavigationIntent)(e.currentTarget,!0===R)},onTouchStart:function(e){T||"function"!=typeof E||E(e),T&&n.props&&"function"==typeof n.props.onTouchStart&&n.props.onTouchStart(e),q&&z&&(0,m.onNavigationIntent)(e.currentTarget,!0===R)}};return(0,u.isAbsoluteUrl)(F)?N.href=F:T&&!I&&("a"!==n.type||"href"in n.props)||(N.href=(0,h.addBasePath)(F)),o=T?s.default.cloneElement(n,N):(0,a.jsx)("a",{...O,...N,children:r}),(0,a.jsx)(v.Provider,{value:c,children:o})}e.r(84508);let v=(0,s.createContext)(m.IDLE_LINK_STATUS),y=()=>(0,s.useContext)(v);("function"==typeof i.default||"object"==typeof i.default&&null!==i.default)&&void 0===i.default.__esModule&&(Object.defineProperty(i.default,"__esModule",{value:!0}),Object.assign(i.default,i),t.exports=i.default)},75254,e=>{"use strict";var t=e.i(71645);let i=(...e)=>e.filter((e,t,i)=>!!e&&""!==e.trim()&&i.indexOf(e)===t).join(" ").trim(),r=e=>{let t=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,t,i)=>i?i.toUpperCase():t.toLowerCase());return t.charAt(0).toUpperCase()+t.slice(1)};var n={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let o=(0,t.forwardRef)(({color:e="currentColor",size:r=24,strokeWidth:o=2,absoluteStrokeWidth:a,className:s="",children:c,iconNode:l,...d},u)=>(0,t.createElement)("svg",{ref:u,...n,width:r,height:r,stroke:e,strokeWidth:a?24*Number(o)/Number(r):o,className:i("lucide",s),...!c&&!(e=>{for(let t in e)if(t.startsWith("aria-")||"role"===t||"title"===t)return!0;return!1})(d)&&{"aria-hidden":"true"},...d},[...l.map(([e,i])=>(0,t.createElement)(e,i)),...Array.isArray(c)?c:[c]])),a=(e,n)=>{let a=(0,t.forwardRef)(({className:a,...s},c)=>(0,t.createElement)(o,{ref:c,iconNode:n,className:i(`lucide-${r(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,a),...s}));return a.displayName=r(e),a};e.s(["default",()=>a],75254)},91918,20783,e=>{"use strict";var t=e.i(71645);function i(e,t){if("function"==typeof e)return e(t);null!=e&&(e.current=t)}function r(...e){return t=>{let r=!1,n=e.map(e=>{let n=i(e,t);return r||"function"!=typeof n||(r=!0),n});if(r)return()=>{for(let t=0;t<n.length;t++){let r=n[t];"function"==typeof r?r():i(e[t],null)}}}}function n(...e){return t.useCallback(r(...e),e)}e.s(["composeRefs",()=>r,"useComposedRefs",()=>n],20783);var o=e.i(43476);function a(e){var i;let n,a=(i=e,(n=t.forwardRef((e,i)=>{let{children:n,...o}=e;if(t.isValidElement(n)){var a;let e,s,c=(a=n,(s=(e=Object.getOwnPropertyDescriptor(a.props,"ref")?.get)&&"isReactWarning"in e&&e.isReactWarning)?a.ref:(s=(e=Object.getOwnPropertyDescriptor(a,"ref")?.get)&&"isReactWarning"in e&&e.isReactWarning)?a.props.ref:a.props.ref||a.ref),l=function(e,t){let i={...t};for(let r in t){let n=e[r],o=t[r];/^on[A-Z]/.test(r)?n&&o?i[r]=(...e)=>{let t=o(...e);return n(...e),t}:n&&(i[r]=n):"style"===r?i[r]={...n,...o}:"className"===r&&(i[r]=[n,o].filter(Boolean).join(" "))}return{...e,...i}}(o,n.props);return n.type!==t.Fragment&&(l.ref=i?r(i,c):c),t.cloneElement(n,l)}return t.Children.count(n)>1?t.Children.only(null):null})).displayName=`${i}.SlotClone`,n),s=t.forwardRef((e,i)=>{let{children:r,...n}=e,s=t.Children.toArray(r),c=s.find(u);if(c){let e=c.props.children,r=s.map(i=>i!==c?i:t.Children.count(e)>1?t.Children.only(null):t.isValidElement(e)?e.props.children:null);return(0,o.jsx)(a,{...n,ref:i,children:t.isValidElement(e)?t.cloneElement(e,void 0,r):null})}return(0,o.jsx)(a,{...n,ref:i,children:r})});return s.displayName=`${e}.Slot`,s}var s=a("Slot"),c=Symbol("radix.slottable");function l(e){let t=({children:e})=>(0,o.jsx)(o.Fragment,{children:e});return t.displayName=`${e}.Slottable`,t.__radixId=c,t}var d=l("Slottable");function u(e){return t.isValidElement(e)&&"function"==typeof e.type&&"__radixId"in e.type&&e.type.__radixId===c}e.s(["Root",()=>s,"Slot",()=>s,"Slottable",()=>d,"createSlot",()=>a,"createSlottable",()=>l],91918)},19455,e=>{"use strict";let t,i;var r=e.i(43476),n=e.i(7670);let o=e=>"boolean"==typeof e?`${e}`:0===e?"0":e,a=n.clsx;var s=e.i(91918),s=s,c=e.i(75157);let l=(t="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:ring-[3px] focus-visible:ring-primary/35 focus-visible:border-primary/40 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",i={variants:{variant:{default:"bg-primary text-primary-foreground hover:bg-primary/90",destructive:"bg-destructive text-white hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60",outline:"border border-white/12 bg-background/80 shadow-xs hover:bg-accent/70 hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50",secondary:"bg-secondary text-secondary-foreground hover:bg-secondary/80",ghost:"hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50",link:"text-primary underline-offset-4 hover:underline"},size:{default:"h-9 px-4 py-2 has-[>svg]:px-3",xs:"h-6 gap-1 rounded-md px-2 text-xs has-[>svg]:px-1.5 [&_svg:not([class*='size-'])]:size-3",sm:"h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5",lg:"h-10 rounded-md px-6 has-[>svg]:px-4",icon:"size-9","icon-xs":"size-6 rounded-md [&_svg:not([class*='size-'])]:size-3","icon-sm":"size-8","icon-lg":"size-10"}},defaultVariants:{variant:"default",size:"default"}},e=>{var r;if((null==i?void 0:i.variants)==null)return a(t,null==e?void 0:e.class,null==e?void 0:e.className);let{variants:n,defaultVariants:s}=i,c=Object.keys(n).map(t=>{let i=null==e?void 0:e[t],r=null==s?void 0:s[t];if(null===i)return null;let a=o(i)||o(r);return n[t][a]}),l=e&&Object.entries(e).reduce((e,t)=>{let[i,r]=t;return void 0===r||(e[i]=r),e},{});return a(t,c,null==i||null==(r=i.compoundVariants)?void 0:r.reduce((e,t)=>{let{class:i,className:r,...n}=t;return Object.entries(n).every(e=>{let[t,i]=e;return Array.isArray(i)?i.includes({...s,...l}[t]):({...s,...l})[t]===i})?[...e,i,r]:e},[]),null==e?void 0:e.class,null==e?void 0:e.className)});function d({className:e,variant:t="default",size:i="default",asChild:n=!1,...o}){let a=n?s.Root:"button";return(0,r.jsx)(a,{"data-slot":"button","data-variant":t,"data-size":i,className:(0,c.cn)(l({variant:t,size:i,className:e})),...o})}e.s(["Button",()=>d],19455)},78745,e=>{"use strict";let t=(0,e.i(75254).default)("check",[["path",{d:"M20 6 9 17l-5-5",key:"1gmf2c"}]]);e.s(["default",()=>t])},46798,59411,e=>{"use strict";var t=e.i(43476),i=e.i(71645),r=e.i(81140),n=e.i(20783),o=e.i(30030),a=e.i(26330),s=e.i(10772),c=e.i(53660),l=e.i(74606),d=e.i(96626),u=e.i(48425),h=e.i(91918),m=e.i(69340),g=Object.freeze({position:"absolute",border:0,width:1,height:1,padding:0,margin:-1,overflow:"hidden",clip:"rect(0, 0, 0, 0)",whiteSpace:"nowrap",wordWrap:"normal"}),p=i.forwardRef((e,i)=>(0,t.jsx)(u.Primitive.span,{...e,ref:i,style:{...g,...e.style}}));p.displayName="VisuallyHidden",e.s(["Root",()=>p,"VISUALLY_HIDDEN_STYLES",()=>g],59411);var[f,b]=(0,o.createContextScope)("Tooltip",[c.createPopperScope]),v=(0,c.createPopperScope)(),y="TooltipProvider",x="tooltip.open",[S,w]=f(y),B=e=>{let{__scopeTooltip:r,delayDuration:n=700,skipDelayDuration:o=300,disableHoverableContent:a=!1,children:s}=e,c=i.useRef(!0),l=i.useRef(!1),d=i.useRef(0);return i.useEffect(()=>{let e=d.current;return()=>window.clearTimeout(e)},[]),(0,t.jsx)(S,{scope:r,isOpenDelayedRef:c,delayDuration:n,onOpen:i.useCallback(()=>{window.clearTimeout(d.current),c.current=!1},[]),onClose:i.useCallback(()=>{window.clearTimeout(d.current),d.current=window.setTimeout(()=>c.current=!0,o)},[o]),isPointerInTransitRef:l,onPointerInTransitChange:i.useCallback(e=>{l.current=e},[]),disableHoverableContent:a,children:s})};B.displayName=y;var I="Tooltip",[k,A]=f(I),M=e=>{let{__scopeTooltip:r,children:n,open:o,defaultOpen:a,onOpenChange:l,disableHoverableContent:d,delayDuration:u}=e,h=w(I,e.__scopeTooltip),g=v(r),[p,f]=i.useState(null),b=(0,s.useId)(),y=i.useRef(0),S=d??h.disableHoverableContent,B=u??h.delayDuration,A=i.useRef(!1),[M,C]=(0,m.useControllableState)({prop:o,defaultProp:a??!1,onChange:e=>{e?(h.onOpen(),document.dispatchEvent(new CustomEvent(x))):h.onClose(),l?.(e)},caller:I}),V=i.useMemo(()=>M?A.current?"delayed-open":"instant-open":"closed",[M]),E=i.useCallback(()=>{window.clearTimeout(y.current),y.current=0,A.current=!1,C(!0)},[C]),T=i.useCallback(()=>{window.clearTimeout(y.current),y.current=0,C(!1)},[C]),P=i.useCallback(()=>{window.clearTimeout(y.current),y.current=window.setTimeout(()=>{A.current=!0,C(!0),y.current=0},B)},[B,C]);return i.useEffect(()=>()=>{y.current&&(window.clearTimeout(y.current),y.current=0)},[]),(0,t.jsx)(c.Root,{...g,children:(0,t.jsx)(k,{scope:r,contentId:b,open:M,stateAttribute:V,trigger:p,onTriggerChange:f,onTriggerEnter:i.useCallback(()=>{h.isOpenDelayedRef.current?P():E()},[h.isOpenDelayedRef,P,E]),onTriggerLeave:i.useCallback(()=>{S?T():(window.clearTimeout(y.current),y.current=0)},[T,S]),onOpen:E,onClose:T,disableHoverableContent:S,children:n})})};M.displayName=I;var C="TooltipTrigger",V=i.forwardRef((e,o)=>{let{__scopeTooltip:a,...s}=e,l=A(C,a),d=w(C,a),h=v(a),m=i.useRef(null),g=(0,n.useComposedRefs)(o,m,l.onTriggerChange),p=i.useRef(!1),f=i.useRef(!1),b=i.useCallback(()=>p.current=!1,[]);return i.useEffect(()=>()=>document.removeEventListener("pointerup",b),[b]),(0,t.jsx)(c.Anchor,{asChild:!0,...h,children:(0,t.jsx)(u.Primitive.button,{"aria-describedby":l.open?l.contentId:void 0,"data-state":l.stateAttribute,...s,ref:g,onPointerMove:(0,r.composeEventHandlers)(e.onPointerMove,e=>{"touch"!==e.pointerType&&(f.current||d.isPointerInTransitRef.current||(l.onTriggerEnter(),f.current=!0))}),onPointerLeave:(0,r.composeEventHandlers)(e.onPointerLeave,()=>{l.onTriggerLeave(),f.current=!1}),onPointerDown:(0,r.composeEventHandlers)(e.onPointerDown,()=>{l.open&&l.onClose(),p.current=!0,document.addEventListener("pointerup",b,{once:!0})}),onFocus:(0,r.composeEventHandlers)(e.onFocus,()=>{p.current||l.onOpen()}),onBlur:(0,r.composeEventHandlers)(e.onBlur,l.onClose),onClick:(0,r.composeEventHandlers)(e.onClick,l.onClose)})})});V.displayName=C;var E="TooltipPortal",[T,P]=f(E,{forceMount:void 0}),L=e=>{let{__scopeTooltip:i,forceMount:r,children:n,container:o}=e,a=A(E,i);return(0,t.jsx)(T,{scope:i,forceMount:r,children:(0,t.jsx)(d.Presence,{present:r||a.open,children:(0,t.jsx)(l.Portal,{asChild:!0,container:o,children:n})})})};L.displayName=E;var R="TooltipContent",O=i.forwardRef((e,i)=>{let r=P(R,e.__scopeTooltip),{forceMount:n=r.forceMount,side:o="top",...a}=e,s=A(R,e.__scopeTooltip);return(0,t.jsx)(d.Presence,{present:n||s.open,children:s.disableHoverableContent?(0,t.jsx)(F,{side:o,...a,ref:i}):(0,t.jsx)(q,{side:o,...a,ref:i})})}),q=i.forwardRef((e,r)=>{let o=A(R,e.__scopeTooltip),a=w(R,e.__scopeTooltip),s=i.useRef(null),c=(0,n.useComposedRefs)(r,s),[l,d]=i.useState(null),{trigger:u,onClose:h}=o,m=s.current,{onPointerInTransitChange:g}=a,p=i.useCallback(()=>{d(null),g(!1)},[g]),f=i.useCallback((e,t)=>{let i,r=e.currentTarget,n={x:e.clientX,y:e.clientY},o=function(e,t){let i=Math.abs(t.top-e.y),r=Math.abs(t.bottom-e.y),n=Math.abs(t.right-e.x),o=Math.abs(t.left-e.x);switch(Math.min(i,r,n,o)){case o:return"left";case n:return"right";case i:return"top";case r:return"bottom";default:throw Error("unreachable")}}(n,r.getBoundingClientRect());d(((i=[...function(e,t,i=5){let r=[];switch(t){case"top":r.push({x:e.x-i,y:e.y+i},{x:e.x+i,y:e.y+i});break;case"bottom":r.push({x:e.x-i,y:e.y-i},{x:e.x+i,y:e.y-i});break;case"left":r.push({x:e.x+i,y:e.y-i},{x:e.x+i,y:e.y+i});break;case"right":r.push({x:e.x-i,y:e.y-i},{x:e.x-i,y:e.y+i})}return r}(n,o),...function(e){let{top:t,right:i,bottom:r,left:n}=e;return[{x:n,y:t},{x:i,y:t},{x:i,y:r},{x:n,y:r}]}(t.getBoundingClientRect())].slice()).sort((e,t)=>e.x<t.x?-1:e.x>t.x?1:e.y<t.y?-1:1*!!(e.y>t.y)),function(e){if(e.length<=1)return e.slice();let t=[];for(let i=0;i<e.length;i++){let r=e[i];for(;t.length>=2;){let e=t[t.length-1],i=t[t.length-2];if((e.x-i.x)*(r.y-i.y)>=(e.y-i.y)*(r.x-i.x))t.pop();else break}t.push(r)}t.pop();let i=[];for(let t=e.length-1;t>=0;t--){let r=e[t];for(;i.length>=2;){let e=i[i.length-1],t=i[i.length-2];if((e.x-t.x)*(r.y-t.y)>=(e.y-t.y)*(r.x-t.x))i.pop();else break}i.push(r)}return(i.pop(),1===t.length&&1===i.length&&t[0].x===i[0].x&&t[0].y===i[0].y)?t:t.concat(i)}(i))),g(!0)},[g]);return i.useEffect(()=>()=>p(),[p]),i.useEffect(()=>{if(u&&m){let e=e=>f(e,m),t=e=>f(e,u);return u.addEventListener("pointerleave",e),m.addEventListener("pointerleave",t),()=>{u.removeEventListener("pointerleave",e),m.removeEventListener("pointerleave",t)}}},[u,m,f,p]),i.useEffect(()=>{if(l){let e=e=>{let t=e.target,i={x:e.clientX,y:e.clientY},r=u?.contains(t)||m?.contains(t),n=!function(e,t){let{x:i,y:r}=e,n=!1;for(let e=0,o=t.length-1;e<t.length;o=e++){let a=t[e],s=t[o],c=a.x,l=a.y,d=s.x,u=s.y;l>r!=u>r&&i<(d-c)*(r-l)/(u-l)+c&&(n=!n)}return n}(i,l);r?p():n&&(p(),h())};return document.addEventListener("pointermove",e),()=>document.removeEventListener("pointermove",e)}},[u,m,l,h,p]),(0,t.jsx)(F,{...e,ref:c})}),[z,j]=f(I,{isInside:!1}),U=(0,h.createSlottable)("TooltipContent"),F=i.forwardRef((e,r)=>{let{__scopeTooltip:n,children:o,"aria-label":s,onEscapeKeyDown:l,onPointerDownOutside:d,...u}=e,h=A(R,n),m=v(n),{onClose:g}=h;return i.useEffect(()=>(document.addEventListener(x,g),()=>document.removeEventListener(x,g)),[g]),i.useEffect(()=>{if(h.trigger){let e=e=>{let t=e.target;t?.contains(h.trigger)&&g()};return window.addEventListener("scroll",e,{capture:!0}),()=>window.removeEventListener("scroll",e,{capture:!0})}},[h.trigger,g]),(0,t.jsx)(a.DismissableLayer,{asChild:!0,disableOutsidePointerEvents:!1,onEscapeKeyDown:l,onPointerDownOutside:d,onFocusOutside:e=>e.preventDefault(),onDismiss:g,children:(0,t.jsxs)(c.Content,{"data-state":h.stateAttribute,...m,...u,ref:r,style:{...u.style,"--radix-tooltip-content-transform-origin":"var(--radix-popper-transform-origin)","--radix-tooltip-content-available-width":"var(--radix-popper-available-width)","--radix-tooltip-content-available-height":"var(--radix-popper-available-height)","--radix-tooltip-trigger-width":"var(--radix-popper-anchor-width)","--radix-tooltip-trigger-height":"var(--radix-popper-anchor-height)"},children:[(0,t.jsx)(U,{children:o}),(0,t.jsx)(z,{scope:n,isInside:!0,children:(0,t.jsx)(p,{id:h.contentId,role:"tooltip",children:s||o})})]})})});O.displayName=R;var _="TooltipArrow",D=i.forwardRef((e,i)=>{let{__scopeTooltip:r,...n}=e,o=v(r);return j(_,r).isInside?null:(0,t.jsx)(c.Arrow,{...o,...n,ref:i})});D.displayName=_,e.s(["Arrow",()=>D,"Content",()=>O,"Portal",()=>L,"Provider",()=>B,"Root",()=>M,"Tooltip",()=>M,"TooltipArrow",()=>D,"TooltipContent",()=>O,"TooltipPortal",()=>L,"TooltipProvider",()=>B,"TooltipTrigger",()=>V,"Trigger",()=>V,"createTooltipScope",()=>b],86336);var N=e.i(86336),N=N,Q=e.i(75157);function H({delayDuration:e=0,...i}){return(0,t.jsx)(N.Provider,{"data-slot":"tooltip-provider",delayDuration:e,...i})}function $({...e}){return(0,t.jsx)(N.Root,{"data-slot":"tooltip",...e})}function W({...e}){return(0,t.jsx)(N.Trigger,{"data-slot":"tooltip-trigger",...e})}function G({className:e,sideOffset:i=0,children:r,...n}){return(0,t.jsx)(N.Portal,{children:(0,t.jsxs)(N.Content,{"data-slot":"tooltip-content",sideOffset:i,className:(0,Q.cn)("bg-foreground text-background animate-in fade-in-0 zoom-in-95 data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=closed]:zoom-out-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 w-fit origin-(--radix-tooltip-content-transform-origin) rounded-md px-3 py-1.5 text-xs text-balance",e),...n,children:[r,(0,t.jsx)(N.Arrow,{className:"bg-foreground fill-foreground z-50 size-2.5 translate-y-[calc(-50%_-_2px)] rotate-45 rounded-[2px]"})]})})}e.s(["Tooltip",()=>$,"TooltipContent",()=>G,"TooltipProvider",()=>H,"TooltipTrigger",()=>W],46798)},50361,24540,e=>{"use strict";e.i(47167);var t=e.i(71645);let i=function(){try{let e="nuqs-localStorage-test";if("u"<typeof localStorage)return!1;localStorage.setItem(e,e);let t=localStorage.getItem(e)===e;return localStorage.removeItem(e),t&&(localStorage.getItem("debug")||"").includes("nuqs")}catch{return!1}}();function r(e,...t){if(!i)return;let n=function(e,...t){return e.replace(/%[sfdO]/g,e=>{let i=t.shift();return"%O"===e&&i?JSON.stringify(i).replace(/"([^"]+)":/g,"$1:"):String(i)})}(e,...t);performance.mark(n);try{console.log(e,...t)}catch{console.log(n)}}function n(e,...t){i&&console.warn(e,...t)}let o={303:"Multiple adapter contexts detected. This might happen in monorepos.",404:"nuqs requires an adapter to work with your framework.",409:"Multiple versions of the library are loaded. This may lead to unexpected behavior. Currently using `%s`, but `%s` (via the %s adapter) was about to load on top.",414:"Max safe URL length exceeded. Some browsers may not be able to accept this URL. Consider limiting the amount of state stored in the URL.",422:"Invalid options combination: `limitUrlUpdates: debounce` should be used in SSR scenarios, with `shallow: false`",429:"URL update rate-limited by the browser. Consider increasing `throttleMs` for key(s) `%s`. %O",500:"Empty search params cache. Search params can't be accessed in Layouts.",501:"Search params cache already populated. Have you called `parse` twice?"};function a(e){return`[nuqs] ${o[e]}
  See https://nuqs.dev/NUQS-${e}`}function s(e){if(0===e.size)return"";let t=[];for(let[i,r]of e.entries()){let e=i.replace(/#/g,"%23").replace(/&/g,"%26").replace(/\+/g,"%2B").replace(/=/g,"%3D").replace(/\?/g,"%3F");t.push(`${e}=${r.replace(/%/g,"%25").replace(/\+/g,"%2B").replace(/ /g,"+").replace(/#/g,"%23").replace(/&/g,"%26").replace(/"/g,"%22").replace(/'/g,"%27").replace(/`/g,"%60").replace(/</g,"%3C").replace(/>/g,"%3E").replace(/[\x00-\x1F]/g,e=>encodeURIComponent(e))}`)}return"?"+t.join("&")}let c=(0,t.createContext)({useAdapter(){throw Error(a(404))}});function l(e){return({children:i,defaultOptions:r,processUrlSearchParams:n,...o})=>(0,t.createElement)(c.Provider,{...o,value:{useAdapter:e,defaultOptions:r,processUrlSearchParams:n}},i)}function d(e){let i=(0,t.useContext)(c);if(!("useAdapter"in i))throw Error(a(404));return i.useAdapter(e)}c.displayName="NuqsAdapterContext",i&&"u">typeof window&&(window.__NuqsAdapterContext&&window.__NuqsAdapterContext!==c&&console.error(a(303)),window.__NuqsAdapterContext=c);let u=()=>(0,t.useContext)(c).defaultOptions,h=()=>(0,t.useContext)(c).processUrlSearchParams;function m(e){return{method:"throttle",timeMs:e}}function g(e){return{method:"debounce",timeMs:e}}e.s(["a",()=>h,"c",()=>r,"i",()=>u,"l",()=>n,"n",()=>l,"o",()=>s,"r",()=>d,"s",()=>a],24540);let p=m(function(){if("u"<typeof window||!window.GestureEvent)return 50;try{let e=navigator.userAgent?.match(/version\/([\d\.]+) safari/i);return parseFloat(e[1])>=17?120:320}catch{return 320}}());function f(e){return null===e||Array.isArray(e)&&0===e.length}function b(e,t,i){if("string"==typeof e)i.set(t,e);else{for(let r of(i.delete(t),e))i.append(t,r);i.has(t)||i.set(t,"")}return i}function v(){let e=new Map;return{on(t,i){let r=e.get(t)||[];return r.push(i),e.set(t,r),()=>this.off(t,i)},off(t,i){let r=e.get(t);r&&e.set(t,r.filter(e=>e!==i))},emit(t,i){e.get(t)?.forEach(e=>e(i))}}}function y(e,t,i){let r=setTimeout(function(){e(),i.removeEventListener("abort",n)},t);function n(){clearTimeout(r),i.removeEventListener("abort",n)}i.addEventListener("abort",n)}function x(){let e=Promise;if(Promise.hasOwnProperty("withResolvers"))return Promise.withResolvers();let t=()=>{},i=()=>{};return{promise:new e((e,r)=>{t=e,i=r}),resolve:t,reject:i}}function S(){return new URLSearchParams(location.search)}var w=class{updateMap=new Map;options={history:"replace",scroll:!1,shallow:!0};timeMs=p.timeMs;transitions=new Set;resolvers=null;controller=null;lastFlushedAt=0;resetQueueOnNextPush=!1;push({key:e,query:t,options:i},n=p.timeMs){this.resetQueueOnNextPush&&(this.reset(),this.resetQueueOnNextPush=!1),r("[nuqs gtq] Enqueueing %s=%s %O",e,t,i),this.updateMap.set(e,t),"push"===i.history&&(this.options.history="push"),i.scroll&&(this.options.scroll=!0),!1===i.shallow&&(this.options.shallow=!1),i.startTransition&&this.transitions.add(i.startTransition),(!Number.isFinite(this.timeMs)||n>this.timeMs)&&(this.timeMs=n)}getQueuedQuery(e){return this.updateMap.get(e)}getPendingPromise({getSearchParamsSnapshot:e=S}){return this.resolvers?.promise??Promise.resolve(e())}flush({getSearchParamsSnapshot:e=S,rateLimitFactor:t=1,...i},n){if(this.controller??=new AbortController,!Number.isFinite(this.timeMs))return r("[nuqs gtq] Skipping flush due to throttleMs=Infinity"),Promise.resolve(e());if(this.resolvers)return this.resolvers.promise;this.resolvers=x();let o=()=>{this.lastFlushedAt=performance.now();let[t,r]=this.applyPendingUpdates({...i,autoResetQueueOnUpdate:i.autoResetQueueOnUpdate??!0,getSearchParamsSnapshot:e},n);null===r?(this.resolvers.resolve(t),this.resetQueueOnNextPush=!0):this.resolvers.reject(t),this.resolvers=null},a=()=>{let e=performance.now()-this.lastFlushedAt,i=this.timeMs,n=t*Math.max(0,i-e);r("[nuqs gtq] Scheduling flush in %f ms. Throttled at %f ms (x%f)",n,i,t),0===n?o():y(o,n,this.controller.signal)};return y(a,0,this.controller.signal),this.resolvers.promise}abort(){return this.controller?.abort(),this.controller=new AbortController,this.resolvers?.resolve(new URLSearchParams),this.resolvers=null,this.reset()}reset(){let e=Array.from(this.updateMap.keys());return r("[nuqs gtq] Resetting queue %s",JSON.stringify(Object.fromEntries(this.updateMap))),this.updateMap.clear(),this.transitions.clear(),this.options={history:"replace",scroll:!1,shallow:!0},this.timeMs=p.timeMs,e}applyPendingUpdates(e,t){let{updateUrl:i,getSearchParamsSnapshot:n}=e,o=n();if(r("[nuqs gtq] Applying %d pending update(s) on top of %s",this.updateMap.size,o.toString()),0===this.updateMap.size)return[o,null];let s=Array.from(this.updateMap.entries()),c={...this.options},l=Array.from(this.transitions);for(let[t,i]of(e.autoResetQueueOnUpdate&&this.reset(),r("[nuqs gtq] Flushing queue %O with options %O",s,c),s))null===i?o.delete(t):o=b(i,t,o);t&&(o=t(o));try{return!function(e,t){let i=t;for(let t=e.length-1;t>=0;t--){let r=e[t];if(!r)continue;let n=i;i=()=>r(n)}i()}(l,()=>{i(o,c)}),[o,null]}catch(e){return console.error(a(429),s.map(([e])=>e).join(),e),[o,e]}}};let B=new w;var I=class{callback;resolvers=x();controller=new AbortController;queuedValue=void 0;constructor(e){this.callback=e}abort(){this.controller.abort(),this.queuedValue=void 0}push(e,t){return this.queuedValue=e,this.controller.abort(),this.controller=new AbortController,y(()=>{let t=this.resolvers;try{r("[nuqs dq] Flushing debounce queue",e);let i=this.callback(e);r("[nuqs dq] Reset debounce queue %O",this.queuedValue),this.queuedValue=void 0,this.resolvers=x(),i.then(e=>t.resolve(e)).catch(e=>t.reject(e))}catch(e){this.queuedValue=void 0,t.reject(e)}},t,this.controller.signal),this.resolvers.promise}};let k=new class{throttleQueue;queues=new Map;queuedQuerySync=v();constructor(e=new w){this.throttleQueue=e}useQueuedQueries(e){var i,r;let n,o;return i=(e,t)=>this.queuedQuerySync.on(e,t),r=e=>this.getQueuedQuery(e),n=(0,t.useCallback)(()=>{let t=Object.fromEntries(e.map(e=>[e,r(e)]));return[JSON.stringify(t),t]},[e.join(","),r]),null===(o=(0,t.useRef)(null)).current&&(o.current=n()),(0,t.useSyncExternalStore)((0,t.useCallback)(t=>{let r=e.map(e=>i(e,t));return()=>r.forEach(e=>e())},[e.join(","),i]),()=>{let[e,t]=n();return o.current[0]===e?o.current[1]:(o.current=[e,t],t)},()=>o.current[1])}push(e,t,i,n){if(!Number.isFinite(t))return Promise.resolve((i.getSearchParamsSnapshot??S)());let o=e.key;if(!this.queues.has(o)){r("[nuqs dqc] Creating debounce queue for `%s`",o);let e=new I(e=>(this.throttleQueue.push(e),this.throttleQueue.flush(i,n).finally(()=>{this.queues.get(e.key)?.queuedValue===void 0&&(r("[nuqs dqc] Cleaning up empty queue for `%s`",e.key),this.queues.delete(e.key)),this.queuedQuerySync.emit(e.key)})));this.queues.set(o,e)}r("[nuqs dqc] Enqueueing debounce update %O",e);let a=this.queues.get(o).push(e,t);return this.queuedQuerySync.emit(o),a}abort(e){let t=this.queues.get(e);return t?(r("[nuqs dqc] Aborting debounce queue %s=%s",e,t.queuedValue?.query),this.queues.delete(e),t.abort(),this.queuedQuerySync.emit(e),e=>(e.then(t.resolvers.resolve,t.resolvers.reject),e)):e=>e}abortAll(){for(let[e,t]of this.queues.entries())r("[nuqs dqc] Aborting debounce queue %s=%s",e,t.queuedValue?.query),t.abort(),t.resolvers.resolve(new URLSearchParams),this.queuedQuerySync.emit(e);this.queues.clear()}getQueuedQuery(e){let t=this.queues.get(e)?.queuedValue?.query;return void 0!==t?t:this.throttleQueue.getQueuedQuery(e)}}(B);e.s(["a",()=>b,"c",()=>m,"i",()=>f,"n",()=>B,"o",()=>g,"r",()=>v,"s",()=>p,"t",()=>k],50361)},55436,e=>{"use strict";let t=(0,e.i(75254).default)("search",[["path",{d:"m21 21-4.34-4.34",key:"14j7rj"}],["circle",{cx:"11",cy:"11",r:"8",key:"4ej97u"}]]);e.s(["Search",()=>t],55436)},53073,e=>{"use strict";let t={mmlu:"https://arxiv.org/abs/2009.03300","mmlu-pro":"https://arxiv.org/abs/2406.01574",math:"https://arxiv.org/abs/2103.03874","human-eval":"https://arxiv.org/abs/2107.03374","swe-bench-verified":"https://www.swebench.com/",mmmu:"https://mmmu-benchmark.github.io/","mmmu-pro":"https://mmmu-benchmark.github.io/","mmmu-val":"https://mmmu-benchmark.github.io/","mmmu-vision":"https://mmmu-benchmark.github.io/",mmmlu:"https://arxiv.org/abs/2402.03300",mathvista:"https://mathvista.github.io/","mathvista-mini":"https://mathvista.github.io/",livebench:"https://livebench.ai/#/","livecodebench-v6":"https://livecodebench.github.io/","livecodebench-pro":"https://livecodebenchpro.com/",bigcodebench:"https://github.com/bigcode-project/bigcodebench",gsm8k:"https://github.com/openai/grade-school-math",aime:"https://artofproblemsolving.com/wiki/index.php/AIME","aime-2025":"https://artofproblemsolving.com/wiki/index.php/AIME","aime-2026":"https://artofproblemsolving.com/wiki/index.php/AIME","gpqa-diamond":"https://arxiv.org/abs/2311.12022","arc-agi-1":"https://arcprize.org/","arc-agi-2":"https://arcprize.org/","arc-agi-1-image":"https://arcprize.org/","arc-agi-2-image":"https://arcprize.org/",hle:"https://agi.safe.ai/","hle-full":"https://agi.safe.ai/","hle-full-tools":"https://agi.safe.ai/","hle-text":"https://agi.safe.ai/","hle-verified":"https://agi.safe.ai/","hle-vl":"https://agi.safe.ai/",codeforces:"https://codeforces.com/","lmarena-elo":"https://chat.lmsys.org/?leaderboard",webarena:"https://webarena.dev/",agentbench:"https://github.com/THUDM/AgentBench","tau-bench":"https://github.com/sierra-research/tau2-bench","tau-bench-retail":"https://taubench.com/","tau-bench-telecom":"https://github.com/sierra-research/tau2-bench",docvqa:"https://rrc.cvc.uab.es/?ch=17",ocrbench:"https://ocrbench.github.io/","ocrbench-v2":"https://ocrbench.github.io/",videomme:"https://video-mme.github.io/","terminal-bench":"https://www.tbench.ai/leaderboard/terminal-bench/2.0","terminal-bench-hard":"https://www.tbench.ai/leaderboard/terminal-bench/2.0","osworld-verified":"https://os-world.github.io/","swe-bench-pro":"https://www.swebench.com/",lcr:"https://artificialanalysis.ai/evaluations#lcr",ifbench:"https://artificialanalysis.ai/evaluations#ifbench","aa-omniscience":"https://artificialanalysis.ai/evaluations#omniscience",critpt:"https://arxiv.org/abs/2501.00663",scicode:"https://github.com/scicode-bench/scicode",browsecomp:"https://github.com/google-research/browsecomp","screenspot-pro":"https://github.com/octopus-tools/screenspot-pro","charxiv-reasoning":"https://arxiv.org/abs/2406.18521","facts-benchmark":"https://github.com/google-deepmind/facts-benchmark","mcp-atlas":"https://github.com/modelcontextprotocol/mcp-atlas",toolathlon:"https://github.com/toolathlon/toolathlon"},i=[{id:"mmlu",name:"MMLU (5-shot)",category:"Knowledge",description:"Massive Multitask Language Understanding covers 57 subjects across STEM, the humanities, social sciences, and more.",maxScore:100,higherIsBetter:!0,link:"https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu",paperUrl:"https://arxiv.org/abs/2009.03300"},{id:"math",name:"MATH (CoT)",category:"Math",description:"Challenging competition mathematics problems (AIME/IMO level).",maxScore:100,higherIsBetter:!0,link:"https://paperswithcode.com/sota/math-word-problem-solving-on-math",paperUrl:"https://arxiv.org/abs/2103.03874"},{id:"human-eval",name:"HumanEval",category:"Coding",description:"Functional correctness of synthesized programs from docstrings.",maxScore:100,higherIsBetter:!0,link:"https://paperswithcode.com/sota/code-generation-on-humaneval",paperUrl:"https://arxiv.org/abs/2107.03374"},{id:"swe-bench-verified",name:"SWE-bench Verified",category:"Coding",description:"Resolving real-world GitHub issues. Verified subset ensures solvable issues.",maxScore:100,higherIsBetter:!0,link:"https://www.swebench.com/",paperUrl:"https://arxiv.org/abs/2310.06770"},{id:"mmmu",name:"MMMU (Multimodal)",category:"Multimodal",description:"Multi-discipline Multimodal Understanding and Reasoning.",maxScore:100,higherIsBetter:!0,link:"https://mmmu-benchmark.github.io/",paperUrl:"https://arxiv.org/abs/2311.16502"},{id:"livebench",name:"LiveBench",category:"Reasoning",description:"Contamination-free, continuously updated reasoning benchmark.",maxScore:100,higherIsBetter:!0,link:"https://livebench.ai/#/",paperUrl:"https://arxiv.org/abs/2406.19314"},{id:"bigcodebench",name:"BigCodeBench",category:"Coding",description:"Next-generation HumanEval with more diverse library calls and complex tasks.",maxScore:100,higherIsBetter:!0,link:"https://github.com/bigcode-project/bigcodebench",paperUrl:"https://arxiv.org/abs/2406.15877"},{id:"gsm8k",name:"GSM8K",category:"Math",description:"Grade school math word problems requiring multi-step reasoning.",maxScore:100,higherIsBetter:!0,link:"https://github.com/openai/grade-school-math",paperUrl:"https://arxiv.org/abs/2110.14168"},{id:"aime",name:"AIME 2024/25",category:"Math",description:"American Invitational Mathematics Examination. Competition-level math.",maxScore:100,higherIsBetter:!0},{id:"lmarena-elo",name:"LMArena ELO",category:"Real-world",description:"Chatbot Arena ELO score. Crowd-sourced human preference ranking.",maxScore:1700,minScore:1e3,higherIsBetter:!0,normalization:"elo",unit:"ELO",link:"https://chat.lmsys.org/?leaderboard"},{id:"aa-intelligence-index",name:"AA Intelligence Index",category:"Real-world",description:"Artificial Analysis aggregate intelligence index.",maxScore:100,higherIsBetter:!0},{id:"agentbench",name:"AgentBench",category:"Agent",description:"Comprehensive framework to evaluate LLMs as agents across diverse environments.",maxScore:100,higherIsBetter:!0,link:"https://github.com/THUDM/AgentBench",paperUrl:"https://arxiv.org/abs/2308.03688"},{id:"mmlu-pro",name:"MMLU-Pro",category:"Science",description:"A more robust and harder version of MMLU, focusing on complex reasoning and STEM subjects.",maxScore:100,higherIsBetter:!0,link:"https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro",paperUrl:"https://arxiv.org/abs/2406.01574"},{id:"hle",name:"HLE",category:"Science",description:"Humanity's Last Exam - Hard reasoning benchmark without tools.",maxScore:100,higherIsBetter:!0,link:"https://agi.safe.ai/",paperUrl:"https://arxiv.org/abs/2501.14249"},{id:"hle-full",name:"HLE-Full",category:"Science",description:"Humanity's Last Exam full evaluation without tools.",maxScore:100,higherIsBetter:!0,link:"https://agi.safe.ai/",paperUrl:"https://arxiv.org/abs/2501.14249"},{id:"hle-full-tools",name:"HLE-Full (w/ tools)",category:"Science",description:"Humanity's Last Exam full evaluation with tool access enabled.",maxScore:100,higherIsBetter:!0,link:"https://agi.safe.ai/",paperUrl:"https://arxiv.org/abs/2501.14249"},{id:"critpt",name:"CritPt",category:"Science",description:"Complex Research using Integrated Thinking - Physics Test. Research-level physics reasoning.",maxScore:100,higherIsBetter:!0,link:"https://arxiv.org/abs/2501.00663"},{id:"simpleqa",name:"SimpleQA",category:"Science",description:"Open-domain factuality benchmark focusing on short, verifiable answers.",maxScore:100,higherIsBetter:!0},{id:"simpleqa-verified",name:"SimpleQA Verified",category:"Knowledge",description:"Verified subset of SimpleQA for parametric knowledge evaluation.",maxScore:100,higherIsBetter:!0},{id:"healthbench",name:"HealthBench",category:"Science",description:"Medical knowledge and diagnostic reasoning evaluation.",maxScore:100,higherIsBetter:!0},{id:"supergpqa",name:"SuperGPQA",category:"Science",description:"Extremely difficult expert-level science questions.",maxScore:100,higherIsBetter:!0},{id:"aime-2026",name:"AIME 2026",category:"Math",description:"Future prediction of AIME performance levels.",maxScore:100,higherIsBetter:!0},{id:"aa-math-index",name:"AA Math Index",category:"Math",description:"Artificial Analysis aggregate math capability index.",maxScore:100,higherIsBetter:!0},{id:"hmmt-feb-2025",name:"HMMT Feb 2025",category:"Math",description:"Harvard-MIT Mathematics Tournament - High difficulty competition math.",maxScore:100,higherIsBetter:!0},{id:"math-500",name:"MATH-500",category:"Math",description:"500-problem math benchmark for broad quantitative reasoning.",maxScore:100,higherIsBetter:!0},{id:"imo-answerbench",name:"IMO-AnswerBench",category:"Math",description:"International Mathematical Olympiad style answer-only benchmark.",maxScore:100,higherIsBetter:!0},{id:"matharena-apex",name:"MathArenaApex",category:"Math",description:"Competitive math arena for top-tier reasoning models.",maxScore:100,higherIsBetter:!0},{id:"codeforces",name:"Codeforces",category:"Coding",description:"Competitive programming rating based on problem solving.",maxScore:4e3,higherIsBetter:!0,normalization:"max",unit:"rating"},{id:"livecodebench-v6",name:"LiveCodeBench v6",category:"Coding",description:"Contamination-free coding benchmark using recent problems.",maxScore:100,higherIsBetter:!0,link:"https://livecodebench.github.io/",paperUrl:"https://arxiv.org/abs/2403.07974"},{id:"livecodebench-pro",name:"LiveCodeBench Pro",category:"Coding",description:"Competitive programming problems from Codeforces, ICPC, and IOI with Elo rating.",maxScore:4e3,higherIsBetter:!0,normalization:"max",unit:"Elo"},{id:"aa-coding-index",name:"AA Coding Index",category:"Coding",description:"Artificial Analysis aggregate coding capability index.",maxScore:100,higherIsBetter:!0},{id:"paperbench-codedev",name:"PaperBench (CodeDev)",category:"Coding",description:"Research-grade coding and software development tasks.",maxScore:100,higherIsBetter:!0},{id:"cybergym",name:"CyberGym",category:"Coding",description:"Cybersecurity-flavored coding benchmark in simulated environments.",maxScore:100,higherIsBetter:!0},{id:"ojbench-cpp",name:"OJBench (cpp)",category:"Coding",description:"Online-judge competitive coding benchmark focused on C++ tasks.",maxScore:100,higherIsBetter:!0},{id:"gpqa-diamond",name:"GPQA Diamond",category:"STEM",description:"Graduate-Level Google-Proof Q&A Benchmark.",maxScore:100,higherIsBetter:!0,link:"https://gpqa-benchmark.github.io/",paperUrl:"https://arxiv.org/abs/2311.12022"},{id:"phybench",name:"Phybench",category:"STEM",description:"Physics reasoning and problem solving benchmark.",maxScore:100,higherIsBetter:!0},{id:"arc-agi-1",name:"ARC-AGI-1",category:"Reasoning",description:"Abstraction and Reasoning Corpus - Level 1.",maxScore:100,higherIsBetter:!0,link:"https://arcprize.org/",paperUrl:"https://arxiv.org/abs/1911.01547"},{id:"mrcr-v2",name:"MRCR v2",category:"Long Context",description:"Multi-Round Context Retrieval - 8-needle test.",maxScore:100,higherIsBetter:!0},{id:"longbench-v2",name:"LongBench v2",category:"Long Context",description:"Comprehensive long-context understanding (128k).",maxScore:100,higherIsBetter:!0},{id:"lcr",name:"AA-LCR",category:"Long Context",description:"Artificial Analysis Long Context Reasoning benchmark. Evaluates reasoning over long contexts.",maxScore:100,higherIsBetter:!0,link:"https://artificialanalysis.ai/evaluations#lcr"},{id:"mmmlu",name:"MMMLU",category:"Multilingual",description:"Massive Multilingual Language Understanding.",maxScore:100,higherIsBetter:!0,paperUrl:"https://arxiv.org/abs/2402.03300"},{id:"ifeval",name:"IFEval",category:"Instruction Following",description:"Instruction Following Evaluation for Large Language Models. Measures ability to follow strict formatting and constraint requirements.",maxScore:100,higherIsBetter:!0,link:"https://huggingface.co/spaces/yejinxie/IFEval",paperUrl:"https://arxiv.org/abs/2311.07911"},{id:"ifeval-inverse",name:"Inverse IFEval",category:"Instruction Following",description:"Reverse instruction following evaluation.",maxScore:100,higherIsBetter:!0},{id:"ifbench",name:"IFBench",category:"Instruction Following",description:"Artificial Analysis IFBench. Evaluates precise instruction following with constraints.",maxScore:100,higherIsBetter:!0,link:"https://artificialanalysis.ai/evaluations#ifbench"},{id:"verified-advancedif",name:"Verified AdvancedIF",category:"Instruction Following",description:"Advanced instruction-following benchmark with verified grading.",maxScore:100,higherIsBetter:!0},{id:"longfact-concepts",name:"LongFact-Concepts",category:"Hallucination",description:"Factuality in long-form conceptual generations.",maxScore:100,higherIsBetter:!0},{id:"aa-omniscience",name:"AA-Omniscience",category:"Hallucination",description:"Evaluates model omniscience and factual reliability across diverse domains.",maxScore:100,minScore:-100,higherIsBetter:!0,link:"https://artificialanalysis.ai/evaluations#omniscience"},{id:"aime-2025",name:"AIME 2025",category:"Math",description:"American Invitational Mathematics Examination 2025 problems.",maxScore:100,higherIsBetter:!0},{id:"arc-agi-2",name:"ARC-AGI-2",category:"Reasoning",description:"Abstraction and Reasoning Corpus - Level 2 (Extreme difficulty).",maxScore:100,higherIsBetter:!0},{id:"factscore",name:"FactScore",category:"Hallucination",description:"Precision of fine-grained facts in long-form biographies.",maxScore:100,higherIsBetter:!0},{id:"superchem",name:"Superchem",category:"STEM",description:"Expert-level chemistry knowledge and reasoning.",maxScore:100,higherIsBetter:!0},{id:"korbench",name:"KORBench",category:"Reasoning",description:"Korean reasoning and language understanding benchmark.",maxScore:100,higherIsBetter:!0},{id:"graphwalks-bfs",name:"Graphwalks Bfs",category:"Long Context",description:"Traversal-based long context reasoning using BFS (128k).",maxScore:100,higherIsBetter:!0},{id:"global-piqa",name:"Global PIQA",category:"Multilingual",description:"Physical Interaction QA across multiple languages and cultures.",maxScore:100,higherIsBetter:!0},{id:"multichallenge",name:"MultiChallenge",category:"Instruction Following",description:"Complex, multi-constraint instruction following tasks.",maxScore:100,higherIsBetter:!0},{id:"longfact-objects",name:"LongFact-Objects",category:"Hallucination",description:"Factuality in long-form generations about objects.",maxScore:100,higherIsBetter:!0},{id:"putnam-200",name:"Putnam-200",category:"Math",description:"William Lowell Putnam Mathematical Competition problems - top 200 level difficulty.",maxScore:100,higherIsBetter:!0},{id:"mathvista",name:"MathVista",category:"Vision",description:"Mathematical reasoning in visual contexts.",maxScore:100,higherIsBetter:!0,link:"https://mathvista.github.io/",paperUrl:"https://arxiv.org/abs/2310.02255"},{id:"mathvista-mini",name:"MathVista (mini)",category:"Vision",description:"Compact MathVista split for faster multimodal reasoning checks.",maxScore:100,higherIsBetter:!0},{id:"mathvision",name:"MathVision",category:"Vision",description:"Comprehensive mathematical vision benchmark.",maxScore:100,higherIsBetter:!0},{id:"mmmu-vision",name:"MMMU",category:"Vision",description:"Massive Multi-discipline Multimodal Understanding and Reasoning.",maxScore:100,higherIsBetter:!0},{id:"logicvista",name:"LogicVista",category:"Vision",description:"Logical reasoning in visual puzzles and diagrams.",maxScore:100,higherIsBetter:!0},{id:"blink",name:"BLINK",category:"Vision",description:"Spatial and perception benchmark for multimodal models.",maxScore:100,higherIsBetter:!0},{id:"mmvp",name:"MMVP",category:"Vision",description:"Multimodal visual perception benchmark.",maxScore:100,higherIsBetter:!0},{id:"chartqapro",name:"ChartQA Pro",category:"Vision",description:"Expert-level chart understanding and question answering.",maxScore:100,higherIsBetter:!0},{id:"docvqa",name:"DocVQA",category:"Vision",description:"Document visual question answering on scanned and digital documents.",maxScore:100,higherIsBetter:!0,link:"https://rrc.cvc.uab.es/?ch=17",paperUrl:"https://arxiv.org/abs/2007.00398"},{id:"ocrbench-v2",name:"OCRBench v2",category:"Vision",description:"Next-gen optical character recognition and document understanding.",maxScore:100,higherIsBetter:!0},{id:"ocrbench",name:"OCRBench",category:"Vision",description:"Optical character recognition and document understanding benchmark.",maxScore:100,higherIsBetter:!0,link:"https://ocrbench.github.io/",paperUrl:"https://arxiv.org/abs/2312.16151"},{id:"dynamath",name:"DynaMath",category:"Vision",description:"Dynamic mathematical reasoning in visual contexts.",maxScore:100,higherIsBetter:!0},{id:"mathkangaroo",name:"MathKangaroo",category:"Vision",description:"Mathematical competition problems with visual elements.",maxScore:100,higherIsBetter:!0},{id:"mathcanvas",name:"MathCanvas",category:"Vision",description:"Multi-step mathematical reasoning on a canvas.",maxScore:100,higherIsBetter:!0},{id:"mmmu-pro",name:"MMMU-Pro",category:"Vision",description:"Professional level MMMU expansion.",maxScore:100,higherIsBetter:!0},{id:"mmmu-val",name:"MMMU (val)",category:"Vision",description:"Validation split of MMMU for multimodal understanding.",maxScore:100,higherIsBetter:!0},{id:"emma",name:"EMMA",category:"Vision",description:"Expert-level Multimodal Mathematics Analysis.",maxScore:100,higherIsBetter:!0},{id:"sfe",name:"SFE",category:"Vision",description:"Scientific Figure Evaluation.",maxScore:100,higherIsBetter:!0},{id:"hipho",name:"HiPhO",category:"Vision",description:"High-level Physics Olympiad (Vision).",maxScore:100,higherIsBetter:!0},{id:"xlrs-bench",name:"XLRS-Bench",category:"Vision",description:"Cross-domain Logical Reasoning and Spatial benchmark.",maxScore:100,higherIsBetter:!0},{id:"phyx",name:"PhyX",category:"Vision",description:"Physics reasoning with open-ended visual questions.",maxScore:100,higherIsBetter:!0},{id:"vpct",name:"VPCT",category:"Vision",description:"Visual Perception and Coding Tasks.",maxScore:100,higherIsBetter:!0},{id:"zerobench-main",name:"ZeroBench (main)",category:"Vision",description:"Zero-shot visual reasoning benchmark.",maxScore:100,higherIsBetter:!0},{id:"zerobench-sub",name:"ZeroBench (sub)",category:"Vision",description:"Zero-shot visual reasoning sub-tasks.",maxScore:100,higherIsBetter:!0},{id:"zerobench",name:"ZeroBench",category:"Vision",description:"Aggregate ZeroBench score across the full task set.",maxScore:100,higherIsBetter:!0},{id:"zerobench-tools",name:"ZeroBench (w/ tools)",category:"Vision",description:"ZeroBench score when tool use is allowed.",maxScore:100,higherIsBetter:!0},{id:"arc-agi-1-image",name:"ArcAGI1-Image",category:"Vision",description:"ARC-AGI Level 1 tasks in image format.",maxScore:100,higherIsBetter:!0},{id:"arc-agi-2-image",name:"ArcAGI2-Image",category:"Vision",description:"ARC-AGI Level 2 tasks in image format.",maxScore:100,higherIsBetter:!0},{id:"visulogic",name:"VisuLogic",category:"Vision",description:"Visual logic and sequence reasoning.",maxScore:100,higherIsBetter:!0},{id:"vlms-are-biased",name:"VLMsAreBiased",category:"Vision",description:"Evaluating bias in Vision-Language Models.",maxScore:100,higherIsBetter:!0},{id:"vlms-are-blind",name:"VLMsAreBlind",category:"Vision",description:"Evaluating perception failures in VLMs.",maxScore:100,higherIsBetter:!0},{id:"visfactor",name:"VisFactor",category:"Vision",description:"Visual factor identification and reasoning.",maxScore:100,higherIsBetter:!0},{id:"realworldqa",name:"RealWorldQA",category:"Vision",description:"Real-world visual question answering.",maxScore:100,higherIsBetter:!0},{id:"babyvision",name:"BabyVision",category:"Vision",description:"Early-stage visual development benchmark.",maxScore:100,higherIsBetter:!0},{id:"hallusionbench",name:"HallusionBench",category:"Vision",description:"Visual hallucination and factuality benchmark.",maxScore:100,higherIsBetter:!0},{id:"mme-cc",name:"MME-CC",category:"Vision",description:"Multimodal Evaluation (Cognitive Capacity).",maxScore:100,higherIsBetter:!0},{id:"mmstar",name:"MMStar",category:"Vision",description:"Elite multimodal model evaluation.",maxScore:100,higherIsBetter:!0},{id:"muirbench",name:"MUIRBench",category:"Vision",description:"Multimodal Understanding and Interaction Benchmark.",maxScore:100,higherIsBetter:!0},{id:"mtvqa",name:"MTVQA",category:"Vision",description:"Multilingual Text-centric Visual QA.",maxScore:100,higherIsBetter:!0},{id:"worldvqa",name:"WorldVQA",category:"Vision",description:"Global visual knowledge and reasoning.",maxScore:100,higherIsBetter:!0},{id:"vibeeval",name:"VibeEval",category:"Vision",description:"Subjective and intuitive visual quality evaluation.",maxScore:100,higherIsBetter:!0},{id:"viverbench",name:"ViVerBench",category:"Vision",description:"Visual Verification and reasoning.",maxScore:100,higherIsBetter:!0},{id:"countbench",name:"CountBench",category:"Vision",description:"Visual object counting and identification.",maxScore:100,higherIsBetter:!0},{id:"fsc-147",name:"FSC-147",category:"Vision",description:"Few-shot counting benchmark (Lower is better handled in normalization).",maxScore:100,higherIsBetter:!1,normalization:"inverse",unit:"error"},{id:"point-bench",name:"Point-Bench",category:"Vision",description:"Visual pointing and spatial grounding.",maxScore:100,higherIsBetter:!0},{id:"mmsibench",name:"MMSIBench",category:"Vision",description:"Multimodal Spatial Interaction Benchmark.",maxScore:100,higherIsBetter:!0},{id:"treebench",name:"TreeBench",category:"Vision",description:"Hierarchical visual reasoning tasks.",maxScore:100,higherIsBetter:!0},{id:"refspatialbench",name:"RefSpatialBench",category:"Vision",description:"Referential spatial reasoning evaluation.",maxScore:100,higherIsBetter:!0},{id:"da-2k",name:"DA-2K",category:"Vision",description:"Document Analysis and reasoning (2k).",maxScore:100,higherIsBetter:!0},{id:"all-angles",name:"All-Angles",category:"Vision",description:"Multi-perspective visual understanding.",maxScore:100,higherIsBetter:!0},{id:"erqa",name:"ERQA",category:"Vision",description:"Environment Reasoning and Question Answering.",maxScore:100,higherIsBetter:!0},{id:"omnidocbench",name:"OmniDocBench",category:"Vision",description:"Universal document understanding benchmark.",maxScore:100,higherIsBetter:!0},{id:"omnidocbench-15",name:"OmniDocBench 1.5",category:"Vision",description:"OCR benchmark measuring edit distance (lower is better).",maxScore:1,minScore:0,higherIsBetter:!1,unit:"edit distance"},{id:"screenspot-pro",name:"ScreenSpot-Pro",category:"Vision",description:"Screen understanding benchmark for GUI interaction.",maxScore:100,higherIsBetter:!0},{id:"infovqa-test",name:"InfoVQA (test)",category:"Vision",description:"Information-seeking visual question answering on the test split.",maxScore:100,higherIsBetter:!0},{id:"charxiv-dq",name:"CharXiv-DQ",category:"Vision",description:"Chart-based reasoning from arXiv papers (Data QA).",maxScore:100,higherIsBetter:!0},{id:"charxiv-rq",name:"CharXiv-RQ",category:"Vision",description:"Chart-based reasoning from arXiv papers (Reasoning QA).",maxScore:100,higherIsBetter:!0},{id:"charxiv-reasoning",name:"CharXiv Reasoning",category:"Vision",description:"Information synthesis from complex charts.",maxScore:100,higherIsBetter:!0},{id:"dude",name:"DUDE",category:"Vision",description:"Document Understanding and Dialogue Evaluation.",maxScore:100,higherIsBetter:!0},{id:"mmlongbench",name:"MMLongBench",category:"Vision",description:"Multimodal Long context benchmark.",maxScore:100,higherIsBetter:!0},{id:"longdocurl",name:"LongDocURL",category:"Vision",description:"Long document understanding with URLs.",maxScore:100,higherIsBetter:!0},{id:"mmlongbench-doc",name:"MMLongBench-Doc",category:"Vision",description:"Multimodal Long context document evaluation.",maxScore:100,higherIsBetter:!0},{id:"mmvu",name:"MMVU",category:"Video",description:"Multimodal Video Understanding.",maxScore:100,higherIsBetter:!0},{id:"videosimpleqa",name:"VideoSimpleQA",category:"Video",description:"Verifiable question answering for short video clips.",maxScore:100,higherIsBetter:!0},{id:"videoreasonbench",name:"VideoReasonBench",category:"Video",description:"Complex reasoning tasks in video content.",maxScore:100,higherIsBetter:!0},{id:"morse-500",name:"Morse-500",category:"Video",description:"Sequence reasoning and motion understanding.",maxScore:100,higherIsBetter:!0},{id:"videoholmes",name:"VideoHolmes",category:"Video",description:"Deep diagnostic video understanding.",maxScore:100,higherIsBetter:!0},{id:"minerva",name:"Minerva",category:"Video",description:"Long-form video reasoning and knowledge retrieval.",maxScore:100,higherIsBetter:!0},{id:"contphy",name:"ContPhy",category:"Video",description:"Continuous Physics reasoning in video.",maxScore:100,higherIsBetter:!0},{id:"tempcompass",name:"TempCompass",category:"Video",description:"Temporal orientation and perception in video.",maxScore:100,higherIsBetter:!0},{id:"egotempo",name:"EgoTempo",category:"Video",description:"First-person perspective temporal reasoning.",maxScore:100,higherIsBetter:!0},{id:"motionbench",name:"MotionBench",category:"Video",description:"Comprehensive motion perception evaluation.",maxScore:100,higherIsBetter:!0},{id:"tomato",name:"TOMATO",category:"Video",description:"Temporal Object-centric Multimodal Analysis.",maxScore:100,higherIsBetter:!0},{id:"cgbench",name:"CGBench",category:"Video",description:"Contextual Grounding in long videos.",maxScore:100,higherIsBetter:!0},{id:"longvideobench",name:"LongVideoBench",category:"Video",description:"Understanding extremely long-form video content.",maxScore:100,higherIsBetter:!0},{id:"videoeval-pro",name:"VideoEval-Pro",category:"Video",description:"Professional level video quality and content evaluation.",maxScore:100,higherIsBetter:!0},{id:"lvbench",name:"LVBench",category:"Video",description:"Large-scale Video Benchmark.",maxScore:100,higherIsBetter:!0},{id:"crossvid",name:"CrossVid",category:"Video",description:"Cross-video temporal and relational reasoning.",maxScore:100,higherIsBetter:!0},{id:"livesports-3k",name:"LiveSports-3K",category:"Video",description:"Live sports broadcast understanding.",maxScore:100,higherIsBetter:!0},{id:"ovobench",name:"OVOBench",category:"Video",description:"Object-Video-Object relational reasoning.",maxScore:100,higherIsBetter:!0},{id:"odvbench",name:"ODVBench",category:"Video",description:"Open-Domain Video understanding.",maxScore:100,higherIsBetter:!0},{id:"vispeak",name:"ViSpeak",category:"Video",description:"Video-to-speech and dialogue reasoning.",maxScore:100,higherIsBetter:!0},{id:"frontiersci-olympiad",name:"FrontierSci-olympiad",category:"STEM",description:"Scientific Olympiad level problems.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"terminal-bench",name:"Terminal-Bench 2.0",category:"Agentic",description:"Agent performance in realistic terminal workflows (v2.0 leaderboard).",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"terminal-bench-hard",name:"Terminal-Bench Hard",category:"Agentic",description:"Hard split of Terminal-Bench focused on tougher terminal workflows.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"osworld-verified",name:"OSWorld-Verified",category:"Agentic",description:"Verified desktop computer-use benchmark for end-to-end task completion.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"webarena",name:"WebArena",category:"Agentic",description:"Browser-based autonomous task execution benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%",link:"https://webarena.dev/",paperUrl:"https://arxiv.org/abs/2307.13854"},{id:"swe-lancer",name:"SWE-Lancer",category:"Agentic",description:"Software engineering task completion in multi-step coding workflows.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"multi-swe-bench",name:"Multi-SWE-bench",category:"Agentic",description:"Multi-repository software engineering benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"swe-bench-pro",name:"SWE-bench Pro",category:"Agentic",description:"Higher-difficulty SWE-bench subset for frontier coding agents.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"swe-multilingual",name:"SWE Multilingual",category:"Agentic",description:"Software engineering performance across multilingual codebases.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"swe-evo",name:"SWE-Evo",category:"Agentic",description:"Evolutionary coding benchmark focused on long-horizon bug fixing.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"aider-polyglot",name:"Aider Polyglot",category:"Agentic",description:"Multi-language coding agent benchmark with editor-in-the-loop tasks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"artifactsbench",name:"ArtifactsBench",category:"Agentic",description:"Agent ability to produce complete, runnable software artifacts.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"codesimpleqa",name:"CodeSimpleQA",category:"Agentic",description:"Short-form coding QA with executable correctness checks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"spreadsheetbench-verified",name:"SpreadsheetBench Verified",category:"Agentic",description:"Verified spreadsheet manipulation and reasoning tasks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"browsecomp",name:"BrowseComp",category:"Agentic",description:"Web browsing + synthesis benchmark for research agents.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"browsecomp-ctx-manage",name:"BrowseComp (ctx manage)",category:"Agentic",description:"BrowseComp variant with explicit context-window management.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"browsecomp-agent-swarm",name:"BrowseComp (Agent Swarm)",category:"Agentic",description:"Multi-agent swarm variant of BrowseComp.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"browsecomp-zh",name:"BrowseComp-ZH",category:"Agentic",description:"Chinese-language browsing and synthesis benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"hle-text",name:"HLE-Text",category:"Agentic",description:"Text-only variant of Humanity's Last Exam under agentic settings.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"hle-verified",name:"HLE-Verified",category:"Agentic",description:"Verified subset of Humanity's Last Exam for reproducible evaluation.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"widesearch",name:"WideSearch",category:"Agentic",description:"Broad retrieval and synthesis benchmark across many sources.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"widesearch-agent-swarm",name:"WideSearch (Agent Swarm)",category:"Agentic",description:"Multi-agent swarm variant of WideSearch.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"finsearchcomp",name:"FinSearchComp",category:"Agentic",description:"Finance-focused search and evidence-grounded answering benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"finsearchcomp-t2-t3",name:"FinSearchComp T2&T3",category:"Agentic",description:"Tier 2 and Tier 3 slices of FinSearchComp.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"vending-bench-2",name:"Vending-Bench 2",category:"Agentic",description:"Long-horizon business simulation benchmark (final account balance).",maxScore:1e4,minScore:0,higherIsBetter:!0,normalization:"max",unit:"USD"},{id:"facts-benchmark",name:"FACTS Benchmark Suite",category:"Agentic",description:"Factuality benchmark across grounding, parametric, search, and multimodal.",maxScore:100,higherIsBetter:!0},{id:"mcp-atlas",name:"MCP Atlas",category:"Agentic",description:"Multi-step workflows using Model Context Protocol.",maxScore:100,higherIsBetter:!0},{id:"toolathlon",name:"Toolathlon",category:"Agentic",description:"Long horizon real-world software tasks.",maxScore:100,higherIsBetter:!0},{id:"deepsearchqa",name:"DeepSearchQA",category:"Agentic",description:"Deep multi-hop search QA for long-horizon agents.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"seal-0",name:"SEAL-0",category:"Agentic",description:"Strategic environment-agent loop benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"gdpval-aa",name:"GDPVal-AA",category:"Agentic",description:"Artificial Analysis GDPVal benchmark for knowledge-work quality.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tau-bench",name:"TAU-Bench",category:"Agentic",description:"Tool-use and API orchestration benchmark for assistants.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tau-bench-retail",name:"TAU-Bench Retail",category:"Agentic",description:"Retail-domain tool-use and workflow benchmark from -bench.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tau-bench-telecom",name:"TAU-Bench Telecom",category:"Agentic",description:"Telecom-domain tool-use and workflow benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"mcp-mark",name:"MCP-Mark",category:"Agentic",description:"Model Context Protocol interoperability benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"bfcl-v4",name:"BFCL v4",category:"Agentic",description:"Function calling reliability benchmark (v4).",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"vitabench",name:"VitaBench",category:"Agentic",description:"Virtual task assistant benchmark across practical workflows.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"deepconsult",name:"DeepConsult",category:"Agentic",description:"Consulting-style multi-step reasoning and recommendation benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"deepresearchbench",name:"DeepResearchBench",category:"Agentic",description:"Long-horizon research task benchmark with citation requirements.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"researchrubrics",name:"ResearchRubrics",category:"Agentic",description:"Rubric-based evaluation of research quality and rigor.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"minedojo-verified",name:"MineDojo Verified",category:"Agentic",description:"Verified embodied-agent benchmark in Minecraft-style tasks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"mm-browsecomp",name:"MM-BrowseComp",category:"Agentic",description:"Multimodal browse + synthesize benchmark for web agents.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"hle-vl",name:"HLE-VL",category:"Agentic",description:"Vision-language variant of Humanity's Last Exam under agentic settings.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"scicode",name:"SciCode",category:"Advanced Tasks",description:"Scientific programming benchmark for code synthesis and correctness.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"frontiersci-research",name:"FrontierSci Research",category:"Advanced Tasks",description:"Open-ended scientific research benchmark with expert-level questions.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"biobench",name:"BioBench",category:"Advanced Tasks",description:"Biology and life-science benchmark requiring deep domain reasoning.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"ainstein-bench",name:"AInstein-Bench",category:"Advanced Tasks",description:"Hard scientific reasoning benchmark inspired by olympiad-level tasks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"vibe-coding",name:"Vibe Coding",category:"Advanced Tasks",description:"High-level coding outcome quality benchmark for agent-driven development.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"nl2repo-bench",name:"NL2Repo-Bench",category:"Advanced Tasks",description:"Natural language to repository-wide code edits benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"nl2repo-pass1",name:"NL2Repo Pass@1",category:"Advanced Tasks",description:"Pass@1 metric for repository-scale code modification tasks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"cl-bench",name:"CL-Bench",category:"Advanced Tasks",description:"Complex language benchmark covering difficult enterprise workflows.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tob-complex",name:"TOB Complex",category:"Advanced Tasks",description:"Task-oriented benchmark for complex instruction execution.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tob-reference",name:"TOB Reference",category:"Advanced Tasks",description:"Reference-heavy task-oriented benchmark requiring retrieval fidelity.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"healthbench-hard",name:"HealthBench Hard",category:"Advanced Tasks",description:"Hard-split medical reasoning benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"gdpval-diamond",name:"GDPVal Diamond",category:"Advanced Tasks",description:"Diamond subset for difficult planning and valuation tasks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"xpert-bench",name:"Xpert-Bench",category:"Advanced Tasks",description:"Expert-level evaluation benchmark across specialist domains.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tob-k12",name:"TOB K12",category:"Advanced Tasks",description:"Task-oriented benchmark for K12 educational tasks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tob-compositional",name:"TOB Compositional",category:"Advanced Tasks",description:"Compositional instruction-following benchmark with chained constraints.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tob-classification",name:"TOB Classification",category:"Advanced Tasks",description:"Classification-focused track of task-oriented benchmark suite.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tob-extraction",name:"TOB Extraction",category:"Advanced Tasks",description:"Extraction-focused benchmark for structured information tasks.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"world-travel-vlm",name:"World-Travel VLM",category:"Advanced Tasks",description:"Vision-language travel-planning and grounded reasoning benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"world-travel-text",name:"World-Travel Text",category:"Advanced Tasks",description:"Text-only travel-planning and itinerary reasoning benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"simplevqa",name:"SimpleVQA",category:"Vision",description:"Short-form visual question answering with verifiable responses.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"videommmu",name:"VideoMMMU",category:"Video",description:"Video variant of MMMU for multimodal understanding and reasoning.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"videomme",name:"VideoMME",category:"Video",description:"Video multimodal evaluation benchmark for perception and reasoning.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"tvbench",name:"TVBench",category:"Video",description:"Television/video narrative understanding benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"},{id:"ovbench",name:"OVBench",category:"Video",description:"Open-world video understanding benchmark.",maxScore:100,higherIsBetter:!0,normalization:"max",unit:"%"}].map(e=>({...e,normalization:e.normalization??("lmarena-elo"===e.id?"elo":e.higherIsBetter?"max":"inverse"),unit:e.unit??("lmarena-elo"===e.id?"ELO":"%"),link:e.link??t[e.id]??`https://artificialanalysis.ai/evaluations#${e.id}`}));e.s(["benchmarks",0,i])},18566,(e,t,i)=>{t.exports=e.r(76562)},49766,e=>{"use strict";var t=e.i(53073);let i=[{id:"Intelligence",label:"Intelligence",description:"Reasoning, scientific understanding, and complex problem-solving abilities",longDescription:"Measures advanced cognitive capabilities including logical reasoning, scientific knowledge, multi-step problem solving, and the ability to tackle novel challenges. Includes benchmarks for GPQA, ARC-AGI, and other frontier reasoning tasks.",categories:["Reasoning","Science","STEM","Advanced Tasks"],icon:"Brain"},{id:"Knowledge & Communication",label:"Knowledge & Communication",description:"World knowledge, multilingual capabilities, and real-world understanding",longDescription:"Evaluates breadth and depth of world knowledge, language understanding across multiple languages, and ability to communicate effectively. Covers MMLU, HellaSwag, WMT translations, and real-world task performance.",categories:["Knowledge","Multilingual","Real-world"],icon:"Globe"},{id:"Coding",label:"Coding",description:"Code generation, software engineering, and programming tasks",longDescription:"Tests programming proficiency across multiple languages, software engineering tasks, debugging capabilities, and real-world coding scenarios. Includes HumanEval, MBPP, SWE-bench, and competitive programming benchmarks.",categories:["Coding"],icon:"Code"},{id:"Math",label:"Math",description:"Mathematical reasoning, competition math, and quantitative problem-solving",longDescription:"Assesses mathematical capabilities from basic arithmetic to competition-level problems. Covers GSM8K, MATH, AIME, and specialized mathematical reasoning benchmarks.",categories:["Math"],icon:"Calculator"},{id:"Agents & Tools",label:"Agents & Tools",description:"Tool use, agentic workflows, and instruction following",longDescription:"Measures ability to use external tools, follow complex instructions, operate autonomously in multi-step workflows, and function as effective AI agents. Includes BFCL, API-based tasks, and instruction following benchmarks.",categories:["Agent","Agentic","Instruction Following"],icon:"Bot"},{id:"Vision & Video",label:"Vision & Video",description:"Image understanding, video analysis, and multimodal capabilities",longDescription:"Evaluates visual understanding including image classification, object detection, video comprehension, and multimodal reasoning. Covers MMMU, VQA, video understanding, and cross-modal tasks.",categories:["Vision","Video","Multimodal"],icon:"Eye"},{id:"Long Context",label:"Long Context",description:"Performance on extended documents and long-context reasoning",longDescription:"Tests ability to process, understand, and reason over very long inputs. Includes needle-in-haystack tests, long-document QA, and benchmarks measuring performance degradation with context length.",categories:["Long Context"],icon:"Scroll"},{id:"Factuality",label:"Factuality",description:"Accuracy, hallucination resistance, and factual reliability",longDescription:"Measures tendency to produce factually accurate outputs, resistance to hallucinations, and ability to acknowledge uncertainty. Includes TruthfulQA, FACTSCORE, and other factuality benchmarks.",categories:["Hallucination"],icon:"CheckCircle"}];function r(e){let r;return(!(r=i.find(t=>t.id===e))?[]:t.benchmarks.filter(e=>r.categories.includes(e.category))).map(e=>e.id)}function n(e){return e.toLowerCase().replace(/\s*&\s*/g,"-").replace(/\s+/g,"-")}i.reduce((e,t)=>(e[t.id]=t.categories,e),{}),i.map(e=>e.id),e.s(["domainDefinitions",0,i,"domainToSlug",()=>n,"getBenchmarkIdsForDomain",()=>r])}]);